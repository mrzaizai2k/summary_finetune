{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/examples\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "    print(file_path)\n",
        "except:\n",
        "    file_path = os.path.abspath('')\n",
        "    os.chdir(os.path.dirname(file_path))\n",
        "    print(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3_GCCIaj7ulj"
      },
      "outputs": [],
      "source": [
        "# !wget 'https://github.com/ThanhChinhBK/vietnews/archive/master.zip'\n",
        "# !unzip 'master.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TZYjioRkKviO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "import concurrent.futures\n",
        "from datasets import *\n",
        "import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# from vncorenlp import VnCoreNLP\n",
        "import torch \n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Gx4Vg4cbEUJ_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "OUTPUT_DIR = 'vietnamese_mt5_summary_model'\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/mrzaizai2k/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IteMtlc58-y"
      },
      "source": [
        "## Processing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UVkc5HmK6Bdd"
      },
      "outputs": [],
      "source": [
        "def listPaths(path):\n",
        "  pathfiles = list()\n",
        "  for pathfile in glob.glob(path):\n",
        "    pathfiles.append(pathfile)\n",
        "  return pathfiles\n",
        "\n",
        "train_paths = listPaths('data/vietnews-master/data/train_tokenized/*')\n",
        "val_paths = listPaths('data/vietnews-master/data/val_tokenized/*')\n",
        "test_paths = listPaths('data/vietnews-master/data/test_tokenized/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YZ8pgIYN7zSW"
      },
      "outputs": [],
      "source": [
        "def read_content(pathfile):\n",
        "    \"\"\"\n",
        "    Input: Path of txt file\n",
        "    Output: A dictionary has keys 'original' and 'summary'\n",
        "    \"\"\"\n",
        "    with open(pathfile) as f:\n",
        "      rows  = f.readlines()\n",
        "      original = ' '.join(''.join(rows[4:]).split('\\n'))\n",
        "      summary = ' '.join(rows[2].split('\\n'))\n",
        "            \n",
        "    return {'file' : pathfile,\n",
        "              'original': original, \n",
        "              'summary': summary}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_716GF2iDTcD",
        "outputId": "07268442-c69d-4818-a69a-2f9200044eed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'file': 'data/vietnews-master/data/train_tokenized/006157.txt.seg',\n",
              " 'original': 'Tập 4 Thần_tượng Âm_nhạc nhí - Vietnam_Idol_Kids 2017 lên sóng tối 2/6 với màn tranh tài của top 8 thí_sinh nữ để lựa_chọn ra 5 tấm vé vào tiếp vòng trong . Trong đó , 3 giám_khảo Isaac - Văn_Mai_Hương - Bích_Phương được quyền lựa_chọn 3 thí_sinh . 2 thí_sinh còn lại sẽ do các giám_khảo khách mời quyết_định . Nữ ca_sĩ Văn_Mai_Hương xúc_động : “ Cô có may_mắn năm nay ngồi ở vị_trí ban giám_khảo , may_mắn hơn là được gặp con . Mỗi khi gặp Hiền , cô tự thấy bản_thân cô rất kém , bởi có lúc cô không trân_trọng cũng như không tin vào bản_thân ... Cảm_ơn con , bởi đôi_khi có những cái cô không bằng con được , đó là sự lạc_quan . Và cô tin , còn rất nhiều người phải học đức_tính lạc_quan này của Hiền . Con hát rất là hay ” . Đồng_tình với ý_kiến của đồng_nghiệp , Bích_Phương cũng xúc_động chia_sẻ : “ Giọt nước_mắt dành cho con là sự khâm_phục chứ không phải là thương_cảm . Cô chưa bao_giờ thấy con buồn . Từ lúc xuất_hiện , lúc_nào con cũng cười thôi . Cô nghĩ là ngoài tinh_thần lạc_quan của Hiền làm cho mọi người phải khâm_phục nên mọi người mới khóc … Bên cạnh đó , con còn có giọng hát rất hay . Con rất xứng_đáng được sâu vào vòng trong ” . Hà_Linh  ',\n",
              " 'summary': 'Trên sân_khấu Vietnam_Idol_Kids 2017 , cô_bé khiếm_thị Minh_Hiền khiến giám_khảo và khán_giả lặng người khi tiết_lộ ước_mơ của bản_thân . '}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_content(train_paths[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Wm5kLJD_840E"
      },
      "outputs": [],
      "source": [
        "def get_dataframe(pathfiles):\n",
        "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "      data = executor.map(read_content, pathfiles)\n",
        "    \n",
        "    # Make blank dataframe\n",
        "    data_df = list()\n",
        "    for d in data:\n",
        "      data_df.append(d)\n",
        "    data_df = pd.DataFrame(data_df)\n",
        "    data_df.dropna(inplace = True)\n",
        "    data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    return data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d4c0pl5BAl3f"
      },
      "outputs": [],
      "source": [
        "train_df = get_dataframe(train_paths[:10000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DgMgMnisA0cf"
      },
      "outputs": [],
      "source": [
        "val_df = get_dataframe(val_paths[:10000])\n",
        "test_df = get_dataframe(test_paths[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>original</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/01796...</td>\n",
              "      <td>Theo Hãng tin Bloomberg , trong bối_cảnh nhiều...</td>\n",
              "      <td>Nguồn_tin của hãng Bloomberg cho_biết cơ_quan_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/00547...</td>\n",
              "      <td>Hãng tin Reuters cho_biết đã đọc được 1 bản bá...</td>\n",
              "      <td>Tổng_thống Robert_Mugabe từng là tượng_đài , l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/01964...</td>\n",
              "      <td>Tối 7/6 , Thành_uỷ Đà_Nẵng cho_biết đã chỉ_đạo...</td>\n",
              "      <td>Giám_đốc , phó giám_đốc Cảng vụ đường_thuỷ nội...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/01912...</td>\n",
              "      <td>Ngày 28/3 , UBND huyện Hải_Lăng , Quảng_Trị cô...</td>\n",
              "      <td>9 con lợn của hộ dân ở xã Hải_Chánh ( Hải_Lăng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/00591...</td>\n",
              "      <td>' Hai chân ' ... bị lệch Thứ_trưởng Nguyễn_Văn...</td>\n",
              "      <td>Thứ_trưởng Bộ GD-ĐT Nguyễn_Văn_Phúc đã nhấn_mạ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                file  \\\n",
              "0  data/vietnews-master/data/test_tokenized/01796...   \n",
              "1  data/vietnews-master/data/test_tokenized/00547...   \n",
              "2  data/vietnews-master/data/test_tokenized/01964...   \n",
              "3  data/vietnews-master/data/test_tokenized/01912...   \n",
              "4  data/vietnews-master/data/test_tokenized/00591...   \n",
              "\n",
              "                                            original  \\\n",
              "0  Theo Hãng tin Bloomberg , trong bối_cảnh nhiều...   \n",
              "1  Hãng tin Reuters cho_biết đã đọc được 1 bản bá...   \n",
              "2  Tối 7/6 , Thành_uỷ Đà_Nẵng cho_biết đã chỉ_đạo...   \n",
              "3  Ngày 28/3 , UBND huyện Hải_Lăng , Quảng_Trị cô...   \n",
              "4  ' Hai chân ' ... bị lệch Thứ_trưởng Nguyễn_Văn...   \n",
              "\n",
              "                                             summary  \n",
              "0  Nguồn_tin của hãng Bloomberg cho_biết cơ_quan_...  \n",
              "1  Tổng_thống Robert_Mugabe từng là tượng_đài , l...  \n",
              "2  Giám_đốc , phó giám_đốc Cảng vụ đường_thuỷ nội...  \n",
              "3  9 con lợn của hộ dân ở xã Hải_Chánh ( Hải_Lăng...  \n",
              "4  Thứ_trưởng Bộ GD-ĐT Nguyễn_Văn_Phúc đã nhấn_mạ...  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_df.to_parquet(\"data/vietnews/test.parquet\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_df = pd.read_parquet(\"data/vietnews/train.parquet\")\n",
        "# val_df = pd.read_parquet(\"data/vietnews/val.parquet\")\n",
        "# test_df = pd.read_parquet(\"data/vietnews/test.parquet\")\n",
        "# test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# train_df['word_count'] = train_df['summary'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# # Plot the histogram\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.hist(train_df['word_count'], bins=100, edgecolor='black')\n",
        "# plt.title('Histogram of Number of Words in Sentences')\n",
        "# plt.xlabel('Number of Words')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1F58j028eTV"
      },
      "source": [
        "## **Warm-starting RoBERTaShared for BBC XSum**\n",
        "\n",
        "***Note***: This notebook only uses a few training, validation, and test data samples for demonstration purposes. To fine-tune an encoder-decoder model on the full training data, the user should change the training and data preprocessing parameters accordingly as highlighted by the comments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FO5ESocXvlK"
      },
      "source": [
        "### **Data Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sgTiC0rhMb7C"
      },
      "outputs": [],
      "source": [
        "# pretrained_model = \"google/mt5-small\"\n",
        "pretrained_model = \"huggingface-course/mt5-finetuned-amazon-en-es\"\n",
        "# facebook/bart-large-cnn\n",
        "# \"vinai/phobert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "U08MrUK9LcUM"
      },
      "outputs": [],
      "source": [
        "train_data =  Dataset.from_pandas(train_df)\n",
        "val_data =  Dataset.from_pandas(val_df)\n",
        "test_data =  Dataset.from_pandas(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "70bb7c0669ca4a3699ad36dfdcc10910",
            "1ba158d2f09a4c54bc647ebe77d27b60",
            "5ac8ad6eea254d369996622911a6a79e",
            "0aeb387a0f53469c8ff42e57647831d8",
            "efd6b87b93244d5ca6817ab35c385510",
            "e22006901f10483882e1a1f20f645b24",
            "01644f724526402c9f139e19b2035073",
            "7097c890712d418e9dd9c3e33873a2d5",
            "b3ddde0882d841daa3bfde43ed6e6fc9",
            "09375b2aac814adcbb51589402eb8b68",
            "cab0cd369bfa4c80b963ebd27d3e4974",
            "db0264404d934633824b5b381b31a5ac",
            "63276058881e45539d8dcd4ff2e05edd",
            "03b57581ace346d2bde4378a7c6309ca",
            "5507016090f64bb99dcbf88e14d71eda",
            "0d6a0b11ec2a4c6d975857678415f505"
          ]
        },
        "id": "yoN2q0hZUbXN",
        "outputId": "20c6562f-7358-4dc7-dada-787bede963bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 10000/10000 [00:05<00:00, 1719.03 examples/s]\n",
            "Map: 100%|██████████| 10000/10000 [00:05<00:00, 1769.79 examples/s]\n"
          ]
        }
      ],
      "source": [
        "batch_size=16  # change to 16 for full training\n",
        "\n",
        "max_input_length = 512 #1024\n",
        "max_target_length = 128 #128\n",
        "\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "    model_inputs = tokenizer(\n",
        "        batch[\"original\"],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "    labels = tokenizer(\n",
        "        batch[\"summary\"], max_length=max_target_length, truncation=True\n",
        "    )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# only use 32 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# train_data = train_data.select(range(32))\n",
        "\n",
        "train_data_batch = train_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"file\",\"original\", \"summary\"],\n",
        ")\n",
        "train_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        ")\n",
        "\n",
        "\n",
        "# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# val_data = val_data.select(range(16))\n",
        "\n",
        "val_data_batch = val_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"file\", \"original\", \"summary\"],\n",
        ")\n",
        "val_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "file        data/vietnews-master/data/train_tokenized/0661...\n",
              "original    Kết_quả xổ_số Vietlott loại_hình Power 6/55 ng...\n",
              "summary     Sau khi \" siêu độc_đắc \" 300 tỷ nổ vào đầu thá...\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sau khi \" siêu độc_đắc \" 300 tỷ nổ vào đầu tháng 5 , nhiều người còn chưa “ hoàn_hồn ” vì thất_vọng thì những giải jackpot 2 liên_tiếp có người trúng thưởng . Hôm_nay là lần thứ 3 jackpot 2 tìm được chủ_nhân may_mắn sau khi jackpot 1 bị chinh_phục . \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': [7356, 2076, 313, 259, 263, 6121, 2214, 297, 290, 11095, 3625, 313, 2787, 259, 270, 8679, 259, 272, 1544, 259, 793, 268, 355, 1687, 259, 8800, 430, 259, 261, 677, 1990, 1672, 317, 3121, 562, 2294, 262, 359, 623, 2353, 290, 334, 8881, 259, 365, 259, 7568, 394, 1075, 290, 379, 6347, 394, 1135, 259, 272, 1992, 718, 1593, 60694, 356, 615, 1079, 290, 524, 1302, 325, 885, 1672, 534, 6927, 394, 5278, 259, 260, 447, 19698, 290, 16309, 796, 259, 280, 1313, 394, 1978, 381, 60694, 356, 259, 9164, 282, 259, 1318, 562, 708, 290, 272, 4912, 1432, 290, 282, 6701, 1520, 2076, 60694, 333, 330, 933, 259, 69036, 290, 6734, 2902, 259, 260, 259, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = tokenizer(str(train_df[\"summary\"].iloc[0]))\n",
        "print(str(train_df[\"summary\"].iloc[0]))\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['▁Sau',\n",
              " '▁khi',\n",
              " '▁\"',\n",
              " '▁',\n",
              " 's',\n",
              " 'iêu',\n",
              " '▁độ',\n",
              " 'c',\n",
              " '_',\n",
              " 'đ',\n",
              " 'ắc',\n",
              " '▁\"',\n",
              " '▁300',\n",
              " '▁',\n",
              " 't',\n",
              " 'ỷ',\n",
              " '▁',\n",
              " 'n',\n",
              " 'ổ',\n",
              " '▁',\n",
              " 'và',\n",
              " 'o',\n",
              " '▁đ',\n",
              " 'ầu',\n",
              " '▁',\n",
              " 'tháng',\n",
              " '▁5',\n",
              " '▁',\n",
              " ',',\n",
              " '▁nh',\n",
              " 'iều',\n",
              " '▁người',\n",
              " '▁c',\n",
              " 'òn',\n",
              " '▁ch',\n",
              " 'ư',\n",
              " 'a',\n",
              " '▁“',\n",
              " '▁ho',\n",
              " 'àn',\n",
              " '_',\n",
              " 'h',\n",
              " 'ồn',\n",
              " '▁',\n",
              " '”',\n",
              " '▁',\n",
              " 'vì',\n",
              " '▁th',\n",
              " 'ất',\n",
              " '_',\n",
              " 'v',\n",
              " 'ọng',\n",
              " '▁th',\n",
              " 'ì',\n",
              " '▁',\n",
              " 'n',\n",
              " 'hững',\n",
              " '▁gi',\n",
              " 'ải',\n",
              " '▁jackpot',\n",
              " '▁2',\n",
              " '▁li',\n",
              " 'ên',\n",
              " '_',\n",
              " 'ti',\n",
              " 'ế',\n",
              " 'p',\n",
              " '▁có',\n",
              " '▁người',\n",
              " '▁tr',\n",
              " 'úng',\n",
              " '▁th',\n",
              " 'ưởng',\n",
              " '▁',\n",
              " '.',\n",
              " '▁H',\n",
              " 'ôm',\n",
              " '_',\n",
              " 'nay',\n",
              " '▁là',\n",
              " '▁',\n",
              " 'l',\n",
              " 'ần',\n",
              " '▁th',\n",
              " 'ứ',\n",
              " '▁3',\n",
              " '▁jackpot',\n",
              " '▁2',\n",
              " '▁',\n",
              " 'tì',\n",
              " 'm',\n",
              " '▁',\n",
              " 'được',\n",
              " '▁ch',\n",
              " 'ủ',\n",
              " '_',\n",
              " 'n',\n",
              " 'hân',\n",
              " '▁may',\n",
              " '_',\n",
              " 'm',\n",
              " 'ắn',\n",
              " '▁sau',\n",
              " '▁khi',\n",
              " '▁jackpot',\n",
              " '▁1',\n",
              " '▁b',\n",
              " 'ị',\n",
              " '▁',\n",
              " 'chinh',\n",
              " '_',\n",
              " 'ph',\n",
              " 'ục',\n",
              " '▁',\n",
              " '.',\n",
              " '▁',\n",
              " '</s>']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(train_data_batch[0][\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_data_batch[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEjb026cNC38"
      },
      "source": [
        "### **Warm-starting the Encoder-Decoder Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u98CLZiTkgzv"
      },
      "source": [
        "### **Fine-Tuning Warm-Started Encoder-Decoder Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gYzA-w96wCt"
      },
      "source": [
        "The `Seq2SeqTrainer` that can be found under [examples/seq2seq/seq2seq_trainer.py](https://github.com/huggingface/transformers/blob/master/examples/seq2seq/seq2seq_trainer.py) will be used to fine-tune a warm-started encoder-decoder model.\n",
        "\n",
        "Let's download the `Seq2SeqTrainer` code and import the module along with `TrainingArguments`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pyiwaF0noA5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-09 19:03:26.180772: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-06-09 19:03:26.211471: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-09 19:03:26.829976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nmQRT3XuHHz"
      },
      "source": [
        "We need to add some additional parameters to make `TrainingArguments` compatible with the `Seq2SeqTrainer`. Let's just copy the `dataclass` arguments as defined in [this file](https://github.com/patrickvonplaten/transformers/blob/make_seq2seq_trainer_self_contained/examples/seq2seq/finetune_trainer.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPUAgo7pxH24"
      },
      "source": [
        "Also, we need to define a function to correctly compute the ROUGE score during validation. ROUGE is a much better metric to track during training than only language modeling loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "rouge_score = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Decode generated summaries into text\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    # Decode reference summaries into text\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge_score.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract the median scores\n",
        "    result = {key: value * 100 for key, value in result.items()}\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/data/data_collator.py:646: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 412, 1878,  290,  ..., 5182, 1013,    1],\n",
              "        [ 447, 1725,  290,  ..., 2160,  300,    1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[ 7356,  2076,   313,   259,   263,  6121,  2214,   297,   290, 11095,\n",
              "          3625,   313,  2787,   259,   270,  8679,   259,   272,  1544,   259,\n",
              "           793,   268,   355,  1687,   259,  8800,   430,   259,   261,   677,\n",
              "          1990,  1672,   317,  3121,   562,  2294,   262,   359,   623,  2353,\n",
              "           290,   334,  8881,   259,   365,   259,  7568,   394,  1075,   290,\n",
              "           379,  6347,   394,  1135,   259,   272,  1992,   718,  1593, 60694,\n",
              "           356,   615,  1079,   290,   524,  1302,   325,   885,  1672,   534,\n",
              "          6927,   394,  5278,   259,   260,   447, 19698,   290, 16309,   796,\n",
              "           259,   280,  1313,   394,  1978,   381, 60694,   356,   259,  9164,\n",
              "           282,   259,  1318,   562,   708,   290,   272,  4912,  1432,   290,\n",
              "           282,  6701,  1520,  2076, 60694,   333,   330,   933,   259, 69036,\n",
              "           290,  6734,  2902,   259,   260,   259,     1],\n",
              "        [  352,  1266,   408,  5441,   290,   263,  2294,   259, 53334,   355,\n",
              "          1004,   562,  1302,   290,   270,  1262,   268,   300,  1842,   290,\n",
              "           314,  7550,   259,   270,  1242,   290,   379,  1725,  1520,  2076,\n",
              "           690, 10513,   819,  1534, 15437,   259, 18673,   290,  6815,   266,\n",
              "           259,   793,   330,  2289,   270,   290,   297, 12564,  3057,   562,\n",
              "          2902,  1672,   290,  7257,   259,  1369,   594,  3571,   796,   370,\n",
              "           317,   708,   262,  6044,   259,   260,   259,     1,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[    0,  7356,  2076,   313,   259,   263,  6121,  2214,   297,   290,\n",
              "         11095,  3625,   313,  2787,   259,   270,  8679,   259,   272,  1544,\n",
              "           259,   793,   268,   355,  1687,   259,  8800,   430,   259,   261,\n",
              "           677,  1990,  1672,   317,  3121,   562,  2294,   262,   359,   623,\n",
              "          2353,   290,   334,  8881,   259,   365,   259,  7568,   394,  1075,\n",
              "           290,   379,  6347,   394,  1135,   259,   272,  1992,   718,  1593,\n",
              "         60694,   356,   615,  1079,   290,   524,  1302,   325,   885,  1672,\n",
              "           534,  6927,   394,  5278,   259,   260,   447, 19698,   290, 16309,\n",
              "           796,   259,   280,  1313,   394,  1978,   381, 60694,   356,   259,\n",
              "          9164,   282,   259,  1318,   562,   708,   290,   272,  4912,  1432,\n",
              "           290,   282,  6701,  1520,  2076, 60694,   333,   330,   933,   259,\n",
              "         69036,   290,  6734,  2902,   259,   260,   259],\n",
              "        [    0,   352,  1266,   408,  5441,   290,   263,  2294,   259, 53334,\n",
              "           355,  1004,   562,  1302,   290,   270,  1262,   268,   300,  1842,\n",
              "           290,   314,  7550,   259,   270,  1242,   290,   379,  1725,  1520,\n",
              "          2076,   690, 10513,   819,  1534, 15437,   259, 18673,   290,  6815,\n",
              "           266,   259,   793,   330,  2289,   270,   290,   297, 12564,  3057,\n",
              "           562,  2902,  1672,   290,  7257,   259,  1369,   594,  3571,   796,\n",
              "           370,   317,   708,   262,  6044,   259,   260,   259,     1,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0]])}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = [train_data_batch[i] for i in range(2)]\n",
        "data_collator(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ik4hZb2yV-b"
      },
      "source": [
        "Cool! Finally, we start training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "LAaTxUpdzshF",
        "outputId": "7e103b00-0ac7-41c0-84a4-884932474b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logging_steps 625\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1142' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1142/6250 1:55:03 < 8:35:31, 0.17 it/s, Epoch 1.83/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.778100</td>\n",
              "      <td>1.839109</td>\n",
              "      <td>28.502400</td>\n",
              "      <td>11.271700</td>\n",
              "      <td>22.108000</td>\n",
              "      <td>22.436100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# set training arguments - these params are not really tuned, feel free to change\n",
        "logging_steps = min(2000,len(train_data_batch) // batch_size)\n",
        "print(\"logging_steps\", logging_steps)\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir= OUTPUT_DIR,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=1e-3,\n",
        "    # do_train=True,\n",
        "    # do_eval=True,\n",
        "    logging_steps=logging_steps,  # set to 2000 for full training\n",
        "    save_steps=500,  # set to 500 for full training\n",
        "    eval_steps=75,  # set to 7500 for full training\n",
        "    warmup_steps=3000,  # set to 3000 for full training\n",
        "    num_train_epochs=10, #uncomment for full training\n",
        "    overwrite_output_dir=True,\n",
        "    optim='adafactor',\n",
        "    save_total_limit=3,\n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data_batch,\n",
        "    eval_dataset=val_data_batch,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0%|          | 16.4k/1.20G [00:00<3:24:45, 97.7kB/s]\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "events.out.tfevents.1717932463.DESKTOP-H2CRQMR.655616.0: 100%|██████████| 5.39k/5.39k [00:00<00:00, 12.7kB/s]\n",
            "events.out.tfevents.1717932647.DESKTOP-H2CRQMR.656333.0: 100%|██████████| 5.39k/5.39k [00:00<00:00, 14.1kB/s]\n",
            "events.out.tfevents.1717932560.DESKTOP-H2CRQMR.655616.1: 100%|██████████| 5.39k/5.39k [00:00<00:00, 13.3kB/s]\n",
            "events.out.tfevents.1717932716.DESKTOP-H2CRQMR.656333.1: 100%|██████████| 12.3k/12.3k [00:00<00:00, 27.2kB/s]\n",
            "training_args.bin: 100%|██████████| 5.24k/5.24k [00:00<00:00, 5.92kB/s]\n",
            "model.safetensors: 100%|██████████| 1.20G/1.20G [01:20<00:00, 14.8MB/s]\n",
            "\n",
            "Upload 6 LFS files: 100%|██████████| 6/6 [01:21<00:00, 13.59s/it]\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7854KKs6EY4x"
      },
      "outputs": [],
      "source": [
        "# !gsutil -m cp -r '/content/training/*' 'gs://kaggle-vbdi-test/training_Data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwQIEhKOrJpl"
      },
      "source": [
        "### **Evaluation**\n",
        "\n",
        "Awesome, we finished training our dummy model. Let's now evaluated the model on the test data. We make use of the dataset's handy `.map()` function to generate a summary of each sample of the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0ef7f4e43319429d9277d55c83cb084d",
            "ab543b6ef5b34ed4acb85fd25304ed75",
            "825d4b325e9b45859e808cd6b14fdd42",
            "dd0bdf658c6d4c0cb0a091129ecbebb0",
            "f7c296a0b8a84ee3be45c92edb6aad21",
            "e21d97b40ffa43668b9962c5d771debb",
            "a4898ec38618401396928eee2c4f9926",
            "3598a3c015a64c20be134cf4d2e7fbbe"
          ]
        },
        "id": "oOoSrwWarJAC",
        "outputId": "67b60b74-c47c-4718-82a7-072f85a32c4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Map:   0%|          | 0/100 [00:00<?, ? examples/s]/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Map: 100%|██████████| 100/100 [00:02<00:00, 39.38 examples/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model, use_fast=False)\n",
        "\n",
        "# model = EncoderDecoderModel.from_pretrained(OUTPUT_DIR + \"/checkpoint-4000\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"my_fine_tuned_t5_small_model\")\n",
        "\n",
        "model.to(\"cuda\")\n",
        "\n",
        "# test_data = datasets.load_dataset(\"xsum\", split=\"test\")\n",
        "\n",
        "batch_size = 16  # change to 64 for full evaluation\n",
        "\n",
        "# map data correctly\n",
        "def generate_summary(batch):\n",
        "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
        "    inputs = tokenizer(batch[\"original\"], padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(\"cuda\")\n",
        "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # all special tokens including will be removed\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    batch[\"pred\"] = output_str\n",
        "\n",
        "    return batch\n",
        "\n",
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"original\"])\n",
        "\n",
        "pred_str = results[\"pred\"]\n",
        "label_str = results[\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHl8NMjEiTb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rouge1': 0.24678802420560875,\n",
              " 'rouge2': 0.07196920590108752,\n",
              " 'rougeL': 0.18980672691927808,\n",
              " 'rougeLsum': 0.18913783746837431}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rouge_output = rouge_score.compute(predictions=pred_str, references=label_str, use_stemmer=True)\n",
        "rouge_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13HUSVh4-CAk",
        "outputId": "96f5c2c3-439c-41f5-e757-02e9aa568c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rouge1\n",
            "0.24678802420560875\n",
            "rouge2\n",
            "0.07196920590108752\n",
            "rougeL\n",
            "0.18980672691927808\n",
            "rougeLsum\n",
            "0.18913783746837431\n"
          ]
        }
      ],
      "source": [
        "for key,value in rouge_output.items():\n",
        "  print(key)\n",
        "  print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8R5CclwUGuC",
        "outputId": "9b53d98d-8d04-49b5-c55a-d47530564398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction:  Trong bối_cảnh 10 ngày_trước, lần đ\n",
            "Truth:  Giám_đốc hai sở Văn_hoá Thể_thao TP Đà_Nẵng và tỉnh Thừa_Thiên_Huế thống_nhất các giải_pháp để bảo_vệ Hải_Vân quan , sau 20 năm hoang_phế vì chồng lấn địa_giới . \n",
            "Content:  Chiều 24/4 , lần đầu_tiên lãnh_đạo ngành văn_hoá của Đà_Nẵng và Thừa_Thiên_Huế cùng lên đỉnh Hải_Vân quan để bàn cách cứu di_tích đang bị hoang_phế suốt thời_gian dài . Cuộc họp diễn ra ngay bên quán nước nhỏ của người_dân buôn_bán trên đỉnh đèo . Buổi làm_việc được nhiều người mong_chờ , diễn ra trong bối_cảnh 10 ngày_trước , Bộ_trưởng Văn_hoá Thể_thao và Du_lịch Nguyễn_Ngọc_Thiện ký quyết_định công_nhận Hải_Vân quan ( nằm trên đỉnh đèo Hải_Vân thuộc thị_trấn Lăng_Cô , huyện Phú_Lộc , tỉnh Thừa_Thiên_Huế và phường Hoà_Hiệp_Bắc , quận Liên_Chiểu , Đà_Nẵng ) là di_tích cấp quốc_gia . Ông Phan_Tiến_Dũng , Giám_đốc Sở Văn_hoá Thừa_Thiên_Huế thừa_nhận thời_gian qua đã thiếu quản_lý với Hải_Vân quan . 20 năm trước , khi đang còn công_tác tại Trung_tâm Bảo_tồn di_tích cố_đô Huế , chính ông đã làm một bộ hồ_sơ xin công_nhận di_tích lịch_sử cấp quốc_gia , nhưng hai địa_phương không thống_nhất được , dẫn đến suốt một thời_gian dài Hải_Vân quan bị bỏ quên . Việc cần làm ngay lúc này , theo ông Dũng là ngành văn_hoá hai địa_phương phải tham_mưu cho UBND tỉnh Thừa_Thiên_Huế và TP Đà_Nẵng chỉ_đạo công_tác cắm mốc khoanh vùng bảo_vệ di_tích theo hồ_sơ khoa_học ; dựng biển giới_thiệu về di_tích ( tiếng Việt và tiếng Anh ) và bản_đồ khoanh vùng bảo_vệ di_tích ; ban_hành quyết_định phân_cấp quản_lý di_tích . Hải_Vân quan đang bị xuống_cấp , nhếch_nhác . Nhìn vào thực_trạng nhếch_nhác của Hải_Vân quan , ông Dũng đề_xuất xin ý_kiến các chuyên_gia , nhà_nghiên_cứu để di_dời , loại_bỏ các bộ_phận hạng_mục công_trình không liên_quan đến các yếu_tố gốc của di_tích , như vọng gác phía trên cổng Hải_Vân quan , các lô_cốt xây trên đất di_tích hay những nền_móng công_trình xây_dựng dân_sinh đã bị phá dỡ … Trước khi tôn_tạo hay xây_dựng bãi giữ xe , nhà_vệ_sinh công_cộng , Sở Tài_nguyên Môi_trường hai địa_phương cần thu_hồi đất lâm_nghiệp để cấp quyền sử_dụng đất mới . Giám_đốc Sở Văn_hoá Thể_thao TP Đà_Nẵng , ông Huỳnh_Văn_Hùng thống_nhất với những đề_xuất của phía Huế . Ông nói , di_tích lịch_sử quốc_gia thì Huế và Đà_Nẵng đều có rất nhiều , riêng Đà_Nẵng là hơn 20 , nhưng Hải_Vân quan là di_tích quốc_gia đặc_biệt , nằm chính giữa ở hai địa_phương . Do ranh_giới chưa được xác_định rõ_ràng nên kéo_dài đến nay mới làm hồ_sơ công_nhận . Trải qua nhiều cuộc họp , lúc ở Đà_Nẵng , khi ở Huế , thậm_chí ra tận Hà_Nội , hai địa_phương mới thống_nhất một bộ hồ_sơ trình Bộ_trưởng Văn_hoá ký . \" Đây là di_tích thể_hiện sự phối_hợp , gắn_kết của hai địa_phương và có_thể xem là biểu_tượng của tình đoàn_kết , nên cần tập_trung để làm \" , ông Hùng nói và đề_nghị Sở Tài_nguyên Môi_trường hai địa_phương giúp_việc cắm mốc khoanh vùng bảo_vệ . Theo ông Hùng , qua 2 cuộc chiến_tranh nên nguyên_trạng Hải_Vân quan không còn . Có nhiều công_trình và lô_cốt chồng lên di_tích , nên về lâu_dài bằng mọi cách trả lại nguyên_trạng . Những công_trình không phù_hợp trên đất hai địa_phương quản_lý thì tháo_dỡ , còn nằm trên đất quốc_phòng thì làm văn_bản đề_nghị Quân_khu 4 và Quân_khu 5 cho_phép giải_toả . \" Chúng_ta cần lập quy_hoạch tổng_thể và chi_tiết để tu_bổ Hải_Vân quan . Hiện_nay ở một_số nơi khi trùng_tu dư_luận hoan_nghênh và đánh_giá cao , nhưng cũng có di_tích làm xong thì bị méo_mó , biến_dạng nên bị phản_ứng . Sau_này khi Huế và Đà_Nẵng tu_bổ Hải_Vân quan sẽ mời các nhà_nghiên_cứu cho ý_kiến , đồng_thời nghiên_cứu kỹ_lưỡng trước khi làm \" , ông Hùng nói . Ông đề_xuất những cuộc gặp tiếp_theo để xây_dựng cơ_chế phối_hợp dựa trên Luật di_sản văn_hoá , và \" mỗi Sở cử ra một nhóm chuyên_viên phối_hợp xây_dựng cơ_chế quản_lý \" . Đồng_thuận ý_tưởng này , ông Dũng nói nhóm chuyên_viên của hai sở sẽ được lập thành một tổ và tuyệt_đối khi làm_việc không được phân_biệt , đùn_đẩy giới_hạn thuộc Huế hay Đà_Nẵng . \" Không_thể phân_biệt khu_vực thuộc bên này , hay bên kia mà để buông_lỏng quản_lý . Chúng_ta cần rút kinh_nghiệm vì vừa_qua có bài_học Hoành_Sơn quan giữa Hà_Tĩnh và Quảng_Bình , cả hai địa_phương cùng công_nhận di_tích và cuối_cùng cả hai bên đều thả tay , hoặc ở một_số nơi khác \" , ông Dũng nói . Về góc_độ phát_triển du_lịch ở Hải_Vân quan , do hai địa_phương đã tách Sở Du_lịch , nên ông Hùng đề_nghị ngành du_lịch tuyệt_đối không được bất_chấp làm du_lịch mà không đi_đôi với bảo_vệ , bảo_tồn di_tích . \" Nhất_cử_nhất_động gì ở Hải_Vân quan phải có sự thống_nhất của hai địa_phương , trên tinh_thần Luật di_sản văn_hoá . Làm_sao để đây là di_tích văn_hoá có giá_trị và từ giá_trị đó sẽ thu_hút khách du_lịch \" , ông nhấn_mạnh . Kết_thúc buổi làm_việc , Giám_đốc Sở Văn_hoá Huế và Đà_Nẵng cùng đi khảo_sát Hải_Vân quan . Hai bên thống_nhất sẽ cho tháo_dỡ một_số hạng_mục đang làm nhếch_nhác di_tích này , như hàng_rào tạm_bợ , bảng cấm bán hàng rong , tấm biển chỉ_dẫn đường cứu_hộ bằng bê_tông vốn hết tác_dụng và che_khuất Thiên_hạ đệ nhất hùng quan , làm lại lối đi bằng gạch ... Trước lúc ra về , hai lãnh_đạo vốn từng học chung một lớp đứng bắt_tay nhau ngay dưới cổng Hải_Vân quan . \" Chúng_tôi chờ_đợi cái bắt_tay này từ rất lâu rồi \" , ông Hùng nói trong tiếng vỗ_tay của các sở , ngành của Huế và Đà_Nẵng . Nguyễn_Đông   Hải_Vân quan đang bị xuống_cấp , nhếch_nhác . Lần đầu_tiên lãnh_đạo ngành văn_hoá hai địa_phương cùng khảo_sát thực_tế Hải_Vân quan . Ông Huỳnh_Hùng ( bía trái ) và ông Phan_Tiến_Dũng bắt_tay để cùng bảo_vệ Hải_Vân quan . \n"
          ]
        }
      ],
      "source": [
        "i = 27\n",
        "print('Prediction: ',pred_str[i])\n",
        "print('Truth: ',label_str[i])\n",
        "print('Content: ',test_data[i]['original'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n4kLAIQSr5g2",
        "outputId": "b4d745cb-4599-43cf-e8c0-1ec9e5fdba6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'data/vietnews-master/data/test_tokenized/000966.txt.seg'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[0]['file']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "testing-huggingface",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01644f724526402c9f139e19b2035073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03b57581ace346d2bde4378a7c6309ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09375b2aac814adcbb51589402eb8b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aeb387a0f53469c8ff42e57647831d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7097c890712d418e9dd9c3e33873a2d5",
            "placeholder": "​",
            "style": "IPY_MODEL_01644f724526402c9f139e19b2035073",
            "value": " 6589/6589 [02:35&lt;00:00, 42.40ba/s]"
          }
        },
        "0d6a0b11ec2a4c6d975857678415f505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef7f4e43319429d9277d55c83cb084d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_825d4b325e9b45859e808cd6b14fdd42",
              "IPY_MODEL_dd0bdf658c6d4c0cb0a091129ecbebb0"
            ],
            "layout": "IPY_MODEL_ab543b6ef5b34ed4acb85fd25304ed75"
          }
        },
        "1ba158d2f09a4c54bc647ebe77d27b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3598a3c015a64c20be134cf4d2e7fbbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5507016090f64bb99dcbf88e14d71eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ac8ad6eea254d369996622911a6a79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e22006901f10483882e1a1f20f645b24",
            "max": 6589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efd6b87b93244d5ca6817ab35c385510",
            "value": 6589
          }
        },
        "63276058881e45539d8dcd4ff2e05edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "7097c890712d418e9dd9c3e33873a2d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70bb7c0669ca4a3699ad36dfdcc10910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ac8ad6eea254d369996622911a6a79e",
              "IPY_MODEL_0aeb387a0f53469c8ff42e57647831d8"
            ],
            "layout": "IPY_MODEL_1ba158d2f09a4c54bc647ebe77d27b60"
          }
        },
        "825d4b325e9b45859e808cd6b14fdd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21d97b40ffa43668b9962c5d771debb",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7c296a0b8a84ee3be45c92edb6aad21",
            "value": 22
          }
        },
        "a4898ec38618401396928eee2c4f9926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab543b6ef5b34ed4acb85fd25304ed75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ddde0882d841daa3bfde43ed6e6fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cab0cd369bfa4c80b963ebd27d3e4974",
              "IPY_MODEL_db0264404d934633824b5b381b31a5ac"
            ],
            "layout": "IPY_MODEL_09375b2aac814adcbb51589402eb8b68"
          }
        },
        "cab0cd369bfa4c80b963ebd27d3e4974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b57581ace346d2bde4378a7c6309ca",
            "max": 1416,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63276058881e45539d8dcd4ff2e05edd",
            "value": 1416
          }
        },
        "db0264404d934633824b5b381b31a5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d6a0b11ec2a4c6d975857678415f505",
            "placeholder": "​",
            "style": "IPY_MODEL_5507016090f64bb99dcbf88e14d71eda",
            "value": " 1416/1416 [00:44&lt;00:00, 31.76ba/s]"
          }
        },
        "dd0bdf658c6d4c0cb0a091129ecbebb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3598a3c015a64c20be134cf4d2e7fbbe",
            "placeholder": "​",
            "style": "IPY_MODEL_a4898ec38618401396928eee2c4f9926",
            "value": " 22/22 [29:59&lt;00:00, 81.81s/ba]"
          }
        },
        "e21d97b40ffa43668b9962c5d771debb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e22006901f10483882e1a1f20f645b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd6b87b93244d5ca6817ab35c385510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "f7c296a0b8a84ee3be45c92edb6aad21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
