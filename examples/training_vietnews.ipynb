{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/examples\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "    print(file_path)\n",
        "except:\n",
        "    file_path = os.path.abspath('')\n",
        "    os.chdir(os.path.dirname(file_path))\n",
        "    print(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3_GCCIaj7ulj"
      },
      "outputs": [],
      "source": [
        "# !wget 'https://github.com/ThanhChinhBK/vietnews/archive/master.zip'\n",
        "# !unzip 'master.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TZYjioRkKviO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "import concurrent.futures\n",
        "from datasets import *\n",
        "import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# from vncorenlp import VnCoreNLP\n",
        "import torch \n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Gx4Vg4cbEUJ_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "OUTPUT_DIR = 'vietnamese_mt5_summary_model'\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/mrzaizai2k/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IteMtlc58-y"
      },
      "source": [
        "## Processing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UVkc5HmK6Bdd"
      },
      "outputs": [],
      "source": [
        "def listPaths(path):\n",
        "  pathfiles = list()\n",
        "  for pathfile in glob.glob(path):\n",
        "    pathfiles.append(pathfile)\n",
        "  return pathfiles\n",
        "\n",
        "train_paths = listPaths('data/vietnews-master/data/train_tokenized/*')\n",
        "val_paths = listPaths('data/vietnews-master/data/val_tokenized/*')\n",
        "test_paths = listPaths('data/vietnews-master/data/test_tokenized/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YZ8pgIYN7zSW"
      },
      "outputs": [],
      "source": [
        "def read_content(pathfile):\n",
        "    \"\"\"\n",
        "    Input: Path of txt file\n",
        "    Output: A dictionary has keys 'original' and 'summary'\n",
        "    \"\"\"\n",
        "    with open(pathfile) as f:\n",
        "      rows  = f.readlines()\n",
        "      original = ' '.join(''.join(rows[4:]).split('\\n'))\n",
        "      summary = ' '.join(rows[2].split('\\n'))\n",
        "            \n",
        "    return {'file' : pathfile,\n",
        "              'original': original, \n",
        "              'summary': summary}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_716GF2iDTcD",
        "outputId": "07268442-c69d-4818-a69a-2f9200044eed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'file': 'data/vietnews-master/data/train_tokenized/006157.txt.seg',\n",
              " 'original': 'Tập 4 Thần_tượng Âm_nhạc nhí - Vietnam_Idol_Kids 2017 lên sóng tối 2/6 với màn tranh tài của top 8 thí_sinh nữ để lựa_chọn ra 5 tấm vé vào tiếp vòng trong . Trong đó , 3 giám_khảo Isaac - Văn_Mai_Hương - Bích_Phương được quyền lựa_chọn 3 thí_sinh . 2 thí_sinh còn lại sẽ do các giám_khảo khách mời quyết_định . Nữ ca_sĩ Văn_Mai_Hương xúc_động : “ Cô có may_mắn năm nay ngồi ở vị_trí ban giám_khảo , may_mắn hơn là được gặp con . Mỗi khi gặp Hiền , cô tự thấy bản_thân cô rất kém , bởi có lúc cô không trân_trọng cũng như không tin vào bản_thân ... Cảm_ơn con , bởi đôi_khi có những cái cô không bằng con được , đó là sự lạc_quan . Và cô tin , còn rất nhiều người phải học đức_tính lạc_quan này của Hiền . Con hát rất là hay ” . Đồng_tình với ý_kiến của đồng_nghiệp , Bích_Phương cũng xúc_động chia_sẻ : “ Giọt nước_mắt dành cho con là sự khâm_phục chứ không phải là thương_cảm . Cô chưa bao_giờ thấy con buồn . Từ lúc xuất_hiện , lúc_nào con cũng cười thôi . Cô nghĩ là ngoài tinh_thần lạc_quan của Hiền làm cho mọi người phải khâm_phục nên mọi người mới khóc … Bên cạnh đó , con còn có giọng hát rất hay . Con rất xứng_đáng được sâu vào vòng trong ” . Hà_Linh  ',\n",
              " 'summary': 'Trên sân_khấu Vietnam_Idol_Kids 2017 , cô_bé khiếm_thị Minh_Hiền khiến giám_khảo và khán_giả lặng người khi tiết_lộ ước_mơ của bản_thân . '}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_content(train_paths[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Wm5kLJD_840E"
      },
      "outputs": [],
      "source": [
        "def get_dataframe(pathfiles):\n",
        "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "      data = executor.map(read_content, pathfiles)\n",
        "    \n",
        "    # Make blank dataframe\n",
        "    data_df = list()\n",
        "    for d in data:\n",
        "      data_df.append(d)\n",
        "    data_df = pd.DataFrame(data_df)\n",
        "    data_df.dropna(inplace = True)\n",
        "    data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    return data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d4c0pl5BAl3f"
      },
      "outputs": [],
      "source": [
        "train_df = get_dataframe(train_paths[:10000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DgMgMnisA0cf"
      },
      "outputs": [],
      "source": [
        "val_df = get_dataframe(val_paths[:10000])\n",
        "test_df = get_dataframe(test_paths[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>original</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/01796...</td>\n",
              "      <td>Theo Hãng tin Bloomberg , trong bối_cảnh nhiều...</td>\n",
              "      <td>Nguồn_tin của hãng Bloomberg cho_biết cơ_quan_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/00547...</td>\n",
              "      <td>Hãng tin Reuters cho_biết đã đọc được 1 bản bá...</td>\n",
              "      <td>Tổng_thống Robert_Mugabe từng là tượng_đài , l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/01964...</td>\n",
              "      <td>Tối 7/6 , Thành_uỷ Đà_Nẵng cho_biết đã chỉ_đạo...</td>\n",
              "      <td>Giám_đốc , phó giám_đốc Cảng vụ đường_thuỷ nội...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/01912...</td>\n",
              "      <td>Ngày 28/3 , UBND huyện Hải_Lăng , Quảng_Trị cô...</td>\n",
              "      <td>9 con lợn của hộ dân ở xã Hải_Chánh ( Hải_Lăng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/00591...</td>\n",
              "      <td>' Hai chân ' ... bị lệch Thứ_trưởng Nguyễn_Văn...</td>\n",
              "      <td>Thứ_trưởng Bộ GD-ĐT Nguyễn_Văn_Phúc đã nhấn_mạ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                file  \\\n",
              "0  data/vietnews-master/data/test_tokenized/01796...   \n",
              "1  data/vietnews-master/data/test_tokenized/00547...   \n",
              "2  data/vietnews-master/data/test_tokenized/01964...   \n",
              "3  data/vietnews-master/data/test_tokenized/01912...   \n",
              "4  data/vietnews-master/data/test_tokenized/00591...   \n",
              "\n",
              "                                            original  \\\n",
              "0  Theo Hãng tin Bloomberg , trong bối_cảnh nhiều...   \n",
              "1  Hãng tin Reuters cho_biết đã đọc được 1 bản bá...   \n",
              "2  Tối 7/6 , Thành_uỷ Đà_Nẵng cho_biết đã chỉ_đạo...   \n",
              "3  Ngày 28/3 , UBND huyện Hải_Lăng , Quảng_Trị cô...   \n",
              "4  ' Hai chân ' ... bị lệch Thứ_trưởng Nguyễn_Văn...   \n",
              "\n",
              "                                             summary  \n",
              "0  Nguồn_tin của hãng Bloomberg cho_biết cơ_quan_...  \n",
              "1  Tổng_thống Robert_Mugabe từng là tượng_đài , l...  \n",
              "2  Giám_đốc , phó giám_đốc Cảng vụ đường_thuỷ nội...  \n",
              "3  9 con lợn của hộ dân ở xã Hải_Chánh ( Hải_Lăng...  \n",
              "4  Thứ_trưởng Bộ GD-ĐT Nguyễn_Văn_Phúc đã nhấn_mạ...  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_df.to_parquet(\"data/vietnews/test.parquet\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_df = pd.read_parquet(\"data/vietnews/train.parquet\")\n",
        "# val_df = pd.read_parquet(\"data/vietnews/val.parquet\")\n",
        "# test_df = pd.read_parquet(\"data/vietnews/test.parquet\")\n",
        "# test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# train_df['word_count'] = train_df['summary'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# # Plot the histogram\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.hist(train_df['word_count'], bins=100, edgecolor='black')\n",
        "# plt.title('Histogram of Number of Words in Sentences')\n",
        "# plt.xlabel('Number of Words')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1F58j028eTV"
      },
      "source": [
        "## **Warm-starting RoBERTaShared for BBC XSum**\n",
        "\n",
        "***Note***: This notebook only uses a few training, validation, and test data samples for demonstration purposes. To fine-tune an encoder-decoder model on the full training data, the user should change the training and data preprocessing parameters accordingly as highlighted by the comments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FO5ESocXvlK"
      },
      "source": [
        "### **Data Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sgTiC0rhMb7C"
      },
      "outputs": [],
      "source": [
        "# pretrained_model = \"google/mt5-small\"\n",
        "pretrained_model = \"huggingface-course/mt5-finetuned-amazon-en-es\"\n",
        "# facebook/bart-large-cnn\n",
        "# \"vinai/phobert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "U08MrUK9LcUM"
      },
      "outputs": [],
      "source": [
        "train_data =  Dataset.from_pandas(train_df)\n",
        "val_data =  Dataset.from_pandas(val_df)\n",
        "test_data =  Dataset.from_pandas(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "70bb7c0669ca4a3699ad36dfdcc10910",
            "1ba158d2f09a4c54bc647ebe77d27b60",
            "5ac8ad6eea254d369996622911a6a79e",
            "0aeb387a0f53469c8ff42e57647831d8",
            "efd6b87b93244d5ca6817ab35c385510",
            "e22006901f10483882e1a1f20f645b24",
            "01644f724526402c9f139e19b2035073",
            "7097c890712d418e9dd9c3e33873a2d5",
            "b3ddde0882d841daa3bfde43ed6e6fc9",
            "09375b2aac814adcbb51589402eb8b68",
            "cab0cd369bfa4c80b963ebd27d3e4974",
            "db0264404d934633824b5b381b31a5ac",
            "63276058881e45539d8dcd4ff2e05edd",
            "03b57581ace346d2bde4378a7c6309ca",
            "5507016090f64bb99dcbf88e14d71eda",
            "0d6a0b11ec2a4c6d975857678415f505"
          ]
        },
        "id": "yoN2q0hZUbXN",
        "outputId": "20c6562f-7358-4dc7-dada-787bede963bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 10000/10000 [00:05<00:00, 1719.03 examples/s]\n",
            "Map: 100%|██████████| 10000/10000 [00:05<00:00, 1769.79 examples/s]\n"
          ]
        }
      ],
      "source": [
        "batch_size=16  # change to 16 for full training\n",
        "\n",
        "max_input_length = 512 #1024\n",
        "max_target_length = 128 #128\n",
        "\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "    model_inputs = tokenizer(\n",
        "        batch[\"original\"],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "    labels = tokenizer(\n",
        "        batch[\"summary\"], max_length=max_target_length, truncation=True\n",
        "    )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# only use 32 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# train_data = train_data.select(range(32))\n",
        "\n",
        "train_data_batch = train_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"file\",\"original\", \"summary\"],\n",
        ")\n",
        "train_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        ")\n",
        "\n",
        "\n",
        "# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# val_data = val_data.select(range(16))\n",
        "\n",
        "val_data_batch = val_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"file\", \"original\", \"summary\"],\n",
        ")\n",
        "val_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "file        data/vietnews-master/data/train_tokenized/0661...\n",
              "original    Kết_quả xổ_số Vietlott loại_hình Power 6/55 ng...\n",
              "summary     Sau khi \" siêu độc_đắc \" 300 tỷ nổ vào đầu thá...\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sau khi \" siêu độc_đắc \" 300 tỷ nổ vào đầu tháng 5 , nhiều người còn chưa “ hoàn_hồn ” vì thất_vọng thì những giải jackpot 2 liên_tiếp có người trúng thưởng . Hôm_nay là lần thứ 3 jackpot 2 tìm được chủ_nhân may_mắn sau khi jackpot 1 bị chinh_phục . \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': [7356, 2076, 313, 259, 263, 6121, 2214, 297, 290, 11095, 3625, 313, 2787, 259, 270, 8679, 259, 272, 1544, 259, 793, 268, 355, 1687, 259, 8800, 430, 259, 261, 677, 1990, 1672, 317, 3121, 562, 2294, 262, 359, 623, 2353, 290, 334, 8881, 259, 365, 259, 7568, 394, 1075, 290, 379, 6347, 394, 1135, 259, 272, 1992, 718, 1593, 60694, 356, 615, 1079, 290, 524, 1302, 325, 885, 1672, 534, 6927, 394, 5278, 259, 260, 447, 19698, 290, 16309, 796, 259, 280, 1313, 394, 1978, 381, 60694, 356, 259, 9164, 282, 259, 1318, 562, 708, 290, 272, 4912, 1432, 290, 282, 6701, 1520, 2076, 60694, 333, 330, 933, 259, 69036, 290, 6734, 2902, 259, 260, 259, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = tokenizer(str(train_df[\"summary\"].iloc[0]))\n",
        "print(str(train_df[\"summary\"].iloc[0]))\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['▁Sau',\n",
              " '▁khi',\n",
              " '▁\"',\n",
              " '▁',\n",
              " 's',\n",
              " 'iêu',\n",
              " '▁độ',\n",
              " 'c',\n",
              " '_',\n",
              " 'đ',\n",
              " 'ắc',\n",
              " '▁\"',\n",
              " '▁300',\n",
              " '▁',\n",
              " 't',\n",
              " 'ỷ',\n",
              " '▁',\n",
              " 'n',\n",
              " 'ổ',\n",
              " '▁',\n",
              " 'và',\n",
              " 'o',\n",
              " '▁đ',\n",
              " 'ầu',\n",
              " '▁',\n",
              " 'tháng',\n",
              " '▁5',\n",
              " '▁',\n",
              " ',',\n",
              " '▁nh',\n",
              " 'iều',\n",
              " '▁người',\n",
              " '▁c',\n",
              " 'òn',\n",
              " '▁ch',\n",
              " 'ư',\n",
              " 'a',\n",
              " '▁“',\n",
              " '▁ho',\n",
              " 'àn',\n",
              " '_',\n",
              " 'h',\n",
              " 'ồn',\n",
              " '▁',\n",
              " '”',\n",
              " '▁',\n",
              " 'vì',\n",
              " '▁th',\n",
              " 'ất',\n",
              " '_',\n",
              " 'v',\n",
              " 'ọng',\n",
              " '▁th',\n",
              " 'ì',\n",
              " '▁',\n",
              " 'n',\n",
              " 'hững',\n",
              " '▁gi',\n",
              " 'ải',\n",
              " '▁jackpot',\n",
              " '▁2',\n",
              " '▁li',\n",
              " 'ên',\n",
              " '_',\n",
              " 'ti',\n",
              " 'ế',\n",
              " 'p',\n",
              " '▁có',\n",
              " '▁người',\n",
              " '▁tr',\n",
              " 'úng',\n",
              " '▁th',\n",
              " 'ưởng',\n",
              " '▁',\n",
              " '.',\n",
              " '▁H',\n",
              " 'ôm',\n",
              " '_',\n",
              " 'nay',\n",
              " '▁là',\n",
              " '▁',\n",
              " 'l',\n",
              " 'ần',\n",
              " '▁th',\n",
              " 'ứ',\n",
              " '▁3',\n",
              " '▁jackpot',\n",
              " '▁2',\n",
              " '▁',\n",
              " 'tì',\n",
              " 'm',\n",
              " '▁',\n",
              " 'được',\n",
              " '▁ch',\n",
              " 'ủ',\n",
              " '_',\n",
              " 'n',\n",
              " 'hân',\n",
              " '▁may',\n",
              " '_',\n",
              " 'm',\n",
              " 'ắn',\n",
              " '▁sau',\n",
              " '▁khi',\n",
              " '▁jackpot',\n",
              " '▁1',\n",
              " '▁b',\n",
              " 'ị',\n",
              " '▁',\n",
              " 'chinh',\n",
              " '_',\n",
              " 'ph',\n",
              " 'ục',\n",
              " '▁',\n",
              " '.',\n",
              " '▁',\n",
              " '</s>']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(train_data_batch[0][\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_data_batch[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEjb026cNC38"
      },
      "source": [
        "### **Warm-starting the Encoder-Decoder Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u98CLZiTkgzv"
      },
      "source": [
        "### **Fine-Tuning Warm-Started Encoder-Decoder Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gYzA-w96wCt"
      },
      "source": [
        "The `Seq2SeqTrainer` that can be found under [examples/seq2seq/seq2seq_trainer.py](https://github.com/huggingface/transformers/blob/master/examples/seq2seq/seq2seq_trainer.py) will be used to fine-tune a warm-started encoder-decoder model.\n",
        "\n",
        "Let's download the `Seq2SeqTrainer` code and import the module along with `TrainingArguments`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pyiwaF0noA5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-09 19:03:26.180772: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-06-09 19:03:26.211471: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-09 19:03:26.829976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nmQRT3XuHHz"
      },
      "source": [
        "We need to add some additional parameters to make `TrainingArguments` compatible with the `Seq2SeqTrainer`. Let's just copy the `dataclass` arguments as defined in [this file](https://github.com/patrickvonplaten/transformers/blob/make_seq2seq_trainer_self_contained/examples/seq2seq/finetune_trainer.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPUAgo7pxH24"
      },
      "source": [
        "Also, we need to define a function to correctly compute the ROUGE score during validation. ROUGE is a much better metric to track during training than only language modeling loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "rouge_score = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Decode generated summaries into text\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    # Decode reference summaries into text\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge_score.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract the median scores\n",
        "    result = {key: value * 100 for key, value in result.items()}\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/data/data_collator.py:646: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 412, 1878,  290,  ..., 5182, 1013,    1],\n",
              "        [ 447, 1725,  290,  ..., 2160,  300,    1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[ 7356,  2076,   313,   259,   263,  6121,  2214,   297,   290, 11095,\n",
              "          3625,   313,  2787,   259,   270,  8679,   259,   272,  1544,   259,\n",
              "           793,   268,   355,  1687,   259,  8800,   430,   259,   261,   677,\n",
              "          1990,  1672,   317,  3121,   562,  2294,   262,   359,   623,  2353,\n",
              "           290,   334,  8881,   259,   365,   259,  7568,   394,  1075,   290,\n",
              "           379,  6347,   394,  1135,   259,   272,  1992,   718,  1593, 60694,\n",
              "           356,   615,  1079,   290,   524,  1302,   325,   885,  1672,   534,\n",
              "          6927,   394,  5278,   259,   260,   447, 19698,   290, 16309,   796,\n",
              "           259,   280,  1313,   394,  1978,   381, 60694,   356,   259,  9164,\n",
              "           282,   259,  1318,   562,   708,   290,   272,  4912,  1432,   290,\n",
              "           282,  6701,  1520,  2076, 60694,   333,   330,   933,   259, 69036,\n",
              "           290,  6734,  2902,   259,   260,   259,     1],\n",
              "        [  352,  1266,   408,  5441,   290,   263,  2294,   259, 53334,   355,\n",
              "          1004,   562,  1302,   290,   270,  1262,   268,   300,  1842,   290,\n",
              "           314,  7550,   259,   270,  1242,   290,   379,  1725,  1520,  2076,\n",
              "           690, 10513,   819,  1534, 15437,   259, 18673,   290,  6815,   266,\n",
              "           259,   793,   330,  2289,   270,   290,   297, 12564,  3057,   562,\n",
              "          2902,  1672,   290,  7257,   259,  1369,   594,  3571,   796,   370,\n",
              "           317,   708,   262,  6044,   259,   260,   259,     1,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[    0,  7356,  2076,   313,   259,   263,  6121,  2214,   297,   290,\n",
              "         11095,  3625,   313,  2787,   259,   270,  8679,   259,   272,  1544,\n",
              "           259,   793,   268,   355,  1687,   259,  8800,   430,   259,   261,\n",
              "           677,  1990,  1672,   317,  3121,   562,  2294,   262,   359,   623,\n",
              "          2353,   290,   334,  8881,   259,   365,   259,  7568,   394,  1075,\n",
              "           290,   379,  6347,   394,  1135,   259,   272,  1992,   718,  1593,\n",
              "         60694,   356,   615,  1079,   290,   524,  1302,   325,   885,  1672,\n",
              "           534,  6927,   394,  5278,   259,   260,   447, 19698,   290, 16309,\n",
              "           796,   259,   280,  1313,   394,  1978,   381, 60694,   356,   259,\n",
              "          9164,   282,   259,  1318,   562,   708,   290,   272,  4912,  1432,\n",
              "           290,   282,  6701,  1520,  2076, 60694,   333,   330,   933,   259,\n",
              "         69036,   290,  6734,  2902,   259,   260,   259],\n",
              "        [    0,   352,  1266,   408,  5441,   290,   263,  2294,   259, 53334,\n",
              "           355,  1004,   562,  1302,   290,   270,  1262,   268,   300,  1842,\n",
              "           290,   314,  7550,   259,   270,  1242,   290,   379,  1725,  1520,\n",
              "          2076,   690, 10513,   819,  1534, 15437,   259, 18673,   290,  6815,\n",
              "           266,   259,   793,   330,  2289,   270,   290,   297, 12564,  3057,\n",
              "           562,  2902,  1672,   290,  7257,   259,  1369,   594,  3571,   796,\n",
              "           370,   317,   708,   262,  6044,   259,   260,   259,     1,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0]])}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = [train_data_batch[i] for i in range(2)]\n",
        "data_collator(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ik4hZb2yV-b"
      },
      "source": [
        "Cool! Finally, we start training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "LAaTxUpdzshF",
        "outputId": "7e103b00-0ac7-41c0-84a4-884932474b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logging_steps 625\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6250/6250 10:58:06, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.778100</td>\n",
              "      <td>1.839109</td>\n",
              "      <td>28.502400</td>\n",
              "      <td>11.271700</td>\n",
              "      <td>22.108000</td>\n",
              "      <td>22.436100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.062200</td>\n",
              "      <td>1.757558</td>\n",
              "      <td>28.024500</td>\n",
              "      <td>10.611200</td>\n",
              "      <td>21.735300</td>\n",
              "      <td>22.068500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.863600</td>\n",
              "      <td>1.617907</td>\n",
              "      <td>27.353000</td>\n",
              "      <td>10.623800</td>\n",
              "      <td>21.468600</td>\n",
              "      <td>21.751200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.740800</td>\n",
              "      <td>1.614288</td>\n",
              "      <td>28.092800</td>\n",
              "      <td>11.285700</td>\n",
              "      <td>22.060000</td>\n",
              "      <td>22.362900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.649200</td>\n",
              "      <td>1.541136</td>\n",
              "      <td>27.820900</td>\n",
              "      <td>10.918400</td>\n",
              "      <td>21.681900</td>\n",
              "      <td>21.977300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.544800</td>\n",
              "      <td>1.480204</td>\n",
              "      <td>28.043300</td>\n",
              "      <td>11.423200</td>\n",
              "      <td>22.069600</td>\n",
              "      <td>22.373000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.445400</td>\n",
              "      <td>1.462143</td>\n",
              "      <td>27.855200</td>\n",
              "      <td>11.170800</td>\n",
              "      <td>21.895800</td>\n",
              "      <td>22.194900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.363600</td>\n",
              "      <td>1.452241</td>\n",
              "      <td>28.326400</td>\n",
              "      <td>11.794500</td>\n",
              "      <td>22.356300</td>\n",
              "      <td>22.652400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.297800</td>\n",
              "      <td>1.434685</td>\n",
              "      <td>28.444000</td>\n",
              "      <td>11.938800</td>\n",
              "      <td>22.427900</td>\n",
              "      <td>22.734400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.244500</td>\n",
              "      <td>1.444718</td>\n",
              "      <td>28.620500</td>\n",
              "      <td>12.189200</td>\n",
              "      <td>22.662600</td>\n",
              "      <td>22.963500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6250, training_loss=1.69900193359375, metrics={'train_runtime': 39490.375, 'train_samples_per_second': 2.532, 'train_steps_per_second': 0.158, 'total_flos': 5.2874969088e+16, 'train_loss': 1.69900193359375, 'epoch': 10.0})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set training arguments - these params are not really tuned, feel free to change\n",
        "logging_steps = min(2000,len(train_data_batch) // batch_size)\n",
        "print(\"logging_steps\", logging_steps)\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir= OUTPUT_DIR,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=1e-3,\n",
        "    # do_train=True,\n",
        "    # do_eval=True,\n",
        "    logging_steps=logging_steps,  # set to 2000 for full training\n",
        "    save_steps=500,  # set to 500 for full training\n",
        "    eval_steps=75,  # set to 7500 for full training\n",
        "    warmup_steps=3000,  # set to 3000 for full training\n",
        "    num_train_epochs=10, #uncomment for full training\n",
        "    overwrite_output_dir=True,\n",
        "    optim='adafactor',\n",
        "    save_total_limit=3,\n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data_batch,\n",
        "    eval_dataset=val_data_batch,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]\n",
            "\u001b[A\n",
            "events.out.tfevents.1717934610.DESKTOP-H2CRQMR.662540.0: 100%|██████████| 12.4k/12.4k [00:00<00:00, 21.3kB/s]\n",
            "model.safetensors: 100%|██████████| 1.20G/1.20G [01:33<00:00, 12.9MB/s]\n",
            "Upload 2 LFS files: 100%|██████████| 2/2 [01:33<00:00, 46.93s/it]\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7854KKs6EY4x"
      },
      "outputs": [],
      "source": [
        "# !gsutil -m cp -r '/content/training/*' 'gs://kaggle-vbdi-test/training_Data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwQIEhKOrJpl"
      },
      "source": [
        "### **Evaluation**\n",
        "\n",
        "Awesome, we finished training our dummy model. Let's now evaluated the model on the test data. We make use of the dataset's handy `.map()` function to generate a summary of each sample of the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0ef7f4e43319429d9277d55c83cb084d",
            "ab543b6ef5b34ed4acb85fd25304ed75",
            "825d4b325e9b45859e808cd6b14fdd42",
            "dd0bdf658c6d4c0cb0a091129ecbebb0",
            "f7c296a0b8a84ee3be45c92edb6aad21",
            "e21d97b40ffa43668b9962c5d771debb",
            "a4898ec38618401396928eee2c4f9926",
            "3598a3c015a64c20be134cf4d2e7fbbe"
          ]
        },
        "id": "oOoSrwWarJAC",
        "outputId": "67b60b74-c47c-4718-82a7-072f85a32c4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 100/100 [05:03<00:00,  3.03s/ examples]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model, use_fast=False)\n",
        "\n",
        "# model = EncoderDecoderModel.from_pretrained(OUTPUT_DIR + \"/checkpoint-4000\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"my_fine_tuned_t5_small_model\")\n",
        "\n",
        "model.to(\"cuda\")\n",
        "\n",
        "# test_data = datasets.load_dataset(\"xsum\", split=\"test\")\n",
        "\n",
        "batch_size = 16  # change to 64 for full evaluation\n",
        "\n",
        "# map data correctly\n",
        "def generate_summary(batch):\n",
        "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
        "    inputs = tokenizer(batch[\"original\"], padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(\"cuda\")\n",
        "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask,\n",
        "                             max_length=256,\n",
        "                        num_beams=5,\n",
        "                        no_repeat_ngram_size=2,\n",
        "                        early_stopping=True,)\n",
        "\n",
        "    # all special tokens including will be removed\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    batch[\"pred\"] = output_str\n",
        "\n",
        "    return batch\n",
        "\n",
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"original\"])\n",
        "\n",
        "pred_str = results[\"pred\"]\n",
        "label_str = results[\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NHl8NMjEiTb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rouge1': 0.46635404475648523,\n",
              " 'rouge2': 0.17445885772888028,\n",
              " 'rougeL': 0.3090386583457608,\n",
              " 'rougeLsum': 0.3091414947465033}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rouge_output = rouge_score.compute(predictions=pred_str, references=label_str, use_stemmer=True)\n",
        "rouge_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13HUSVh4-CAk",
        "outputId": "96f5c2c3-439c-41f5-e757-02e9aa568c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rouge1\n",
            "0.46635404475648523\n",
            "rouge2\n",
            "0.17445885772888028\n",
            "rougeL\n",
            "0.3090386583457608\n",
            "rougeLsum\n",
            "0.3091414947465033\n"
          ]
        }
      ],
      "source": [
        "for key,value in rouge_output.items():\n",
        "  print(key)\n",
        "  print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8R5CclwUGuC",
        "outputId": "9b53d98d-8d04-49b5-c55a-d47530564398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction:  Dự_án cải_tạo Bến xe_buýt Tân_Quy với kinh_phí 1,9 tỷ đồng.\n",
            "Truth:  Trung_tâm Quản_lý giao_thông công_cộng TP. HCM đưa vào sử_dụng 2 bến xe_buýt mới là bến xe_buýt Tân_Quy ( xã Trung_An - Củ_Chi ) và bến xe_buýt An_Nhơn_Tây ( xã An_Nhơn_Tây - Củ_Chi ) phục_vụ người_dân đi_lại dịp lễ . \n",
            "Content:  Dự_án cải_tạo Bến xe_buýt Tân_Quy với kinh_phí 1,9 tỷ đồng , công_trình có tổng diện_tích xây_dựng 1.156 m2 tại gần giao_lộ đường_Tỉnh_Lộ 8 và đường Sen_Hồng , thuộc xã Trung_An ( huyện Củ_Chi ) . Tại bến_xe xây_dựng mới 1 nhà_vệ_sinh công_cộng , nhà điều_hành , nhà bảo_vệ và xây_dựng hàng_rào bảo_vệ , hệ_thống chiếu sáng nhằm phục_vụ tốt hơn nhu_cầu đi_lại bằng xe_buýt của người_dân . Tuyến xe_buýt qua bến này là tuyến 122 ( Bến_xe An_Sương - Tân_Quy ) và tuyến 70 ( Tân_Quy - Bến_Súc ) . Dự_án Xây_dựng bến xe_buýt An_Nhơn_Tây có tổng diện_tích xây_dựng 600m2 tại đường An_Nhơn_Tây , thuộc xã An_Nhơn_Tây ( huyện Củ_Chi ) . Bến_xe này được xây_dựng với đầy_đủ trang_thiết_bị , nhà_vệ_sinh , hàng_rào đảm_bảo bến_xe an_ninh , tiện_lợi . Tuyến xe_buýt qua bến là tuyến 87 ( Bến_xe Củ_Chi - An_Nhơn_Tây ) . Theo ông Trần_Chí_Trung – giám_đốc Trung_tâm Quản_lý giao_thông công_cộng đây là các công_trình đầu_tư , xây_dựng mới bến_bãi hạ_tầng phục_vụ vận_tải hành_khách công_cộng bằng xe_buýt , góp_phần thu_hút người_dân sử_dụng phương_tiện công_cộng , giảm ùn_tắc giao_thông và tai_nạn giao_thông . Trong thời_gian tơi , trung_tâm tiếp_tục theo_dõi , rà saots , đề_xuất xây_dựng thêm bến_bãi tại các khu_vực cần_thiết .  Phối_cảnh Bến_xe Tân_Quy - Ảnh : Sở GTVT TP. HCM \n",
            "\n",
            "Prediction:  Trong bối_cảnh 10 ngày_trước, Bộ_trưởng Văn_hoá Thể_thao và Du_lịch Nguyễn_Ngọc_Thiện ký quyết_định công_nhận Hải_Vân quan diễn ra ngay bên quán nước nhỏ của người_dân buôn_bán.\n",
            "Truth:  Giám_đốc hai sở Văn_hoá Thể_thao TP Đà_Nẵng và tỉnh Thừa_Thiên_Huế thống_nhất các giải_pháp để bảo_vệ Hải_Vân quan , sau 20 năm hoang_phế vì chồng lấn địa_giới . \n",
            "Content:  Chiều 24/4 , lần đầu_tiên lãnh_đạo ngành văn_hoá của Đà_Nẵng và Thừa_Thiên_Huế cùng lên đỉnh Hải_Vân quan để bàn cách cứu di_tích đang bị hoang_phế suốt thời_gian dài . Cuộc họp diễn ra ngay bên quán nước nhỏ của người_dân buôn_bán trên đỉnh đèo . Buổi làm_việc được nhiều người mong_chờ , diễn ra trong bối_cảnh 10 ngày_trước , Bộ_trưởng Văn_hoá Thể_thao và Du_lịch Nguyễn_Ngọc_Thiện ký quyết_định công_nhận Hải_Vân quan ( nằm trên đỉnh đèo Hải_Vân thuộc thị_trấn Lăng_Cô , huyện Phú_Lộc , tỉnh Thừa_Thiên_Huế và phường Hoà_Hiệp_Bắc , quận Liên_Chiểu , Đà_Nẵng ) là di_tích cấp quốc_gia . Ông Phan_Tiến_Dũng , Giám_đốc Sở Văn_hoá Thừa_Thiên_Huế thừa_nhận thời_gian qua đã thiếu quản_lý với Hải_Vân quan . 20 năm trước , khi đang còn công_tác tại Trung_tâm Bảo_tồn di_tích cố_đô Huế , chính ông đã làm một bộ hồ_sơ xin công_nhận di_tích lịch_sử cấp quốc_gia , nhưng hai địa_phương không thống_nhất được , dẫn đến suốt một thời_gian dài Hải_Vân quan bị bỏ quên . Việc cần làm ngay lúc này , theo ông Dũng là ngành văn_hoá hai địa_phương phải tham_mưu cho UBND tỉnh Thừa_Thiên_Huế và TP Đà_Nẵng chỉ_đạo công_tác cắm mốc khoanh vùng bảo_vệ di_tích theo hồ_sơ khoa_học ; dựng biển giới_thiệu về di_tích ( tiếng Việt và tiếng Anh ) và bản_đồ khoanh vùng bảo_vệ di_tích ; ban_hành quyết_định phân_cấp quản_lý di_tích . Hải_Vân quan đang bị xuống_cấp , nhếch_nhác . Nhìn vào thực_trạng nhếch_nhác của Hải_Vân quan , ông Dũng đề_xuất xin ý_kiến các chuyên_gia , nhà_nghiên_cứu để di_dời , loại_bỏ các bộ_phận hạng_mục công_trình không liên_quan đến các yếu_tố gốc của di_tích , như vọng gác phía trên cổng Hải_Vân quan , các lô_cốt xây trên đất di_tích hay những nền_móng công_trình xây_dựng dân_sinh đã bị phá dỡ … Trước khi tôn_tạo hay xây_dựng bãi giữ xe , nhà_vệ_sinh công_cộng , Sở Tài_nguyên Môi_trường hai địa_phương cần thu_hồi đất lâm_nghiệp để cấp quyền sử_dụng đất mới . Giám_đốc Sở Văn_hoá Thể_thao TP Đà_Nẵng , ông Huỳnh_Văn_Hùng thống_nhất với những đề_xuất của phía Huế . Ông nói , di_tích lịch_sử quốc_gia thì Huế và Đà_Nẵng đều có rất nhiều , riêng Đà_Nẵng là hơn 20 , nhưng Hải_Vân quan là di_tích quốc_gia đặc_biệt , nằm chính giữa ở hai địa_phương . Do ranh_giới chưa được xác_định rõ_ràng nên kéo_dài đến nay mới làm hồ_sơ công_nhận . Trải qua nhiều cuộc họp , lúc ở Đà_Nẵng , khi ở Huế , thậm_chí ra tận Hà_Nội , hai địa_phương mới thống_nhất một bộ hồ_sơ trình Bộ_trưởng Văn_hoá ký . \" Đây là di_tích thể_hiện sự phối_hợp , gắn_kết của hai địa_phương và có_thể xem là biểu_tượng của tình đoàn_kết , nên cần tập_trung để làm \" , ông Hùng nói và đề_nghị Sở Tài_nguyên Môi_trường hai địa_phương giúp_việc cắm mốc khoanh vùng bảo_vệ . Theo ông Hùng , qua 2 cuộc chiến_tranh nên nguyên_trạng Hải_Vân quan không còn . Có nhiều công_trình và lô_cốt chồng lên di_tích , nên về lâu_dài bằng mọi cách trả lại nguyên_trạng . Những công_trình không phù_hợp trên đất hai địa_phương quản_lý thì tháo_dỡ , còn nằm trên đất quốc_phòng thì làm văn_bản đề_nghị Quân_khu 4 và Quân_khu 5 cho_phép giải_toả . \" Chúng_ta cần lập quy_hoạch tổng_thể và chi_tiết để tu_bổ Hải_Vân quan . Hiện_nay ở một_số nơi khi trùng_tu dư_luận hoan_nghênh và đánh_giá cao , nhưng cũng có di_tích làm xong thì bị méo_mó , biến_dạng nên bị phản_ứng . Sau_này khi Huế và Đà_Nẵng tu_bổ Hải_Vân quan sẽ mời các nhà_nghiên_cứu cho ý_kiến , đồng_thời nghiên_cứu kỹ_lưỡng trước khi làm \" , ông Hùng nói . Ông đề_xuất những cuộc gặp tiếp_theo để xây_dựng cơ_chế phối_hợp dựa trên Luật di_sản văn_hoá , và \" mỗi Sở cử ra một nhóm chuyên_viên phối_hợp xây_dựng cơ_chế quản_lý \" . Đồng_thuận ý_tưởng này , ông Dũng nói nhóm chuyên_viên của hai sở sẽ được lập thành một tổ và tuyệt_đối khi làm_việc không được phân_biệt , đùn_đẩy giới_hạn thuộc Huế hay Đà_Nẵng . \" Không_thể phân_biệt khu_vực thuộc bên này , hay bên kia mà để buông_lỏng quản_lý . Chúng_ta cần rút kinh_nghiệm vì vừa_qua có bài_học Hoành_Sơn quan giữa Hà_Tĩnh và Quảng_Bình , cả hai địa_phương cùng công_nhận di_tích và cuối_cùng cả hai bên đều thả tay , hoặc ở một_số nơi khác \" , ông Dũng nói . Về góc_độ phát_triển du_lịch ở Hải_Vân quan , do hai địa_phương đã tách Sở Du_lịch , nên ông Hùng đề_nghị ngành du_lịch tuyệt_đối không được bất_chấp làm du_lịch mà không đi_đôi với bảo_vệ , bảo_tồn di_tích . \" Nhất_cử_nhất_động gì ở Hải_Vân quan phải có sự thống_nhất của hai địa_phương , trên tinh_thần Luật di_sản văn_hoá . Làm_sao để đây là di_tích văn_hoá có giá_trị và từ giá_trị đó sẽ thu_hút khách du_lịch \" , ông nhấn_mạnh . Kết_thúc buổi làm_việc , Giám_đốc Sở Văn_hoá Huế và Đà_Nẵng cùng đi khảo_sát Hải_Vân quan . Hai bên thống_nhất sẽ cho tháo_dỡ một_số hạng_mục đang làm nhếch_nhác di_tích này , như hàng_rào tạm_bợ , bảng cấm bán hàng rong , tấm biển chỉ_dẫn đường cứu_hộ bằng bê_tông vốn hết tác_dụng và che_khuất Thiên_hạ đệ nhất hùng quan , làm lại lối đi bằng gạch ... Trước lúc ra về , hai lãnh_đạo vốn từng học chung một lớp đứng bắt_tay nhau ngay dưới cổng Hải_Vân quan . \" Chúng_tôi chờ_đợi cái bắt_tay này từ rất lâu rồi \" , ông Hùng nói trong tiếng vỗ_tay của các sở , ngành của Huế và Đà_Nẵng . Nguyễn_Đông   Hải_Vân quan đang bị xuống_cấp , nhếch_nhác . Lần đầu_tiên lãnh_đạo ngành văn_hoá hai địa_phương cùng khảo_sát thực_tế Hải_Vân quan . Ông Huỳnh_Hùng ( bía trái ) và ông Phan_Tiến_Dũng bắt_tay để cùng bảo_vệ Hải_Vân quan . \n",
            "\n",
            "Prediction:  Cảnh_sát cho_hay có 500.000 người đã tham_gia biểu_tình tối nay.\n",
            "Truth:  Hàng trăm_nghìn người Hàn_Quốc hôm_nay xuống_đường ở Seoul trong cuối tuần thứ tư liên_tiếp để phản_đối Tổng_thống Park_Geun-hye sau bê_bối liên_quan tới bạn thân . \n",
            "Content:  Các nhà_tổ_chức cho_hay có 500.000 người đã tham_gia biểu_tình tối nay . Cuộc biểu_tình tối nay có quy_mô nhỏ hơn những lần trước khi các hoạt_động tương_tự cũng diễn ra ở khắp nhiều thành_phố khác . Cảnh_sát cho_hay ít_nhất 155.000 người đã tập_trung tại một quảng_trường trung_tâm Seoul vào đầu buổi tối để thắp nến , trong khi các nhà_tổ_chức nói rằng con_số này lên tới 500.000 người . Tổng_thống Park từ_chối các lời kêu_gọi từ_chức , bất_chấp cuộc khủng_hoảng_chính_trị đang diễn ra , trong đó bà bị_cáo buộc để Choi_Soon - sil , một người bạn thân , can_thiệp vào công_việc nhà_nước và trục_lợi cho cá_nhân . Bà thừa_nhận sai_sót trên và cam_kết hợp_tác với các nhà điều_tra vụ bê_bối . Các công_tố_viên dự_kiến sẽ trình cáo_trạng chống lại bà Choi và hai cựu cố_vấn tổng_thống vào ngày_mai . Người biểu_tình tại trung_tâm Seoul tối nay . Tuy_nhiên , không tất_cả người Hàn_Quốc đều kêu_gọi tổng_thống từ_chức . Cách điểm biểu_tình chính không xa , một nhóm người bảo_thủ tập_trung bên ngoài ga Seoul để ủng_hộ bà Park . \" 16 triệu người đã bầu ra tổng_thống này . Điều đó có nghĩa_là không_thể yêu_cầu bà rút_lui một_cách đơn_giản được \" , Geum Sang - chul , một người nghỉ hưu 78 tuổi , thành_viên của Hội Cựu_chiến_binh Hàn_Quốc , nói . Ông Geum tham_gia một nhóm chống người biểu_tình mà cảnh_sát ước_tính có khoảng 11.000 người . Nhiều người trong số 5 % người_dân Hàn_Quốc còn ủng_hộ bà Park là những người trung_thành với cha bà , cố tổng_thống Park_Chung - hee , người từng lãnh_đạo nước này suốt 18 năm cho đến khi bị ám_sát năm 1979 . \" Nếu họ thực_sự quan_tâm đến đất_nước , họ nên cân_nhắc đến hình_ảnh của nó \" , Lee Sang - soon , một người nghỉ hưu 66 tuổi , nói . \" Tôi rất buồn khi đất_nước được nhắc đến ở nước_ngoài bằng những cuộc biểu_tình trên \" . Xem thêm : Hàn_Quốc sẽ thẩm_vấn Tổng_thống Park_Geun-hye Anh Ngọc   Các nhà_tổ_chức cho_hay có 500.000 người đã tham_gia biểu_tình tối nay . \n",
            "\n",
            "Prediction:  Ông Zarif nói với các phóng_viên tại Managua ngày 22-7.\n",
            "Truth:  Ngoại_trưởng Iran_Mohammad_Javad_Zarif dịu giọng với Anh trong thông_điệp mới nhất hướng đến tân thủ_tướng của nước này , nhiều khả_năng là cựu Ngoại_trưởng Anh Boris_Johnson . \n",
            "Content:  Ngoại_trưởng Zarif khẳng_định Iran không muốn đối_đầu với Anh sau vụ bắt_giữ tàu dầu qua_lại giữa hai nước này . Ông Zarif khẳng_định Tehran mong_muốn có quan_hệ bình_thường dựa trên sự tôn_trọng lẫn nhau với London . \" Điều quan_trọng mà ông Boris_Johnson phải hiểu khi ông ấy đặt_chân vào số 10 Downing ( PV - Văn_phòng Thủ_tướng Anh ) là Iran không muốn đối_đầu và rằng Iran muốn các mối quan_hệ bình_thường dựa trên sự tôn_trọng lẫn nhau \" - ông Zarif nói với các phóng_viên tại Managua ngày 22-7 . Hãng tin AFP cho_biết kết_quả cuộc bỏ_phiếu bầu_chọn lãnh_đạo Đảng Bảo_thủ cầm_quyền tại Anh sẽ được công_bố trong ngày 24-7 . Ông Johnson dự_kiến sẽ giành được số phiếu áp_đảo trong cuộc bầu_chọn này . Điều này đồng_nghĩa ông ấy sẽ trở_thành tân thủ_tướng Anh thay_thế bà Theresa_May . Trong khi đó , Anh đã yêu_cầu Iran thả tàu chở dầu mang cờ Anh bị Tehran bắt_giữ tại vùng Vịnh ngày 19-7 . Sự_việc trên xảy ra 2 tuần sau khi các nhà_chức_trách London bắt_giữ một tàu chở dầu của Iran ở ngoài khơi vùng lãnh_thổ Gibraltar với cáo_buộc tàu này vi_phạm các biện_pháp trừng_phạt chống lại Syria . Ông Zarif cho_rằng hành_động bắt tàu dầu Iran của Anh có sự can_thiệp của Mỹ . \" Điều hiển_nhiên ngay từ đầu là Anh đang làm theo lệnh của chính_quyền Tổng_thống Donald_Trump \" - ông Zarif nói . \" Những gì nước Anh và các nhà_chức_trách Giraltar đã làm tại eo_biển Gibraltar là hành_động vi_phạm luật_pháp quốc_tế \" - Bộ_trưởng Zarif cáo_buộc . Cuối tuần trước , Ngoại_trưởng Anh Jeremy_Hunt nói rằng London muốn hạ nhiệt căng_thẳng với Iran nhưng khẳng_định tàu dầu Grace -1 của Iran bị bắt_giữ do \" chở dầu đến Syria trái_lại các biện_pháp trừng_phạt của EU \" . Ông Zarif mô_tả cáo_buộc trên là \" vô_căn_cứ \" . \" Mọi người đều hiểu để bắt_đầu một cuộc_chiến có_lẽ rất dễ_dàng nhưng khó có_thể kết_thúc nó \" - ông Zarif cảnh_báo . Ngoại_trưởng Hunt ngày 22-7 nói rằng ông đang tìm_kiếm \" nhiệm_vụ bảo_vệ hàng_hải do châu_Âu dẫn_đầu \" để bảo_vệ các tàu hàng đi qua vùng Vịnh .  Anh lên_án Iran vì bắt_giữ tàu chở dầu Stena_Bulk mang cờ Anh - Ảnh : AFP \n",
            "\n",
            "Prediction:  Cựu_học_sinh của phòng_khám nhỏ, những người đã nghỉ hưu hoặc đang làm_việc tại trường được khám bệnh đau khớp.\n",
            "Truth:  Gần chục bác_sĩ là cựu_học_sinh trường THPT Lê_Quý_Đôn đã về thăm và khám bệnh cho thầy_cô như một lời tri_ân ngày Nhà_giáo Việt_Nam . \n",
            "Content:  Sáng 19/11 , giữa không_khí rộn_ràng của lễ tri ân nhà_giáo , phòng học dưới tầng trệt trường THPT Lê_Quý_Đôn ( quận 3 , TP HCM ) trở_thành phòng_khám nhỏ . Hơn 100 thầy_cô , những người đã nghỉ hưu hoặc đang làm_việc tại trường được khám bệnh , tư_vấn sức_khoẻ và bốc thuốc miễn_phí . Bác_sĩ , dược_sĩ của \" phòng_khám \" là cựu_học_sinh của trường 20-30 năm trước . Bà Nguyễn_Thị_Hồng ( phải ) được học_trò cũ tư_vấn cách phòng_bệnh đau khớp . Nghỉ hưu gần chục năm , bà giáo Nguyễn_Thị_Hồng vẫn thường lui_tới trường cũ mỗi khi có dịp lễ . Hôm_nay , sau khi dự họp_mặt nhà_giáo hưu_trí của trường , bà được học_trò đón vào phòng_khám bệnh . \" Có_tuổi rồi nên nhiều bệnh , nào_là viêm nha_chu , bướu_cổ , thấp_khớp \" , bà Hồng kể và tỏ ra vui_mừng khi những bác_sĩ đều là học_trò bà từng dạy . \" Bác_sĩ Thuý_Nga là hồi đó tôi chủ_nhiệm , cũng khoảng hơn 20 năm trước rồi . Thỉnh_thoảng cô trò có gặp nhau mỗi khi có dịp lễ ở trường nhưng hôm_nay mới được học_trò mình khám bệnh , xúc_động lắm \" , bà Hồng nói . Trong ký_ức bà giáo dạy môn Vật_lý , nữ_sinh Thuý_Nga là cô học_trò nhỏ xinh và rất thông_minh . Đồng_nghiệp của bà Hồng , ông Nguyễn_Thắng_Cảnh ( 68 tuổi , giáo_viên Địa_lý ) , đã nghỉ hưu nhiều năm , bị đau răng . Sẵn tiện về trường họp_mặt nhân ngày 20/11 , thầy Cảnh được bác_sĩ nha_khoa Phạm_Hoài_Thanh khám bệnh . Thầy Cảnh được chuẩn đoán bị viêm nướu nên gây đau và nhức răng . Ông giáo được học_trò cũ kê đơn thuốc và ân_cần dặn_dò cách phòng_bệnh . \" Được gặp lại những học_trò của mình đã bất_ngờ , bất_ngờ hơn_nữa là các em còn khám bệnh cho thầy_cô . Em nào cũng nhớ và nhận ra thầy , không gì vui bằng \" , ông giáo thổ_lộ . Bác_sĩ Phạm_Hoài_Thanh khám bệnh cho thầy_giáo Nguyễn_Thắng_Cảnh . Trong đoàn bác_sĩ là cựu_học_sinh THPT Lê_Quý_Đôn , ông Phạm_Hoài_Thanh ( 44 tuổi ) được khá nhiều bạn_bè quan_tâm thăm_hỏi đã xa quê khá lâu . Tốt_nghiệp THPT năm 1990 , ông sang Mỹ theo học ngành nha_khoa . Sau đó , ông định_cư tại đây và mở một phòng_khám tư . Nhiều lần về Việt_Nam thăm gia_đình nhưng lần nào cũng vội_vã nên bác_sĩ Thanh chưa có dịp về thăm trường cũ . \" 26 năm rồi mới lại bước chân vào cổng trường . Trường không thay_đổi nhiều nhưng mái đầu của thầy_cô đã bạc trắng . Lúc đó cảm_thấy có_điều gì rất thiêng_liêng và mình thấy nhỏ_bé như thời còn đi học \" , bác_sĩ Thanh giọng xúc_động . Thế_hệ đàn_anh của bác_sĩ Thanh , cựu_học_sinh những năm đầu thập_niên 80 cũng tề_tựu khá đông về trường để gặp_mặt thầy_cô_giáo cũ . Thầy_trò trường THPT Lê_Quý_Đôn trong buổi lễ kỷ_niệm ngày Nhà_giáo Việt_Nam . Dược_sĩ Ngô_Thiên_Tùng , người đưa ra ý_tưởng khám bệnh cho thầy_cô nhân_dịp 20/11 cho biết , những cựu_học_sinh trường Lê_Quý_Đôn đang làm ngành y khá gắn_kết , thân_thiết . Lời đề_nghị của ông Tùng được anh_em ủng_hộ và lên kế_hoạch chuẩn_bị chu_đáo nhân_lực , thuốc để phục_vụ thầy_cô . Nhóm có đủ bác_sĩ để khám các bệnh thông_thường mà người già hay mắc phải , như răng - hàm - mặt , tim_mạch , lao , khớp , tai - mũi - họng . Dược_sĩ Tùng kể , trường Lê_Quý_Đôn là một phần ký_ức trong cuộc_đời của ông . Nhà kế bên trường , học ở đây từ tiểu_học lên cấp ba và gần_như năm nào ông cũng về thăm thầy_cô cũ . Ông Tùng hứa sẽ duy_trì tổ_chức hoạt_động này vào ngày Nhà_giáo ở các năm tiếp_theo . \" Thầy_cô có tuổi rồi nên cần được khám bệnh và theo_dõi định_kỳ . Anh_em chúng_tôi chỉ mong việc_làm nhỏ_bé này là một lời biết_ơn chân_thành nhất của học_trò dành cho những người thầy đáng kính \" , ông chia_sẻ . Mạnh_Tùng   Bà Nguyễn_Thị_Hồng ( phải ) được học_trò cũ tư_vấn cách phòng_bệnh đau khớp . \n",
            "\n",
            "Prediction:  Công_ty TNHH Hwaseung_Vina, cho_biết đang phối_hợp xử_lý vụ tại nạn lao_động bất_ngờ phát_nổ.\n",
            "Truth:  Sau tiếng nổ lớn , nhiều công_nhân Công_ty TNHH Hwaseung_Vina ( Khu_công_nghiệp Nhơn_Trạch 1 , huyện Nhơn_Trạch , Đồng_Nai ) đứng gần bình_điện bị bỏng phải nhập_viện cấp_cứu . \n",
            "Content:  Ngày 16-11 , ông Lê_Văn_Vang , chủ_tịch Liên_đoàn Lao_động huyện Nhơn_Trạch ( Đồng_Nai ) , cho_biết đang phối_hợp xử_lý vụ tại nạn lao_động xảy ra tại Công_ty TNHH Hwaseung_Vina ( đóng tại Khu_công_nghiệp Nhơn_Trạch 1 , huyện Nhơn_Trạch , Đồng_Nai ) khiến nhiều công_nhân bị bỏng nặng phải nhập_viện điều_trị . Theo ông Vang , sáng cùng ngày , bình_điện trong xưởng 5 của Công_ty TNHH Hwaseung_Vina bất_ngờ phát_nổ khiến nhiều công_nhân đứng gần bị bỏng . Ngay khi vụ_việc xảy ra , hệ_thống chữa_cháy đã phun nước tự_động dập tắt đám cháy . Các nạn_nhân được đưa vào Trung_tâm y_tế huyện Nhơn_Trạch điều_trị . Trao_đổi cùng Tuổi_Trẻ , bác_sĩ Hồ_Thanh_Phong - giám_đốc Trung_tâm y_tế huyện Nhơn_Trạch - cho_biết khoảng 9h cùng ngày , bệnh_viện tiếp_nhận 10 công_nhân Công_ty TNHH Hwaseung_Vina nhập_viện do bị bỏng . Theo bác_sĩ Phong , các bệnh_nhân bị phỏng cấp_độ 1-2 , đang nằm tại bệnh_viện theo_dõi thêm nhưng không còn nguy_hiểm đến tính_mạng . Cũng theo ông Vang , ngày 15-11 tại công_ty cũng xảy ra sự_cố điện khiến nhiều dây_chuyền sản_xuất phải ngưng hoạt_động . Có_thể hôm_nay bật lại khiến bình_điện phát_nổ . Hiện các lực_lượng chức_năng đang tiếp_tục điều_tra nguyên_nhân .  Công_ty TNHH Hwaseung_Vina ( Khu_công_nghiệp Nhơn_Trạch 1 , huyện Nhơn_Trạch , Đồng_Nai ) , nơi công_nhân bị tai_nạn - Ảnh : B.A . \n",
            "\n",
            "Prediction:  Những tín_hiệu cứng_rắn từ Bắc_Kinh - điều rất ít khi thấy trước đó.\n",
            "Truth:  Trong bối_cảnh ngày_càng bị bao_vây trừng_phạt , khả_năng Triều_Tiên sẵn_sàng bán công_nghệ hạt_nhân và tên_lửa đổi lấy tiền_mặt ngày_càng cao . \n",
            "Content:  Tính từ năm 2006 đến tháng 9-2107 , tổng_cộng Hội_đồng Bảo_an Liên_Hiệp_Quốc ( LHQ ) đã áp 9 lệnh trừng_phạt đối_với Triều_Tiên vì chương_trình hạt_nhân của nước này . Hai lệnh trừng_phạt liên_tiếp trong tháng 8 và tháng 9-2017 nhận được sự ủng_hộ và thực_thi có - vẻ - là - nghiêm - túc ban_đầu của Trung_Quốc - quốc_gia thân_cận nhất với Triều_Tiên . Những tín_hiệu cứng_rắn từ Bắc_Kinh - điều rất ít khi thấy trước đó , đang có xu_hướng ngày_càng tăng kể từ khi ông Kim_Jong_Un lên cầm_quyền ở Bình_Nhưỡng . Điều đó đồng_nghĩa những dòng_chảy thương_mại xuyên biên_giới Trung - Triều sẽ bị ảnh_hưởng . Nhưng liệu điều đó có làm_khó được Bình_Nhưỡng ? Vỏ quýt dày có móng tay nhọn Các vụ bắn tên_lửa và thử hạt_nhân của Triều_Tiên gần đây , nếu nhìn ở khía_cạnh khác , giống như các màn quảng_cáo để chào_mời khách_hàng tiềm_năng . Hồi đầu tháng 9 rồi , giám_đốc Cục tình_báo trung_ương Mỹ ( CIA ) Mike_Pompeo thừa_nhận Triều_Tiên \" có bề dày lịch_sử trong việc phổ_biến và chia_sẻ kiến_thức , công_nghệ và các tiềm_lực quân_sự ra khắp thế_giới \" . Trải qua thời_gian , cho đến thời_điểm hiện_tại , chỉ còn đếm được trên đầu ngón tay những phi_vụ Triều_Tiên bán công_nghệ và nguyên_liệu chế_tạo hạt_nhân cho nước khác thông_qua các mạng_lưới bất_hợp_pháp . Những năm 1990 , một loạt các cáo_buộc xuất_hiện nói các chuyên_gia kỹ_thuật Triều_Tiên đã hỗ_trợ người Pakistan sản_xuất Krytrons - một thiết_bị được dùng để kích nổ bom hạt_nhân . Cuối thập_niên đó , người_ta tin rằng Bình_Nhưỡng đã chuyển một cơ_số không xác_định các thùng Uranium hexafluoride ( UF 6 ) làm_giàu ở mức_độ thấp sang Pakistan , nơi chúng được A.Q Khan - cha_đẻ của chương_trình hạt_nhân Pakistan , chuyển sang Libya . UF6 là hợp_chất hoá_học cần_thiết để tạo ra uranium làm_giàu cấp_độ cao được sử_dụng trong vũ_khí_hạt_nhân . Nhưng vụ_việc chấn_động nhất và có dính_líu tới Triều_Tiên xảy ra tại Syria năm 2007 . Nghi_ngờ chính_quyền Damascus bí_mật xây_dựng nhà_máy làm_giàu plutonium dưới sự trợ_giúp của Triều_Tiên , Israel đã đưa ra quyết_định liều_lĩnh : điều phi_đội ném bom phá_huỷ toàn_bộ . Một báo_cáo tình_báo vắn_tắt của Mỹ sau vụ không_kích đã chỉ ra những điểm tương_đồng giữa lò phản_ứng Yongbyon của Triều_Tiên và lò phản_ứng của Syria . Báo_cáo cũng lưu_ý đến chuyện nhiều hàng_hoá chưa xác_định đã được chuyển từ Triều_Tiên tới khu lò phản_ứng Al_Kibar từ cuối năm 2006 . Năm 2017 , một báo_cáo của LHQ cho thấy Triều_Tiên đang tìm cách bán Lithium -6 ( Li -6 ) , một đồng_vị được sử_dụng để chế_tạo bom nhiệt_hạch ( bom H ) . Triều_Tiên tuyên_bố đã thử thành_công bom H có_thể gắn lên tên_lửa_đạn_đạo liên lục_địa và doạ sẽ thử tiếp ở tây Thái_Bình_Dương nếu Mỹ làm càn . Một báo_cáo của LHQ khẳng_định sẽ điều_tra việc Bình_Nhưỡng ký các hợp_đồng đào_tạo quân_sự , cung_cấp vũ_khí cho một_số nước châu_Phi . Triều_Tiên nói gì ? Điều ngạc_nhiên là việc bán Li -6 được chào_mời công_khai qua các mẩu quảng_cáo trực_tuyến . Lần theo dấu_vết , người bán khẳng_định mỗi tháng có_thể cung_cấp ít_nhất 10kg Li -6 từ Đan_Đông - một thành_phố của Trung_Quốc nằm ở biên_giới Trung - Triều . Nhưng tất_cả , từ số điện_thoại đến địa_chỉ ghi trên quảng_cáo , trên thực_tế đều không hề tồn_tại . Dù vậy , người mua vẫn có đủ số_lượng Li -6 muốn có thông_qua đơn đặt_hàng trực_tuyến . Green Pine_Associated_Corporation - một công_ty của Triều_Tiên bị liệt vào danh_sách trừng_phạt của LHQ năm 2012 , được cho là đứng sau các mẩu quảng_cáo trên . Sự_việc một lần nữa làm dấy lên quan_ngại khi có ý_kiến cho_rằng bán Li -6 chỉ là phép thử và tính_toán của Triều_Tiên trước khi rao_bán thêm nhiều thứ khác giá_trị hơn . Mặc_dù vậy , trong các tuyên_bố công_khai hiếm_hoi , Bình_Nhưỡng luôn phủ_nhận xuất_khẩu công_nghệ hạt_nhân . Điển_hình như tuyên_bố năm 2006 của Bộ_trưởng ngoại_giao Triều_Tiên , nhấn_mạnh Bình_Nhưỡng sẽ \" cực_lực chống lại mối đe_doạ đến từ việc chuyển_giao công_nghệ hạt_nhân \" . Thực_tế tại những nước đã từng bắt_tay với Triều_Tiên trước đây cũng đã khác . Syria rơi vào_cuộc nội_chiến và không có dấu_hiệu cho thấy vũ_khí_hạt_nhân còn là ưu_tiên số 1 của họ . Năm 2003 , Libya từ_bỏ tham_vọng hạt_nhân nhưng sau cái chết của nhà_lãnh_đạo Muammar_Gaddafi , đất_nước này rơi vào khủng_hoảng , chia_rẽ và bất_ổn . Iran - đỉnh còn lại trong tam_giác Triều_Tiên - Iran - Syria , rốt_cuộc cũng chọn cách thoả_hiệp với phương tây bằng Thoả_thuận hạt_nhân năm 2015 . Điều này dẫn tới một suy_đoán nguy_hiểm khác đến từ Mỹ : Triều_Tiên có_thể bán công_nghệ hạt_nhân , tên_lửa cho các tổ_chức khủng_bố . Đó chính_xác là điều Chủ_tịch Hạ_viện Mỹ_Paul_Ryan đã nêu ra hồi cuối tháng 8 vừa_qua . Thực_tế cho thấy nó vẫn thiếu cơ_sở khi phần_lớn các bạn_hàng vũ_khí Triều_Tiên từ trước đến nay là các quốc_gia - chủ_thể của quan_hệ quốc_tế .  Lãnh_đạo Triều_Tiên_Kim_Jong_Un ( thứ 3 từ trái sang ) xem_xét một thiết_bị được cho là bom H - Ảnh : REUTERS . Ảnh vệ_tinh nơi được cho là nhà_máy hạt_nhân Al_Kibar của Syria trước ( bên trái ) và sau cuộc không_kích của Israel năm 2007 - Ảnh chụp màn_hình . Có ý_kiến cho_rằng các vụ bắn thử tên_lửa của Triều_Tiên là cách để tiếp_thị tới bạn_hàng tiềm_năng tương_lai - Ảnh chụp màn_hình \n",
            "\n",
            "Prediction:  Trong những ngày đầu năm, Kim_Tuyến “ gây thương_nhớ ” bằng vẻ đẹp tinh_khôi.\n",
            "Truth:  Chọn cho mình những chiếc áo_dài trắng thướt_tha , “ ngọc nữ điện_ảnh ” Kim_Tuyến khiến nhiều người ngẩn_ngơ trước vẻ_đẹp không tỳ vết . \n",
            "Content:  Trong những ngày đầu năm , Kim_Tuyến “ gây thương_nhớ ” bằng vẻ đẹp tinh_khôi mà đậm chất truyền_thống . Nữ diễn_viên xuất_hiện dịu_dàng trong những chiếc áo_dài duyên_dáng cũng như mang đến chút hương_vị dân dã hay một_chút không_khí của xuân Đinh_Dậu . Người đẹp luôn tinh_tế và khéo_léo trong việc xây_dựng hình_ảnh của chính mình . Đó chính là những hình_ảnh biến_hoá được nhiều lời khen_ngợi từ công_chúng . Và lần này cũng không ngoại_lệ , Kim_Tuyến nền_nã , duyên_dáng và đậm chất riêng trong những bức hình chào năm mới . Kim_Tuyến thổi hồn quê vào những chiếc áo_dài . Nét hồn_hậu , duyên_dáng của người phụ_nữ Việt được Kim_Tuyến gửi_gắm trong những khoảnh_khắc cuốn_hút nhất của ngày xuân . Trên nền chiếc áo_dài trắng tinh_khôi là những hoạ_tiết mang đậm hồn quê cũng như phảng_phất không_khí của xuân Đinh_Dậu . Hình_ảnh con gà , bụi chuối , phụ_nữ , … lần_lượt trở_thành những điểm nhấn trên tà áo_dài truyền_thống . Bên cạnh đó , những biểu_cảm vô_cùng tinh_tế của Kim_Tuyến cũng giúp những hình_ảnh này trở_nên cuốn_hút hơn_bao_giờ_hết . Hiện_tại , Kim_Tuyến đang được mọi người chú_ý với vai diễn đầy thú_vị trong phim Lục_Vân_Tiên của đạo_diễn Hoàng_Phúc . Với tạo_hình ấn_tượng cũng như chọn cho mình một hình_ảnh mới_mẻ , Kim_Tuyến đang nhận được nhiều phản_hồi tích_cực từ khán_giả . Trong bộ phim Lục_Vân_Tiên , Kim_Tuyến hoá_thân với hình_ảnh đáng nhớ là cô_gái quê , một nhân_vật khác hoàn_toàn so với truyện gốc để mang đến những điều bất_ngờ cho khán_giả . Được biết , đây là vai diễn tâm_huyết của nữ diễn_viên từ lúc hoá_thân đến tạo_hình ra_mắt bộ phim . Có_thể nói , Kim_Tuyến là một trong những mỹ nữ tài_sắc của điện_ảnh nói_riêng và làng giải_trí nói_chung . Cô sở_hữu nét đẹp không tỳ vết , biến_hoá đa_dạng trong hình_ảnh để mang đến những nét riêng đáng nhớ . Song_Ngư  Kim_Tuyến hút_hồn người đối_diện bằng vẻ ngoài tinh_khôi . \n",
            "\n",
            "Prediction:  Ảnh minh_hoạ : Nguyễn_Đông Cục lãnh_sự Việt_Nam tối qua đề_nghị Bộ Ngoại_giao Thái_Lan thực_hiện điều_tra việc hải_quân nước này bắn vào tàu cá của ngư_dân Việt vẫn chưa tìm thấy.\n",
            "Truth:  Đại_diện Bộ Ngoại_giao Việt_Nam hôm_qua gặp đại_diện Đại_sứ_quán Thái_Lan tại Hà_Nội để phản_đối việc sử_dụng vũ_lực với ngư_dân . \n",
            "Content:  Một ngư_dân Việt mất_tích vẫn chưa tìm thấy . Ảnh minh_hoạ : Nguyễn_Đông Cục lãnh_sự Việt_Nam tối qua đề_nghị Bộ Ngoại_giao Thái_Lan thực_hiện điều_tra việc hải_quân nước này bắn vào tàu cá của ngư_dân Việt hôm 8/7 , thông_cáo của Bộ Ngoại_giao cho biết . Nói đến tiến_độ hợp_tác với phía Thái_Lan , bà Phạm_Thu_Hằng , Phó phát_ngôn Bộ Ngoại_giao cho_biết Đại_sứ_quán Việt_Nam tại Thái_Lan đang làm_việc với các cơ_quan_chức_năng sở_tại để xác_minh thông_tin , có các biện_pháp bảo_hộ cần_thiết đối_với các ngư_dân đang bị tạm giam . Các đơn_vị liên_quan của Bộ Ngoại_giao cũng phối_hợp chặt_chẽ với các cơ_quan_chức_năng trong nước làm rõ những thông_tin liên_quan để giải_quyết vụ_việc . Hải_quân Thái_Lan hôm 8/7 đã nổ_súng vào một tàu cá của ngư_dân tỉnh Bến_Tre khiến hai người bị_thương , hai tàu cá khác của Việt_Nam bị chìm trong lúc áp_giải về Thái_Lan khiến một lái tàu mất_tích . Đại_sứ Việt_Nam tại Thái_Lan Nguyễn_Tất_Thành hôm_qua cho_hay Thái_Lan điều một_số máy_bay và tàu tìm_kiếm ngư_dân Việt mất_tích sau vụ nổ_súng với cáo_buộc các tàu này xâm_phạm trái_phép . Đại_sứ_quán hiện vẫn chưa nhận được thông_tin chính_thức của Thái_Lan và đã đề_nghị trao_đổi trong thời_gian sớm nhất . Các cán_bộ bảo_hộ công_dân đang tiếp_tục làm_việc với phía Thái_Lan tại Songkhla , hai người bị_thương đã đi_lại bình_thường do vết_thương không nguy_hiểm . Vị_trí toạ_độ 8,02 độ Bắc và 102 độ Đông . Thái_Lan cho_biết toạ_độ xảy ra vụ_việc là 8,02 độ Bắc và 102 độ Đông và nước này đang hoàn_tất hồ_sơ nên chưa xét_xử các ngư_dân Việt bị_cáo buộc xâm_nhập và đánh_bắt cá trái_phép . Trước đó Bangkok dự_kiến đưa các ngư_dân Việt ra hầu toà hôm_qua . Đây là lần thứ hai tàu_chiến Thái_Lan nổ_súng vào tàu cá Việt_Nam gây thương_vong . Hồi tháng 9 năm_ngoái , tàu_chiến Thái_Lan cũng xả súng vào tàu cá Việt_Nam làm một ngư_dân thiệt_mạng . Xem thêm Thái_Lan thừa_nhận nổ_súng bắn tàu cá Việt_Nam Việt_Anh   Một ngư_dân Việt mất_tích vẫn chưa tìm thấy . Ảnh minh_hoạ : Nguyễn_Đông Vị_trí toạ_độ 8,02 độ Bắc và 102 độ Đông . \n",
            "\n",
            "Prediction:  Lịch dương phát_sinh từ vùng văn_hoá Ai_Cập khoảng 3.000 ngày.\n",
            "Truth:  Người Việt đón tết cổ_truyền dựa vào loại lịch mà mọi người hay gọi là lịch âm . Thực_tế cách gọi này đúng không ? \n",
            "Content:  Trong cuốn Cơ_sở văn_hoá Việt_Nam , giáo_sư Trần_Ngọc_Thêm cho_biết lịch dương phát_sinh từ vùng văn_hoá Ai_Cập khoảng 3.000 năm TCN dựa trên chu_kỳ chuyển_động của mặt_trời , mỗi năm 365,25 ngày . Ngược_lại , lịch âm phát_sinh từ vùng văn_hoá Lưỡng_Hà dựa trên chuyển_động của mặt_trăng với chu_kỳ 29,53 ngày , mỗi năm có 354 ngày . Lịch âm chỉ còn ở một_số lịch Hồi_giáo Lịch âm xác_định ngày trong tháng nhờ vào mặt_trăng : mặt trăng_tròn rồi lại khuyết nên người_xưa đã nhận_thấy bầu_trời đêm ở Trái_đất có độ sáng khác nhau , từ đó dựa vào độ sáng tối này để tính ngày . Ngày mà ban_đêm ở Trái_đất tối nhất gọi là sóc . Đây là ngày cơ_bản nhất để tính lịch , khoảng_cách giữa 2 sóc là một tháng dài 29,53 ngày . Không_thể để số_lẻ , người_ta đưa ra quy_luật nếu khoảng_cách giữa 2 sóc là 30 ngày thì tháng đó đủ , còn khoảng_cách giữa 2 sóc là 29 ngày là tháng thiếu . Hệ_thống lịch hình_thành chỉ bằng việc xác_định các sóc liên_tiếp nhau để tính ngày_tháng là lịch hoàn_toàn dựa vào mặt_trăng hay_là lịch âm \" đúng nghĩa \" . Ngày_nay , loại lịch này chỉ còn được sử_dụng trong một_số loại lịch Hồi_giáo . Nhờ vào mặt_trời để xác_định các mùa Từ lâu mọi người vẫn quen miệng gọi lịch âm hay lịch dựa vào mặt_trăng để chỉ lịch truyền_thống của Việt_Nam và một_số nước Á_Đông . Thật_ra , lịch của chúng_ta vẫn dựa vào mặt_trời để xác_định những thông_tin quan_trọng , do_đó phải gọi là lịch âm dương . Đầu_tiên , lịch âm dương sử_dụng mặt_trời để xác_định các khí_tiết , các mùa trong năm . Trước_hết , người_xưa xác_định 2 ngày - 2 tiết quan_trọng nhất trong năm để làm mốc là đông_chí ( ngày lạnh nhất trong năm ) và hạ_chí ( ngày nóng nhất trong năm ) . Tiếp đó , người_ta xác_định thêm 2 ngày xuân phân và thu_phân ( ngày giữa mùa_xuân và giữa thu ) . Đông_chí , hạ_chí , xuân_phân , thu_phân gọi chung là tứ_thời . Sau đó , người_ta tính thêm 4 ngày khởi_đầu một mùa : lập_xuân , lập_hạ , lập_thu , lập đông , được 8 mốc thời_gian gọi là bát_tiết . Dần_dần người_ta chia nhỏ các khoảng giữa ra được 24 tiết ứng với các mùa trong năm . Tính năm nhuận thế_nào ? Một mối liên_hệ khác giữa mặt_trăng và mặt_trời trong lịch âm dương nằm ở các tháng nhuận . Mỗi năm , lịch dương ( 365 ngày ) dài hơn lịch âm ( 354 ngày ) 11 ngày nên cứ sau 3 năm lại phải điều_chỉnh cho 2 chu_kỳ phù_hợp nhau , tức thường 3 năm sẽ nhuận 1 lần . Khi tính chính_xác hơn , các nhà làm lịch đưa ra quy_luật : 19 năm nhuận 7 lần . Đây gọi là chu_kỳ 19 năm , tức sau 19 năm_âm_lịch và dương_lịch có_thể trùng lại với nhau . Ví_dụ mùng 2 Tết năm 2018 năm nay là 17-2 thì mùng 2 Tết năm 1999 hay năm 1980 cũng là 17-2 . 7 lần nhuận trong chu_kỳ 19 năm được quy_ước vào các năm thứ 3 , 6 , 9 , 11 , 14 , 17 , 19 của chu_kỳ 19 năm . Do_đó , để xác_định một năm có nhuận hay không , bạn hãy lấy năm_dương_lịch chia cho 19 , nếu số_dư là 0 , 3 , 6 , 9 , 11 , 14 , 17 thì năm đó có nhuận . Ví_dụ , năm 2017 chia 19 được 106 dư 3 tức có nhuận . Tương_tự , năm 2020 chia 19 dư 6 , 2023 chia 19 dư 9 , 2025 chia 19 dư 11 sẽ là những năm có nhuận . Các nhà làm lịch có_thể tính trước tháng nhuận trong nhiều năm và thống_kê thành một bảng để tiện tra_cứu .  Lịch truyền_thống của Việt_Nam và các nước Á_Đông được tính_toán dựa trên cả hoạt_động của mặt_trăng và mặt_trời - Ảnh : Getty_Images \n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    print('\\nPrediction: ',pred_str[i])\n",
        "    print('Truth: ',label_str[i])\n",
        "    print('Content: ',test_data[i]['original'])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n4kLAIQSr5g2",
        "outputId": "b4d745cb-4599-43cf-e8c0-1ec9e5fdba6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'data/vietnews-master/data/test_tokenized/003528.txt.seg'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[0]['file']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "testing-huggingface",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01644f724526402c9f139e19b2035073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03b57581ace346d2bde4378a7c6309ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09375b2aac814adcbb51589402eb8b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aeb387a0f53469c8ff42e57647831d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7097c890712d418e9dd9c3e33873a2d5",
            "placeholder": "​",
            "style": "IPY_MODEL_01644f724526402c9f139e19b2035073",
            "value": " 6589/6589 [02:35&lt;00:00, 42.40ba/s]"
          }
        },
        "0d6a0b11ec2a4c6d975857678415f505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef7f4e43319429d9277d55c83cb084d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_825d4b325e9b45859e808cd6b14fdd42",
              "IPY_MODEL_dd0bdf658c6d4c0cb0a091129ecbebb0"
            ],
            "layout": "IPY_MODEL_ab543b6ef5b34ed4acb85fd25304ed75"
          }
        },
        "1ba158d2f09a4c54bc647ebe77d27b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3598a3c015a64c20be134cf4d2e7fbbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5507016090f64bb99dcbf88e14d71eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ac8ad6eea254d369996622911a6a79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e22006901f10483882e1a1f20f645b24",
            "max": 6589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efd6b87b93244d5ca6817ab35c385510",
            "value": 6589
          }
        },
        "63276058881e45539d8dcd4ff2e05edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "7097c890712d418e9dd9c3e33873a2d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70bb7c0669ca4a3699ad36dfdcc10910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ac8ad6eea254d369996622911a6a79e",
              "IPY_MODEL_0aeb387a0f53469c8ff42e57647831d8"
            ],
            "layout": "IPY_MODEL_1ba158d2f09a4c54bc647ebe77d27b60"
          }
        },
        "825d4b325e9b45859e808cd6b14fdd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21d97b40ffa43668b9962c5d771debb",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7c296a0b8a84ee3be45c92edb6aad21",
            "value": 22
          }
        },
        "a4898ec38618401396928eee2c4f9926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab543b6ef5b34ed4acb85fd25304ed75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ddde0882d841daa3bfde43ed6e6fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cab0cd369bfa4c80b963ebd27d3e4974",
              "IPY_MODEL_db0264404d934633824b5b381b31a5ac"
            ],
            "layout": "IPY_MODEL_09375b2aac814adcbb51589402eb8b68"
          }
        },
        "cab0cd369bfa4c80b963ebd27d3e4974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b57581ace346d2bde4378a7c6309ca",
            "max": 1416,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63276058881e45539d8dcd4ff2e05edd",
            "value": 1416
          }
        },
        "db0264404d934633824b5b381b31a5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d6a0b11ec2a4c6d975857678415f505",
            "placeholder": "​",
            "style": "IPY_MODEL_5507016090f64bb99dcbf88e14d71eda",
            "value": " 1416/1416 [00:44&lt;00:00, 31.76ba/s]"
          }
        },
        "dd0bdf658c6d4c0cb0a091129ecbebb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3598a3c015a64c20be134cf4d2e7fbbe",
            "placeholder": "​",
            "style": "IPY_MODEL_a4898ec38618401396928eee2c4f9926",
            "value": " 22/22 [29:59&lt;00:00, 81.81s/ba]"
          }
        },
        "e21d97b40ffa43668b9962c5d771debb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e22006901f10483882e1a1f20f645b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd6b87b93244d5ca6817ab35c385510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "f7c296a0b8a84ee3be45c92edb6aad21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
