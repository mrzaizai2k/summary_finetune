{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/examples\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "    print(file_path)\n",
        "except:\n",
        "    file_path = os.path.abspath('')\n",
        "    os.chdir(os.path.dirname(file_path))\n",
        "    print(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3_GCCIaj7ulj"
      },
      "outputs": [],
      "source": [
        "# !wget 'https://github.com/ThanhChinhBK/vietnews/archive/master.zip'\n",
        "# !unzip 'master.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TZYjioRkKviO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "import concurrent.futures\n",
        "from datasets import *\n",
        "import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import transformers\n",
        "from transformers import RobertaTokenizerFast,AutoTokenizer\n",
        "from vncorenlp import VnCoreNLP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Gx4Vg4cbEUJ_"
      },
      "outputs": [],
      "source": [
        "OUTPUT_DIR = 'my_fine_tuned_t5_small_model'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IteMtlc58-y"
      },
      "source": [
        "## Processing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UVkc5HmK6Bdd"
      },
      "outputs": [],
      "source": [
        "def listPaths(path):\n",
        "  pathfiles = list()\n",
        "  for pathfile in glob.glob(path):\n",
        "    pathfiles.append(pathfile)\n",
        "  return pathfiles\n",
        "\n",
        "train_paths = listPaths('data/vietnews-master/data/train_tokenized/*')\n",
        "val_paths = listPaths('data/vietnews-master/data/val_tokenized/*')\n",
        "test_paths = listPaths('data/vietnews-master/data/test_tokenized/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YZ8pgIYN7zSW"
      },
      "outputs": [],
      "source": [
        "def read_content(pathfile):\n",
        "    \"\"\"\n",
        "    Input: Path of txt file\n",
        "    Output: A dictionary has keys 'original' and 'summary'\n",
        "    \"\"\"\n",
        "    with open(pathfile) as f:\n",
        "      rows  = f.readlines()\n",
        "      original = ' '.join(''.join(rows[4:]).split('\\n'))\n",
        "      summary = ' '.join(rows[2].split('\\n'))\n",
        "            \n",
        "    return {'file' : pathfile,\n",
        "              'original': original, \n",
        "              'summary': summary}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_716GF2iDTcD",
        "outputId": "07268442-c69d-4818-a69a-2f9200044eed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'file': 'data/vietnews-master/data/train_tokenized/006157.txt.seg',\n",
              " 'original': 'Tập 4 Thần_tượng Âm_nhạc nhí - Vietnam_Idol_Kids 2017 lên sóng tối 2/6 với màn tranh tài của top 8 thí_sinh nữ để lựa_chọn ra 5 tấm vé vào tiếp vòng trong . Trong đó , 3 giám_khảo Isaac - Văn_Mai_Hương - Bích_Phương được quyền lựa_chọn 3 thí_sinh . 2 thí_sinh còn lại sẽ do các giám_khảo khách mời quyết_định . Nữ ca_sĩ Văn_Mai_Hương xúc_động : “ Cô có may_mắn năm nay ngồi ở vị_trí ban giám_khảo , may_mắn hơn là được gặp con . Mỗi khi gặp Hiền , cô tự thấy bản_thân cô rất kém , bởi có lúc cô không trân_trọng cũng như không tin vào bản_thân ... Cảm_ơn con , bởi đôi_khi có những cái cô không bằng con được , đó là sự lạc_quan . Và cô tin , còn rất nhiều người phải học đức_tính lạc_quan này của Hiền . Con hát rất là hay ” . Đồng_tình với ý_kiến của đồng_nghiệp , Bích_Phương cũng xúc_động chia_sẻ : “ Giọt nước_mắt dành cho con là sự khâm_phục chứ không phải là thương_cảm . Cô chưa bao_giờ thấy con buồn . Từ lúc xuất_hiện , lúc_nào con cũng cười thôi . Cô nghĩ là ngoài tinh_thần lạc_quan của Hiền làm cho mọi người phải khâm_phục nên mọi người mới khóc … Bên cạnh đó , con còn có giọng hát rất hay . Con rất xứng_đáng được sâu vào vòng trong ” . Hà_Linh  ',\n",
              " 'summary': 'Trên sân_khấu Vietnam_Idol_Kids 2017 , cô_bé khiếm_thị Minh_Hiền khiến giám_khảo và khán_giả lặng người khi tiết_lộ ước_mơ của bản_thân . '}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_content(train_paths[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Wm5kLJD_840E"
      },
      "outputs": [],
      "source": [
        "def get_dataframe(pathfiles):\n",
        "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "      data = executor.map(read_content, pathfiles)\n",
        "    \n",
        "    # Make blank dataframe\n",
        "    data_df = list()\n",
        "    for d in data:\n",
        "      data_df.append(d)\n",
        "    data_df = pd.DataFrame(data_df)\n",
        "    data_df.dropna(inplace = True)\n",
        "    data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    return data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "d4c0pl5BAl3f"
      },
      "outputs": [],
      "source": [
        "train_df = get_dataframe(train_paths[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DgMgMnisA0cf"
      },
      "outputs": [],
      "source": [
        "val_df = get_dataframe(val_paths[:100])\n",
        "test_df = get_dataframe(test_paths[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>original</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/02153...</td>\n",
              "      <td>Ngày 4/4 , hội_nghị đại_biểu Quốc_hội chuyên_t...</td>\n",
              "      <td>Đại_biểu Lưu_Bình_Nhưỡng cho_rằng , cần quy_đị...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/00352...</td>\n",
              "      <td>Dự_án cải_tạo Bến xe_buýt Tân_Quy với kinh_phí...</td>\n",
              "      <td>Trung_tâm Quản_lý giao_thông công_cộng TP. HCM...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/00323...</td>\n",
              "      <td>Theo UBND tỉnh Quảng_Ninh , dự_án có tổng mức ...</td>\n",
              "      <td>Chiều 22-8 , UBND tỉnh Quảng_Ninh tổ_chức khởi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/01056...</td>\n",
              "      <td>Tổng_thống Philippines_Rodrigo_Duterte . Bộ Nộ...</td>\n",
              "      <td>Quyết_định mới của chính_quyền Duterte gây ra ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/01260...</td>\n",
              "      <td>Bà Obama giới_thiệu chồng là \" tình_yêu đời tô...</td>\n",
              "      <td>Đệ nhất phu_nhân Mỹ giới_thiệu \" tình_yêu đời ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                file  \\\n",
              "0  data/vietnews-master/data/test_tokenized/02153...   \n",
              "1  data/vietnews-master/data/test_tokenized/00352...   \n",
              "2  data/vietnews-master/data/test_tokenized/00323...   \n",
              "3  data/vietnews-master/data/test_tokenized/01056...   \n",
              "4  data/vietnews-master/data/test_tokenized/01260...   \n",
              "\n",
              "                                            original  \\\n",
              "0  Ngày 4/4 , hội_nghị đại_biểu Quốc_hội chuyên_t...   \n",
              "1  Dự_án cải_tạo Bến xe_buýt Tân_Quy với kinh_phí...   \n",
              "2  Theo UBND tỉnh Quảng_Ninh , dự_án có tổng mức ...   \n",
              "3  Tổng_thống Philippines_Rodrigo_Duterte . Bộ Nộ...   \n",
              "4  Bà Obama giới_thiệu chồng là \" tình_yêu đời tô...   \n",
              "\n",
              "                                             summary  \n",
              "0  Đại_biểu Lưu_Bình_Nhưỡng cho_rằng , cần quy_đị...  \n",
              "1  Trung_tâm Quản_lý giao_thông công_cộng TP. HCM...  \n",
              "2  Chiều 22-8 , UBND tỉnh Quảng_Ninh tổ_chức khởi...  \n",
              "3  Quyết_định mới của chính_quyền Duterte gây ra ...  \n",
              "4  Đệ nhất phu_nhân Mỹ giới_thiệu \" tình_yêu đời ...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1F58j028eTV"
      },
      "source": [
        "## **Warm-starting RoBERTaShared for BBC XSum**\n",
        "\n",
        "***Note***: This notebook only uses a few training, validation, and test data samples for demonstration purposes. To fine-tune an encoder-decoder model on the full training data, the user should change the training and data preprocessing parameters accordingly as highlighted by the comments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FO5ESocXvlK"
      },
      "source": [
        "### **Data Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sgTiC0rhMb7C"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "pretrained_model = \"google/mt5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U08MrUK9LcUM"
      },
      "outputs": [],
      "source": [
        "train_data =  Dataset.from_pandas(train_df)\n",
        "val_data =  Dataset.from_pandas(val_df)\n",
        "test_data =  Dataset.from_pandas(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "70bb7c0669ca4a3699ad36dfdcc10910",
            "1ba158d2f09a4c54bc647ebe77d27b60",
            "5ac8ad6eea254d369996622911a6a79e",
            "0aeb387a0f53469c8ff42e57647831d8",
            "efd6b87b93244d5ca6817ab35c385510",
            "e22006901f10483882e1a1f20f645b24",
            "01644f724526402c9f139e19b2035073",
            "7097c890712d418e9dd9c3e33873a2d5",
            "b3ddde0882d841daa3bfde43ed6e6fc9",
            "09375b2aac814adcbb51589402eb8b68",
            "cab0cd369bfa4c80b963ebd27d3e4974",
            "db0264404d934633824b5b381b31a5ac",
            "63276058881e45539d8dcd4ff2e05edd",
            "03b57581ace346d2bde4378a7c6309ca",
            "5507016090f64bb99dcbf88e14d71eda",
            "0d6a0b11ec2a4c6d975857678415f505"
          ]
        },
        "id": "yoN2q0hZUbXN",
        "outputId": "20c6562f-7358-4dc7-dada-787bede963bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 100/100 [00:00<00:00, 1251.49 examples/s]\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 1543.16 examples/s]\n"
          ]
        }
      ],
      "source": [
        "batch_size=16  # change to 16 for full training\n",
        "encoder_max_length=256\n",
        "decoder_max_length=64\n",
        "\n",
        "def process_data_to_model_inputs(batch):                                                               \n",
        "    # Tokenizer will automatically set [BOS] <text> [EOS]                                               \n",
        "    model_inputs  = tokenizer(batch[\"original\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "    labels = tokenizer(batch[\"summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "                                                                                                        \n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# only use 32 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# train_data = train_data.select(range(32))\n",
        "\n",
        "train_data_batch = train_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"file\",\"original\", \"summary\"],\n",
        ")\n",
        "train_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        ")\n",
        "\n",
        "\n",
        "# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# val_data = val_data.select(range(16))\n",
        "\n",
        "val_data_batch = val_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"file\", \"original\", \"summary\"],\n",
        ")\n",
        "val_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>original</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/vietnews-master/data/train_tokenized/0739...</td>\n",
              "      <td>Đó là ý_kiến của các chuyên_gia giáo_dục liên_...</td>\n",
              "      <td>Nếu được nghỉ học thứ_bảy , học_sinh có thêm t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                file  \\\n",
              "0  data/vietnews-master/data/train_tokenized/0739...   \n",
              "\n",
              "                                            original  \\\n",
              "0  Đó là ý_kiến của các chuyên_gia giáo_dục liên_...   \n",
              "\n",
              "                                             summary  \n",
              "0  Nếu được nghỉ học thứ_bảy , học_sinh có thêm t...  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  977,   553,   796,   259,   952,   290,   650,  1405,   317,   708,\n",
              "           262,   259,  1226,   562,  4634,   290, 10745,   259,  2624,   268,\n",
              "           290,   285,  2902,   615,  1079,   290, 84631,   355,  1492,   290,\n",
              "         33601,  1075,   970,  2906,   297,   290,   263, 25833,   594,  2802,\n",
              "          2906,   297,   394,  1978,   290,   316,  1138,   276,   259, 15265,\n",
              "           290,  7568,   317,  2802,   594,  2802,   562,   708,   290,   272,\n",
              "         13262,   259,  2180,   382,  1375,   290, 16309,   259,   260,  9448,\n",
              "           553,   394,  1849,   290,   334,  1375,   259,   272,  3502,  2906,\n",
              "           297,   333,   758,  1544,   266,   259,   275,   259,  3665,   259,\n",
              "          3920,   370,   259, 15355,   290,   561,  2296,   290, 26250,  3502,\n",
              "           259,   264,   690,   553,   259,  2624,   282,   290, 11095,  4059,\n",
              "           320,  1269, 83438,   264,  8143,   490, 14133,   260,   259, 27398,\n",
              "           259,   261,   970,   290,   316,  2591,   259,  1735,   259,   708,\n",
              "           370,   290,   334,  1514,   421,  5182,   290,  1301,   970,  2906,\n",
              "           297,   290,   263, 25833,   594,  2802,  2906,   297,   356,   259,\n",
              "          3665,   651,  2163,   719,  1313,   394,  1978,   290,   316,  1138,\n",
              "           276,   259,   793,   562,   708,   290,   272, 13262,   259,   260,\n",
              "           259, 19791,   290,   272, 12093,   259,   261,   342,   355,  1335,\n",
              "           297,   290,   807,  1541,   317,   708,   262, 14133,   260,   259,\n",
              "         27398,  2906,   297,   290,   263, 25833,   819,   471,   355,  1735,\n",
              "           259,  4251,   259,  1226,   259,  5368,  1284,   355,   708,   690,\n",
              "          3633,  2906,   297,   355,   924,   259,   270,  1544,   290,   697,\n",
              "          1690,   970,   966,  1448,  2906,   297,   290,   263, 25833,  2906,\n",
              "           297,   356,   758,  1544,   266,   259,   275,   259,  3665,   259,\n",
              "           260,   977,  2163,   290,   379,   908,   259,  1226,   259,   280,\n",
              "          4941,   325,   290,   334,  4929,     1]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'labels': tensor([  441,  3502,   259,  1318,   594,  2802,  2906,   297,   394,  1978,\n",
              "           290,   316,  1138,   276,   259,   261,  2906,   297,   290,   263,\n",
              "         25833,   885,   394,  3316,   394,  1894,   290, 64213,   355,   924,\n",
              "          2906,   297,   408,  5441,   290,   272,  2184,   259,   263,  2160,\n",
              "           259,   261,   690,  1308,   290,  1731,  5735,  2626,   290, 11095,\n",
              "          1253,   480,   259, 19791,   290,   272, 12093,   300,  3452,   297,\n",
              "          2424,   259,   263,     1])}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_batch[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEjb026cNC38"
      },
      "source": [
        "### **Warm-starting the Encoder-Decoder Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u98CLZiTkgzv"
      },
      "source": [
        "### **Fine-Tuning Warm-Started Encoder-Decoder Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gYzA-w96wCt"
      },
      "source": [
        "The `Seq2SeqTrainer` that can be found under [examples/seq2seq/seq2seq_trainer.py](https://github.com/huggingface/transformers/blob/master/examples/seq2seq/seq2seq_trainer.py) will be used to fine-tune a warm-started encoder-decoder model.\n",
        "\n",
        "Let's download the `Seq2SeqTrainer` code and import the module along with `TrainingArguments`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pyiwaF0noA5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-08 18:46:07.407372: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-06-08 18:46:07.437992: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-08 18:46:08.062203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nmQRT3XuHHz"
      },
      "source": [
        "We need to add some additional parameters to make `TrainingArguments` compatible with the `Seq2SeqTrainer`. Let's just copy the `dataclass` arguments as defined in [this file](https://github.com/patrickvonplaten/transformers/blob/make_seq2seq_trainer_self_contained/examples/seq2seq/finetune_trainer.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPUAgo7pxH24"
      },
      "source": [
        "Also, we need to define a function to correctly compute the ROUGE score during validation. ROUGE is a much better metric to track during training than only language modeling loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "68IHmFYLx09W"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_225222/1860282078.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge = datasets.load_metric(\"rouge\")\n",
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# load rouge for validation\n",
        "rouge = datasets.load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    # all unnecessary tokens are removed\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
        "\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ik4hZb2yV-b"
      },
      "source": [
        "Cool! Finally, we start training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "LAaTxUpdzshF",
        "outputId": "7e103b00-0ac7-41c0-84a4-884932474b22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 00:20, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=70, training_loss=0.0, metrics={'train_runtime': 20.6957, 'train_samples_per_second': 48.319, 'train_steps_per_second': 3.382, 'total_flos': 264374845440000.0, 'train_loss': 0.0, 'epoch': 10.0})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set training arguments - these params are not really tuned, feel free to change\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir= OUTPUT_DIR,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    # evaluate_during_training=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    logging_steps=200,  # set to 2000 for full training\n",
        "    save_steps=5000,  # set to 500 for full training\n",
        "    eval_steps=7500,  # set to 7500 for full training\n",
        "    warmup_steps=3000,  # set to 3000 for full training\n",
        "    num_train_epochs=10, #uncomment for full training\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=3,\n",
        "    fp16=True, \n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data_batch,\n",
        "    eval_dataset=val_data_batch,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   0%|          | 16.4k/1.20G [00:00<5:47:05, 57.7kB/s]\n",
            "\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "events.out.tfevents.1717847220.DESKTOP-H2CRQMR.225222.0: 100%|██████████| 4.18k/4.18k [00:00<00:00, 7.28kB/s]\n",
            "events.out.tfevents.1717847225.DESKTOP-H2CRQMR.225222.1: 100%|██████████| 5.47k/5.47k [00:00<00:00, 9.64kB/s]\n",
            "model.safetensors:   0%|          | 2.56M/1.20G [00:00<04:46, 4.18MB/s]  \n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   0%|          | 3.44M/1.20G [00:00<04:35, 4.34MB/s]\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   0%|          | 4.49M/1.20G [00:00<03:39, 5.44MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   1%|          | 6.64M/1.20G [00:01<03:14, 6.15MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   1%|          | 7.91M/1.20G [00:01<02:43, 7.30MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   1%|          | 9.39M/1.20G [00:01<02:20, 8.48MB/s]\n",
            "\n",
            "\n",
            "training_args.bin: 100%|██████████| 5.30k/5.30k [00:00<00:00, 15.8kB/s]\n",
            "model.safetensors:   1%|          | 10.9M/1.20G [00:01<02:06, 9.41MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   1%|          | 12.5M/1.20G [00:01<01:52, 10.5MB/s]\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spiece.model: 100%|██████████| 4.31M/4.31M [00:01<00:00, 2.17MB/s]MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   1%|▏         | 16.5M/1.20G [00:02<03:09, 6.25MB/s]\n",
            "\n",
            "\n",
            "tokenizer.json: 100%|██████████| 16.3M/16.3M [00:03<00:00, 4.75MB/s]/s]\n",
            "model.safetensors: 100%|██████████| 1.20G/1.20G [01:37<00:00, 12.3MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 6 LFS files: 100%|██████████| 6/6 [01:37<00:00, 16.30s/it]\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(\"my_fine_tuned_t5_small_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7854KKs6EY4x"
      },
      "outputs": [],
      "source": [
        "# !gsutil -m cp -r '/content/training/*' 'gs://kaggle-vbdi-test/training_Data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwQIEhKOrJpl"
      },
      "source": [
        "### **Evaluation**\n",
        "\n",
        "Awesome, we finished training our dummy model. Let's now evaluated the model on the test data. We make use of the dataset's handy `.map()` function to generate a summary of each sample of the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0ef7f4e43319429d9277d55c83cb084d",
            "ab543b6ef5b34ed4acb85fd25304ed75",
            "825d4b325e9b45859e808cd6b14fdd42",
            "dd0bdf658c6d4c0cb0a091129ecbebb0",
            "f7c296a0b8a84ee3be45c92edb6aad21",
            "e21d97b40ffa43668b9962c5d771debb",
            "a4898ec38618401396928eee2c4f9926",
            "3598a3c015a64c20be134cf4d2e7fbbe"
          ]
        },
        "id": "oOoSrwWarJAC",
        "outputId": "67b60b74-c47c-4718-82a7-072f85a32c4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:   0%|          | 0/100 [00:00<?, ? examples/s]/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Map: 100%|██████████| 100/100 [00:01<00:00, 61.07 examples/s]\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "from transformers import RobertaTokenizer, EncoderDecoderModel, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model, use_fast=False)\n",
        "\n",
        "# model = EncoderDecoderModel.from_pretrained(OUTPUT_DIR + \"/checkpoint-4000\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"my_fine_tuned_t5_small_model\")\n",
        "\n",
        "model.to(\"cuda\")\n",
        "\n",
        "# test_data = datasets.load_dataset(\"xsum\", split=\"test\")\n",
        "\n",
        "batch_size = 16  # change to 64 for full evaluation\n",
        "\n",
        "# map data correctly\n",
        "def generate_summary(batch):\n",
        "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
        "    inputs = tokenizer(batch[\"original\"], padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(\"cuda\")\n",
        "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # all special tokens including will be removed\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    batch[\"pred\"] = output_str\n",
        "\n",
        "    return batch\n",
        "\n",
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"original\"])\n",
        "\n",
        "pred_str = results[\"pred\"]\n",
        "label_str = results[\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NHl8NMjEiTb6"
      },
      "outputs": [],
      "source": [
        "rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\",\"rouge2\",\"rougeL\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13HUSVh4-CAk",
        "outputId": "96f5c2c3-439c-41f5-e757-02e9aa568c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rouge1\n",
            "Score(precision=0.14416666666666672, recall=0.015686256903094605, fmeasure=0.02800959396390076)\n",
            "rouge2\n",
            "Score(precision=0.017, recall=0.001761819575773064, fmeasure=0.0031891063410072534)\n",
            "rougeL\n",
            "Score(precision=0.13818939393939392, recall=0.014820770937357524, fmeasure=0.026534492964907685)\n"
          ]
        }
      ],
      "source": [
        "for key,value in rouge_output.items():\n",
        "  print(key)\n",
        "  print(value.mid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8R5CclwUGuC",
        "outputId": "9b53d98d-8d04-49b5-c55a-d47530564398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction:  <extra_id_0>.\n",
            "Truth:  Đại_biểu Lưu_Bình_Nhưỡng cho_rằng , cần quy_định chặt_chẽ việc cơ_quan nhà_nước tiếp_nhận quà tặng từ doanh_nghiệp . Các tỉnh được doanh_nghiệp tặng ôtô nên đấu_giá để thực_hiện công_tác xã_hội . \n",
            "Content:  Ngày 4/4 , hội_nghị đại_biểu Quốc_hội chuyên_trách đã cho ý_kiến vào dự_thảo Luật Quản_lý , sử_dụng tài_sản nhà_nước ( sửa_đổi ) . Ông Lưu_Bình_Nhưỡng , Uỷ_viên thường_trực Uỷ_ban về các vấn_đề xã_hội , nêu vấn_đề thời_gian qua đã xảy ra những sự_việc đáng tiếc liên_quan đến việc các tỉnh , thành nhận ôtô đắt tiền do doanh_nghiệp tặng , sau đó phải trả lại . \" Việc quản_lý , sử_dụng các loại tài_sản biếu tặng cho cơ_quan nhà_nước là một bài_học . Do_vậy , dự_thảo luật cần phải quy_định chặt_chẽ \" , ông nói . Theo ông Nhưỡng , ranh_giới giữa việc sử_dụng tài_sản là ôtô được tặng cho mục_đích công và nhu_cầu cá_nhân trong trường_hợp này rất khó xác_định , thậm_chí rất dễ nảy_sinh tiêu_cực . Ngoài_ra , việc tỉnh nhận xe của doanh_nghiệp còn có_thể phát_sinh tình_trạng đối_xử mất công_bằng giữa các doanh_nghiệp trong cùng một lĩnh_vực , trên cùng một địa_bàn . Chiếc ôtô doanh_nghiệp tặng , đã được Đà_Nẵng trả lại . Ảnh : Nguyễn_Đông . Để khắc_phục tình_trạng trên , theo ông Nhưỡng , cần quy_định rõ về việc tiếp_nhận tài_sản biếu tặng và mục_đích sử_dụng . \" Phải đảm_bảo sử_dụng vì mục_đích công . Ngoài_ra có_thể đưa các tài_sản này vào hệ_thống đấu_giá để thực_hiện công_tác xã_hội , từ_thiện \" , ông Nhưỡng nói và cho_rằng việc trả lại xe cho doanh_nghiệp như vừa_qua là không nên , vì địa_phương đã tiếp_nhận và đăng_ký tài_sản công rồi . \" Việc trả lại xe ngay như_vậy có_thể khiến dư_luận liên_tưởng là ... có tật giật_mình . Theo tôi , địa_phương nên đưa ra đấu_giá và sử_dụng tiền vào mục_đích xã_hội . Ví_dụ , 2 chiếc xe Lexus mà doanh_nghiệp tặng Cà_Mau trị_giá hơn 6 tỷ đồng , tương_đương với số tiền xây được 250 căn nhà_tình_nghĩa . Nếu việc này được thực_hiện đúng luật , công_khai và có hiệu_quả thì chắc không có dư_luận \" , ông Nhưỡng nêu quan_điểm . Đại_biểu Lưu_Bình_Nhưỡng . Đại_biểu Nguyễn_Thanh_Hồng , Uỷ_viên thường_trực Uỷ_ban quốc_phòng an_ninh , cũng cho_rằng không nên từ_chối sự đóng_góp của cá_nhân , tổ_chức để phục_vụ mục_đích an_sinh xã_hội . Bộ_trưởng Tài_chính Đinh_Tiến_Dũng khẳng_định Ban soạn_thảo dự_án Luật sẽ tiếp_thu các ý_kiến của đại_biểu . Theo ông , việc nhận quà tặng , quà biếu của các tổ_chức trong và ngoài nước , hay qua hình_thức ODA cho mục_đích an_sinh xã_hội , xoá_đói_giảm_nghèo là bình_thường . \" Thời_gian qua dư_luận băn_khoăn chủ_yếu với các trường_hợp biếu tặng ôtô , những trường_hợp này sẽ được áp_dụng theo các quy_định , thủ_tục về xác_lập tài_sản nhà_nước và định_mức , chế_độ đã quy_định \" , ông Dũng cho_hay . Theo Phó chủ_tịch Quốc_hội Phùng_Quốc_Hiển , nếu cơ_quan nào được tặng xe 3 tỷ đồng mà định_mức dùng xe một tỷ đồng thì \" không được sử_dụng \" . Bên cạnh đó , đã là tài_sản Nhà_nước thì \" không_thể trả lại như bình_thường , mà phải qua đấu_giá \" . Chủ_nhiệm Uỷ_ban tài_chính – Ngân_sách Nguyễn_Đức_Hải cho_biết , dự_thảo Luật quy_định rõ việc giao tài_sản công cho cơ_quan nhà_nước , đơn_vị sự_nghiệp công_lập phải phù_hợp với tiêu_chuẩn , định_mức sử_dụng tài_sản , thẩm_quyền quyết_định xác_lập quyền_sở_hữu toàn dân về tài_sản . Đồng_thời , dự_thảo Luật giao Chính_phủ quy_định trình_tự , thủ_tục xác_lập quyền_sở_hữu toàn dân về tài_sản , trong đó có tài_sản do các tổ_chức , cá_nhân cho , tặng cơ_quan , đơn_vị của Nhà_nước . Hoàng_Thuỳ   Đại_biểu Lưu_Bình_Nhưỡng . \n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "print('Prediction: ',pred_str[i])\n",
        "print('Truth: ',label_str[i])\n",
        "print('Content: ',test_data[i]['original'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n4kLAIQSr5g2",
        "outputId": "b4d745cb-4599-43cf-e8c0-1ec9e5fdba6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'data/vietnews-master/data/test_tokenized/021531.txt.seg'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[0]['file']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "testing-huggingface",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01644f724526402c9f139e19b2035073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03b57581ace346d2bde4378a7c6309ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09375b2aac814adcbb51589402eb8b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aeb387a0f53469c8ff42e57647831d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7097c890712d418e9dd9c3e33873a2d5",
            "placeholder": "​",
            "style": "IPY_MODEL_01644f724526402c9f139e19b2035073",
            "value": " 6589/6589 [02:35&lt;00:00, 42.40ba/s]"
          }
        },
        "0d6a0b11ec2a4c6d975857678415f505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef7f4e43319429d9277d55c83cb084d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_825d4b325e9b45859e808cd6b14fdd42",
              "IPY_MODEL_dd0bdf658c6d4c0cb0a091129ecbebb0"
            ],
            "layout": "IPY_MODEL_ab543b6ef5b34ed4acb85fd25304ed75"
          }
        },
        "1ba158d2f09a4c54bc647ebe77d27b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3598a3c015a64c20be134cf4d2e7fbbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5507016090f64bb99dcbf88e14d71eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ac8ad6eea254d369996622911a6a79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e22006901f10483882e1a1f20f645b24",
            "max": 6589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efd6b87b93244d5ca6817ab35c385510",
            "value": 6589
          }
        },
        "63276058881e45539d8dcd4ff2e05edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "7097c890712d418e9dd9c3e33873a2d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70bb7c0669ca4a3699ad36dfdcc10910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ac8ad6eea254d369996622911a6a79e",
              "IPY_MODEL_0aeb387a0f53469c8ff42e57647831d8"
            ],
            "layout": "IPY_MODEL_1ba158d2f09a4c54bc647ebe77d27b60"
          }
        },
        "825d4b325e9b45859e808cd6b14fdd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21d97b40ffa43668b9962c5d771debb",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7c296a0b8a84ee3be45c92edb6aad21",
            "value": 22
          }
        },
        "a4898ec38618401396928eee2c4f9926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab543b6ef5b34ed4acb85fd25304ed75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ddde0882d841daa3bfde43ed6e6fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cab0cd369bfa4c80b963ebd27d3e4974",
              "IPY_MODEL_db0264404d934633824b5b381b31a5ac"
            ],
            "layout": "IPY_MODEL_09375b2aac814adcbb51589402eb8b68"
          }
        },
        "cab0cd369bfa4c80b963ebd27d3e4974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b57581ace346d2bde4378a7c6309ca",
            "max": 1416,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63276058881e45539d8dcd4ff2e05edd",
            "value": 1416
          }
        },
        "db0264404d934633824b5b381b31a5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d6a0b11ec2a4c6d975857678415f505",
            "placeholder": "​",
            "style": "IPY_MODEL_5507016090f64bb99dcbf88e14d71eda",
            "value": " 1416/1416 [00:44&lt;00:00, 31.76ba/s]"
          }
        },
        "dd0bdf658c6d4c0cb0a091129ecbebb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3598a3c015a64c20be134cf4d2e7fbbe",
            "placeholder": "​",
            "style": "IPY_MODEL_a4898ec38618401396928eee2c4f9926",
            "value": " 22/22 [29:59&lt;00:00, 81.81s/ba]"
          }
        },
        "e21d97b40ffa43668b9962c5d771debb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e22006901f10483882e1a1f20f645b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd6b87b93244d5ca6817ab35c385510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "f7c296a0b8a84ee3be45c92edb6aad21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
