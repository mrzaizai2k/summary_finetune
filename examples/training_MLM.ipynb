{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/examples\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "    print(file_path)\n",
        "except:\n",
        "    file_path = os.path.abspath('')\n",
        "    os.chdir(os.path.dirname(file_path))\n",
        "    print(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3_GCCIaj7ulj"
      },
      "outputs": [],
      "source": [
        "# !wget 'https://github.com/ThanhChinhBK/vietnews/archive/master.zip'\n",
        "# !unzip 'master.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TZYjioRkKviO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2024-06-11 11:16:40.631890: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-06-11 11:16:40.674848: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-11 11:16:41.309300: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "import concurrent.futures\n",
        "from datasets import *\n",
        "import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "\n",
        "# from vncorenlp import VnCoreNLP\n",
        "import torch \n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Gx4Vg4cbEUJ_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "OUTPUT_DIR = 'Vietnam_T5_small_200'\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/mrzaizai2k/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IteMtlc58-y"
      },
      "source": [
        "## Processing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UVkc5HmK6Bdd"
      },
      "outputs": [],
      "source": [
        "def listPaths(path):\n",
        "  pathfiles = list()\n",
        "  for pathfile in glob.glob(path):\n",
        "    pathfiles.append(pathfile)\n",
        "  return pathfiles\n",
        "\n",
        "train_paths = listPaths('data/vietnews-master/data/train_tokenized/*')\n",
        "val_paths = listPaths('data/vietnews-master/data/val_tokenized/*')\n",
        "test_paths = listPaths('data/vietnews-master/data/test_tokenized/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YZ8pgIYN7zSW"
      },
      "outputs": [],
      "source": [
        "def read_content(pathfile):\n",
        "    \"\"\"\n",
        "    Input: Path of txt file\n",
        "    Output: A dictionary has keys 'original' and 'summary'\n",
        "    \"\"\"\n",
        "    with open(pathfile) as f:\n",
        "      rows  = f.readlines()\n",
        "      original = ' '.join(''.join(rows[4:]).split('\\n'))\n",
        "      summary = ' '.join(rows[2].split('\\n'))\n",
        "            \n",
        "    return {'file' : pathfile,\n",
        "              'original': original, \n",
        "              'summary': summary}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_716GF2iDTcD",
        "outputId": "07268442-c69d-4818-a69a-2f9200044eed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'file': 'data/vietnews-master/data/train_tokenized/006157.txt.seg',\n",
              " 'original': 'Tập 4 Thần_tượng Âm_nhạc nhí - Vietnam_Idol_Kids 2017 lên sóng tối 2/6 với màn tranh tài của top 8 thí_sinh nữ để lựa_chọn ra 5 tấm vé vào tiếp vòng trong . Trong đó , 3 giám_khảo Isaac - Văn_Mai_Hương - Bích_Phương được quyền lựa_chọn 3 thí_sinh . 2 thí_sinh còn lại sẽ do các giám_khảo khách mời quyết_định . Nữ ca_sĩ Văn_Mai_Hương xúc_động : “ Cô có may_mắn năm nay ngồi ở vị_trí ban giám_khảo , may_mắn hơn là được gặp con . Mỗi khi gặp Hiền , cô tự thấy bản_thân cô rất kém , bởi có lúc cô không trân_trọng cũng như không tin vào bản_thân ... Cảm_ơn con , bởi đôi_khi có những cái cô không bằng con được , đó là sự lạc_quan . Và cô tin , còn rất nhiều người phải học đức_tính lạc_quan này của Hiền . Con hát rất là hay ” . Đồng_tình với ý_kiến của đồng_nghiệp , Bích_Phương cũng xúc_động chia_sẻ : “ Giọt nước_mắt dành cho con là sự khâm_phục chứ không phải là thương_cảm . Cô chưa bao_giờ thấy con buồn . Từ lúc xuất_hiện , lúc_nào con cũng cười thôi . Cô nghĩ là ngoài tinh_thần lạc_quan của Hiền làm cho mọi người phải khâm_phục nên mọi người mới khóc … Bên cạnh đó , con còn có giọng hát rất hay . Con rất xứng_đáng được sâu vào vòng trong ” . Hà_Linh  ',\n",
              " 'summary': 'Trên sân_khấu Vietnam_Idol_Kids 2017 , cô_bé khiếm_thị Minh_Hiền khiến giám_khảo và khán_giả lặng người khi tiết_lộ ước_mơ của bản_thân . '}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_content(train_paths[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Wm5kLJD_840E"
      },
      "outputs": [],
      "source": [
        "def get_dataframe(pathfiles):\n",
        "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "      data = executor.map(read_content, pathfiles)\n",
        "    \n",
        "    # Make blank dataframe\n",
        "    data_df = list()\n",
        "    for d in data:\n",
        "      data_df.append(d)\n",
        "    data_df = pd.DataFrame(data_df)\n",
        "    data_df.dropna(inplace = True)\n",
        "    data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    return data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d4c0pl5BAl3f"
      },
      "outputs": [],
      "source": [
        "train_df = get_dataframe(train_paths[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DgMgMnisA0cf"
      },
      "outputs": [],
      "source": [
        "val_df = get_dataframe(val_paths[:100])\n",
        "test_df = get_dataframe(test_paths[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>original</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/00859...</td>\n",
              "      <td>Cảnh_sát bang Jharkhand , phía đông Ấn_Độ hôm ...</td>\n",
              "      <td>Dhanu_Bhuiyan bị buộc_tội cưỡng_hiếp thiếu_nữ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/00904...</td>\n",
              "      <td>Tấm cửa_sổ bằng nhựa có kích_thước 58 x 47 cm ...</td>\n",
              "      <td>Trực_thăng CH -53 E của thuỷ_quân_lục_chiến Mỹ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/01516...</td>\n",
              "      <td>Ngày 3/12 , ông Phạm_Văn_Ru , Trưởng_ban Tổ_ch...</td>\n",
              "      <td>Do vẫn mong_muốn được công_tác , bà Phan_Thị_M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/00560...</td>\n",
              "      <td>Ngoại_trưởng Zarif khẳng_định Iran không muốn ...</td>\n",
              "      <td>Ngoại_trưởng Iran_Mohammad_Javad_Zarif dịu giọ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/vietnews-master/data/test_tokenized/01738...</td>\n",
              "      <td>Trò_chuyện với chúng_tôi , H. gửi tấm hình hai...</td>\n",
              "      <td>“ Có dịp vui anh_em lại tổ_chức “ bay ” thôi ....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                file  \\\n",
              "0  data/vietnews-master/data/test_tokenized/00859...   \n",
              "1  data/vietnews-master/data/test_tokenized/00904...   \n",
              "2  data/vietnews-master/data/test_tokenized/01516...   \n",
              "3  data/vietnews-master/data/test_tokenized/00560...   \n",
              "4  data/vietnews-master/data/test_tokenized/01738...   \n",
              "\n",
              "                                            original  \\\n",
              "0  Cảnh_sát bang Jharkhand , phía đông Ấn_Độ hôm ...   \n",
              "1  Tấm cửa_sổ bằng nhựa có kích_thước 58 x 47 cm ...   \n",
              "2  Ngày 3/12 , ông Phạm_Văn_Ru , Trưởng_ban Tổ_ch...   \n",
              "3  Ngoại_trưởng Zarif khẳng_định Iran không muốn ...   \n",
              "4  Trò_chuyện với chúng_tôi , H. gửi tấm hình hai...   \n",
              "\n",
              "                                             summary  \n",
              "0  Dhanu_Bhuiyan bị buộc_tội cưỡng_hiếp thiếu_nữ ...  \n",
              "1  Trực_thăng CH -53 E của thuỷ_quân_lục_chiến Mỹ...  \n",
              "2  Do vẫn mong_muốn được công_tác , bà Phan_Thị_M...  \n",
              "3  Ngoại_trưởng Iran_Mohammad_Javad_Zarif dịu giọ...  \n",
              "4  “ Có dịp vui anh_em lại tổ_chức “ bay ” thôi ....  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_df.to_parquet(\"data/vietnews/test.parquet\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_df = pd.read_parquet(\"data/vietnews/train.parquet\")\n",
        "# val_df = pd.read_parquet(\"data/vietnews/val.parquet\")\n",
        "# test_df = pd.read_parquet(\"data/vietnews/test.parquet\")\n",
        "# test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# train_df['word_count'] = train_df['summary'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# # Plot the histogram\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.hist(train_df['word_count'], bins=100, edgecolor='black')\n",
        "# plt.title('Histogram of Number of Words in Sentences')\n",
        "# plt.xlabel('Number of Words')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1F58j028eTV"
      },
      "source": [
        "## **Warm-starting RoBERTaShared for BBC XSum**\n",
        "\n",
        "***Note***: This notebook only uses a few training, validation, and test data samples for demonstration purposes. To fine-tune an encoder-decoder model on the full training data, the user should change the training and data preprocessing parameters accordingly as highlighted by the comments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FO5ESocXvlK"
      },
      "source": [
        "### **Data Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sgTiC0rhMb7C"
      },
      "outputs": [],
      "source": [
        "pretrained_model = \"google-t5/t5-small\"\n",
        "# pretrained_model = \"Falconsai/text_summarization\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Vietnam_T5_small_200\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "U08MrUK9LcUM"
      },
      "outputs": [],
      "source": [
        "train_data =  Dataset.from_pandas(train_df)\n",
        "val_data =  Dataset.from_pandas(val_df)\n",
        "test_data =  Dataset.from_pandas(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "70bb7c0669ca4a3699ad36dfdcc10910",
            "1ba158d2f09a4c54bc647ebe77d27b60",
            "5ac8ad6eea254d369996622911a6a79e",
            "0aeb387a0f53469c8ff42e57647831d8",
            "efd6b87b93244d5ca6817ab35c385510",
            "e22006901f10483882e1a1f20f645b24",
            "01644f724526402c9f139e19b2035073",
            "7097c890712d418e9dd9c3e33873a2d5",
            "b3ddde0882d841daa3bfde43ed6e6fc9",
            "09375b2aac814adcbb51589402eb8b68",
            "cab0cd369bfa4c80b963ebd27d3e4974",
            "db0264404d934633824b5b381b31a5ac",
            "63276058881e45539d8dcd4ff2e05edd",
            "03b57581ace346d2bde4378a7c6309ca",
            "5507016090f64bb99dcbf88e14d71eda",
            "0d6a0b11ec2a4c6d975857678415f505"
          ]
        },
        "id": "yoN2q0hZUbXN",
        "outputId": "20c6562f-7358-4dc7-dada-787bede963bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 100/100 [00:00<00:00, 810.20 examples/s]\n",
            "Map: 100%|██████████| 100/100 [00:00<00:00, 756.94 examples/s]\n"
          ]
        }
      ],
      "source": [
        "batch_size=16 # change to 16 for full training\n",
        "block_size = 128\n",
        "max_input_length = 512 #1024\n",
        "max_target_length = 128 #128\n",
        "\n",
        "def process_data_to_model_inputs(examples):\n",
        "    return tokenizer([\" \".join(x) for x in examples[\"original\"]])\n",
        "\n",
        "# def process_data_to_model_inputs(batch):\n",
        "#     model_inputs = tokenizer(\n",
        "#         batch[\"original\"],\n",
        "#         max_length=max_input_length,\n",
        "#         truncation=True,\n",
        "#     )\n",
        "#     labels = tokenizer(\n",
        "#         batch[\"summary\"], max_length=max_target_length, truncation=True\n",
        "#     )\n",
        "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "#     return model_inputs\n",
        "\n",
        "# only use 32 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# train_data = train_data.select(range(32))\n",
        "\n",
        "train_data_batch = train_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"file\",\"original\", \"summary\"],\n",
        ")\n",
        "train_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\"],\n",
        ")\n",
        "\n",
        "\n",
        "# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "# val_data = val_data.select(range(16))\n",
        "\n",
        "val_data_batch = val_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"file\", \"original\", \"summary\"],\n",
        ")\n",
        "val_data_batch.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\"],\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "can only concatenate list (not \"Tensor\") to list",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/datasets/utils/py_utils.py\", line 678, in _write_generator_to_queue\n    for i, result in enumerate(func(**kwargs)):\n  File \"/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py\", line 3547, in _map_single\n    batch = apply_function_on_filtered_inputs(\n  File \"/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py\", line 3416, in apply_function_on_filtered_inputs\n    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n  File \"/tmp/ipykernel_410785/1835567460.py\", line 3, in group_texts\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n  File \"/tmp/ipykernel_410785/1835567460.py\", line 3, in <dictcomp>\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\nTypeError: can only concatenate list (not \"Tensor\") to list\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m     result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m         k: [t[i : i \u001b[38;5;241m+\u001b[39m block_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, total_length, block_size)]\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m concatenated_examples\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     13\u001b[0m     }\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m---> 16\u001b[0m lm_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/code_Bao/ViT5/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
            "File \u001b[0;32m~/code_Bao/ViT5/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
            "File \u001b[0;32m~/code_Bao/ViT5/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3248\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3242\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3243\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3244\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3245\u001b[0m     total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3246\u001b[0m     desc\u001b[38;5;241m=\u001b[39m(desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (num_proc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3248\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m iflatmap_unordered(\n\u001b[1;32m   3249\u001b[0m         pool, Dataset\u001b[38;5;241m.\u001b[39m_map_single, kwargs_iterable\u001b[38;5;241m=\u001b[39mkwargs_per_job\n\u001b[1;32m   3250\u001b[0m     ):\n\u001b[1;32m   3251\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3252\u001b[0m             shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m~/code_Bao/ViT5/venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:718\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m         [async_result\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
            "File \u001b[0;32m~/code_Bao/ViT5/venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:718\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m         [\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
            "File \u001b[0;32m~/code_Bao/ViT5/venv/lib/python3.10/site-packages/multiprocess/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"Tensor\") to list"
          ]
        }
      ],
      "source": [
        "def group_texts(examples):\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
        "    # customize this part to your needs.\n",
        "    if total_length >= block_size:\n",
        "        total_length = (total_length // block_size) * block_size\n",
        "    # Split by chunks of block_size.\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    return result\n",
        "\n",
        "lm_dataset = train_data_batch.map(group_texts, batched=True, num_proc=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "file        data/vietnews-master/data/train_tokenized/0012...\n",
              "original    Kịch_bản của kẻ_cướp ngân_hàng Liên_quan đến v...\n",
              "summary     Liên_quan đến vụ cướp ngân_hàng Agribank ở Thá...\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Liên_quan đến vụ cướp ngân_hàng Agribank ở Thái_Bình , lãnh_đạo Công_an tỉnh Thái_Bình cho biết , trước khi gây án , nghi_phạm đã có kế_hoạch chuẩn_bị rất kỹ , dùng các chiêu để đánh lạc hướng mọi người xung_quanh . \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': [712, 2, 12364, 149, 178, 1069, 123, 690, 105, 2, 2054, 3044, 2161, 103, 135, 672, 2, 9145, 103, 104, 409, 113, 2, 148, 536, 121, 248, 2, 117, 105, 260, 672, 2, 9145, 122, 182, 103, 104, 235, 109, 145, 546, 125, 103, 143, 105, 103, 104, 787, 2, 123, 1632, 127, 119, 564, 2, 113, 121, 5114, 581, 556, 2, 337, 1673, 317, 108, 103, 190, 524, 103, 104, 415, 115, 120, 2186, 111, 141, 445, 1126, 103, 113, 513, 709, 130, 862, 115, 2, 12364, 113, 103, 106, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = tokenizer(str(train_df[\"summary\"].iloc[0]))\n",
        "print(str(train_df[\"summary\"].iloc[0]))\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['▁Liên', '<unk>', 'quan', '▁đến', '▁vụ', '▁cướ', 'p', '▁ngâ', 'n', '<unk>']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(train_data_batch[0][\"labels\"])[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_data_batch[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEjb026cNC38"
      },
      "source": [
        "### **Warm-starting the Encoder-Decoder Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generation_config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(pretrained_model).to(device)\n",
        "\n",
        "my_config = model.generation_config\n",
        "print(\"generation_config\", model.generation_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u98CLZiTkgzv"
      },
      "source": [
        "### **Fine-Tuning Warm-Started Encoder-Decoder Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gYzA-w96wCt"
      },
      "source": [
        "The `Seq2SeqTrainer` that can be found under [examples/seq2seq/seq2seq_trainer.py](https://github.com/huggingface/transformers/blob/master/examples/seq2seq/seq2seq_trainer.py) will be used to fine-tune a warm-started encoder-decoder model.\n",
        "\n",
        "Let's download the `Seq2SeqTrainer` code and import the module along with `TrainingArguments`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nmQRT3XuHHz"
      },
      "source": [
        "We need to add some additional parameters to make `TrainingArguments` compatible with the `Seq2SeqTrainer`. Let's just copy the `dataclass` arguments as defined in [this file](https://github.com/patrickvonplaten/transformers/blob/make_seq2seq_trainer_self_contained/examples/seq2seq/finetune_trainer.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPUAgo7pxH24"
      },
      "source": [
        "Also, we need to define a function to correctly compute the ROUGE score during validation. ROUGE is a much better metric to track during training than only language modeling loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "rouge_score = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Decode generated summaries into text\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    # Decode reference summaries into text\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge_score.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract the median scores\n",
        "    result = {key: value * 100 for key, value in result.items()}\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/data/data_collator.py:646: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 489, 1181,    2,  ...,  103,  117,    1],\n",
              "        [ 103, 1454,  165,  ...,  322,  107,    1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[  712,     2, 12364,   149,   178,  1069,   123,   690,   105,     2,\n",
              "          2054,  3044,  2161,   103,   135,   672,     2,  9145,   103,   104,\n",
              "           409,   113,     2,   148,   536,   121,   248,     2,   117,   105,\n",
              "           260,   672,     2,  9145,   122,   182,   103,   104,   235,   109,\n",
              "           145,   546,   125,   103,   143,   105,   103,   104,   787,     2,\n",
              "           123,  1632,   127,   119,   564,     2,   113,   121,  5114,   581,\n",
              "           556,     2,   337,  1673,   317,   108,   103,   190,   524,   103,\n",
              "           104,   415,   115,   120,  2186,   111,   141,   445,  1126,   103,\n",
              "           113,   513,   709,   130,   862,   115,     2, 12364,   113,   103,\n",
              "           106,     1],\n",
              "        [ 2263,   967,   204,   157,   553,   103,   739,   103,   104,   232,\n",
              "           129,  1378,   157,   270,   237,  1173,   108,     2,   362,   542,\n",
              "          1465,   105,  1173,   108,     2,  1051,   112,     2,   208,  1181,\n",
              "           103,   105,   156,   121,   103,   135,   225,     2,   598,   117,\n",
              "           112,   103,   104,   114,   167,   535,   144,   220,     2,   110,\n",
              "           107,   117,   105,   141,   481,   107,     2,   115,   113,  1238,\n",
              "           154,   220,     2,   190,  8421,   258,     2,   108,   113,  1575,\n",
              "          1378,   157,   270,   305,   103,   627,   103,   135,  1568,     2,\n",
              "           275,   135,   136,   103,   106,     1,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100]]), 'decoder_input_ids': tensor([[    0,   712,     2, 12364,   149,   178,  1069,   123,   690,   105,\n",
              "             2,  2054,  3044,  2161,   103,   135,   672,     2,  9145,   103,\n",
              "           104,   409,   113,     2,   148,   536,   121,   248,     2,   117,\n",
              "           105,   260,   672,     2,  9145,   122,   182,   103,   104,   235,\n",
              "           109,   145,   546,   125,   103,   143,   105,   103,   104,   787,\n",
              "             2,   123,  1632,   127,   119,   564,     2,   113,   121,  5114,\n",
              "           581,   556,     2,   337,  1673,   317,   108,   103,   190,   524,\n",
              "           103,   104,   415,   115,   120,  2186,   111,   141,   445,  1126,\n",
              "           103,   113,   513,   709,   130,   862,   115,     2, 12364,   113,\n",
              "           103,   106],\n",
              "        [    0,  2263,   967,   204,   157,   553,   103,   739,   103,   104,\n",
              "           232,   129,  1378,   157,   270,   237,  1173,   108,     2,   362,\n",
              "           542,  1465,   105,  1173,   108,     2,  1051,   112,     2,   208,\n",
              "          1181,   103,   105,   156,   121,   103,   135,   225,     2,   598,\n",
              "           117,   112,   103,   104,   114,   167,   535,   144,   220,     2,\n",
              "           110,   107,   117,   105,   141,   481,   107,     2,   115,   113,\n",
              "          1238,   154,   220,     2,   190,  8421,   258,     2,   108,   113,\n",
              "          1575,  1378,   157,   270,   305,   103,   627,   103,   135,  1568,\n",
              "             2,   275,   135,   136,   103,   106,     1,     0,     0,     0,\n",
              "             0,     0]])}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = [train_data_batch[i] for i in range(2)]\n",
        "data_collator(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ik4hZb2yV-b"
      },
      "source": [
        "Cool! Finally, we start training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "LAaTxUpdzshF",
        "outputId": "7e103b00-0ac7-41c0-84a4-884932474b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logging_steps 12\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 01:12, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.525600</td>\n",
              "      <td>5.013842</td>\n",
              "      <td>5.130100</td>\n",
              "      <td>1.110400</td>\n",
              "      <td>4.345400</td>\n",
              "      <td>4.461800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.386600</td>\n",
              "      <td>5.012387</td>\n",
              "      <td>5.280100</td>\n",
              "      <td>1.159200</td>\n",
              "      <td>4.485600</td>\n",
              "      <td>4.609600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.533100</td>\n",
              "      <td>5.010102</td>\n",
              "      <td>5.280100</td>\n",
              "      <td>1.159200</td>\n",
              "      <td>4.485600</td>\n",
              "      <td>4.609600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.374500</td>\n",
              "      <td>5.006131</td>\n",
              "      <td>5.223300</td>\n",
              "      <td>1.159200</td>\n",
              "      <td>4.430900</td>\n",
              "      <td>4.548300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5.546100</td>\n",
              "      <td>5.002307</td>\n",
              "      <td>4.946200</td>\n",
              "      <td>1.005100</td>\n",
              "      <td>4.177800</td>\n",
              "      <td>4.312700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>5.326000</td>\n",
              "      <td>4.996574</td>\n",
              "      <td>4.991400</td>\n",
              "      <td>1.007500</td>\n",
              "      <td>4.173100</td>\n",
              "      <td>4.309000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>5.543200</td>\n",
              "      <td>4.990853</td>\n",
              "      <td>5.152900</td>\n",
              "      <td>1.161400</td>\n",
              "      <td>4.286900</td>\n",
              "      <td>4.397700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>5.448200</td>\n",
              "      <td>4.982821</td>\n",
              "      <td>5.022300</td>\n",
              "      <td>0.970900</td>\n",
              "      <td>4.151300</td>\n",
              "      <td>4.234600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>5.400600</td>\n",
              "      <td>4.973183</td>\n",
              "      <td>5.219900</td>\n",
              "      <td>1.014600</td>\n",
              "      <td>4.291000</td>\n",
              "      <td>4.382300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>5.455800</td>\n",
              "      <td>4.963674</td>\n",
              "      <td>5.325900</td>\n",
              "      <td>1.043200</td>\n",
              "      <td>4.358900</td>\n",
              "      <td>4.431200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mrzaizai2k/code_Bao/ViT5/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=130, training_loss=5.448418279794546, metrics={'train_runtime': 72.9699, 'train_samples_per_second': 13.704, 'train_steps_per_second': 1.782, 'total_flos': 135341801472000.0, 'train_loss': 5.448418279794546, 'epoch': 10.0})"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set training arguments - these params are not really tuned, feel free to change\n",
        "logging_steps = min(2000,len(train_data_batch) // batch_size)\n",
        "print(\"logging_steps\", logging_steps)\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir= OUTPUT_DIR,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    # do_train=True,\n",
        "    # do_eval=True,\n",
        "    logging_steps=logging_steps,  # set to 2000 for full training\n",
        "    save_steps=500,  # set to 500 for full training\n",
        "    eval_steps=750,  # set to 7500 for full training\n",
        "    warmup_steps=3000,  # set to 3000 for full training\n",
        "    num_train_epochs=10, #uncomment for full training\n",
        "    overwrite_output_dir=True,\n",
        "    optim='adafactor',\n",
        "    save_total_limit=3,\n",
        "    push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data_batch,\n",
        "    eval_dataset=val_data_batch,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]\n",
            "\u001b[A\n",
            "\n",
            "training_args.bin: 100%|██████████| 5.30k/5.30k [00:00<00:00, 14.2kB/s]\n",
            "events.out.tfevents.1718077729.DESKTOP-H2CRQMR.405568.0: 100%|██████████| 13.0k/13.0k [00:00<00:00, 33.5kB/s]\n",
            "model.safetensors: 100%|██████████| 242M/242M [00:23<00:00, 10.2MB/s] \n",
            "Upload 3 LFS files: 100%|██████████| 3/3 [00:24<00:00,  8.05s/it]\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7854KKs6EY4x"
      },
      "outputs": [],
      "source": [
        "# !gsutil -m cp -r '/content/training/*' 'gs://kaggle-vbdi-test/training_Data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwQIEhKOrJpl"
      },
      "source": [
        "### **Evaluation**\n",
        "\n",
        "Awesome, we finished training our dummy model. Let's now evaluated the model on the test data. We make use of the dataset's handy `.map()` function to generate a summary of each sample of the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0ef7f4e43319429d9277d55c83cb084d",
            "ab543b6ef5b34ed4acb85fd25304ed75",
            "825d4b325e9b45859e808cd6b14fdd42",
            "dd0bdf658c6d4c0cb0a091129ecbebb0",
            "f7c296a0b8a84ee3be45c92edb6aad21",
            "e21d97b40ffa43668b9962c5d771debb",
            "a4898ec38618401396928eee2c4f9926",
            "3598a3c015a64c20be134cf4d2e7fbbe"
          ]
        },
        "id": "oOoSrwWarJAC",
        "outputId": "67b60b74-c47c-4718-82a7-072f85a32c4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Parameter 'function'=<function generate_summary at 0x7f423895ff40> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "WARNING:datasets.fingerprint:Parameter 'function'=<function generate_summary at 0x7f423895ff40> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generation_config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 100/100 [00:08<00:00, 11.36 examples/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model, use_fast=False)\n",
        "\n",
        "# model = EncoderDecoderModel.from_pretrained(OUTPUT_DIR + \"/checkpoint-4000\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(OUTPUT_DIR, torch_dtype=torch.bfloat16,).to(device)\n",
        "print(\"generation_config\", model.generation_config)\n",
        "\n",
        "\n",
        "# test_data = datasets.load_dataset(\"xsum\", split=\"test\")\n",
        "\n",
        "batch_size = 16  # change to 64 for full evaluation\n",
        "\n",
        "# map data correctly\n",
        "def generate_summary(batch):\n",
        "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
        "    inputs = tokenizer(batch[\"original\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask,\n",
        "                             max_length=128,\n",
        "                        # num_beams=4,\n",
        "                        # no_repeat_ngram_size=3,\n",
        "                        # early_stopping=True,\n",
        "                        )\n",
        "\n",
        "    # all special tokens including will be removed\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    batch[\"pred\"] = output_str\n",
        "\n",
        "    return batch\n",
        "\n",
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"original\"])\n",
        "\n",
        "pred_str = results[\"pred\"]\n",
        "label_str = results[\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHl8NMjEiTb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rouge1': 34.278702846384604,\n",
              " 'rouge2': 8.099618792816216,\n",
              " 'rougeL': 22.1942267098939,\n",
              " 'rougeLsum': 22.140831895853147}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rouge_output = rouge_score.compute(predictions=pred_str, references=label_str, use_stemmer=True)\n",
        "rouge_output = {key: value * 100 for key, value in rouge_output.items()}\n",
        "rouge_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8R5CclwUGuC",
        "outputId": "9b53d98d-8d04-49b5-c55a-d47530564398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction:  trong bà Mnh vit trong bà Mnh vit trong bà Mnh vit trong bà Mnh vit trong bà Mnh vit trong bà Mnh vit trong bà trong bà th công_b trên mt din\n",
            "Truth:  Lần đầu_tiên kể từ khi bị bắt tại Canada tháng 12-2018 , giám_đốc tài_chính toàn_cầu công_ty Huawei , bà Mạnh_Vãn_Chu , gửi thư tới 188.000 nhân_viên công_ty này , cảm_ơn sự động_viên của họ . \n",
            "Content:  Theo đài CNN , trong bản_sao bức thư họ nhận được , bà Mạnh cảm_ơn gần 200.000 nhân_viên Huawei toàn_cầu vì đã hết_lòng ủng_hộ , động_viên bà , trao cho bà \" sức_mạnh \" trong thời_gian qua . Bà Mạnh_Vãn_Chu vẫn đang chờ_đợi phiên xử tại toà Canada để quyết_định việc có bị dẫn_độ qua Mỹ xét_xử không . Chính_quyền Mỹ cáo_buộc bà Mạnh vi_phạm các lệnh trừng_phạt của Mỹ với Iran . \" Cứ mỗi khi phiên xét_xử kết_thúc , tôi lại thấy các nhân_viên của Huawei đứng chờ trắng đêm chỉ để theo_dõi vụ_việc của tôi theo các múi thời_gian cách xa nhau \" , bà Mạnh viết trong bức thư được công_bố trên một diễn_đàn mạng nội_bộ của công_ty Huawei . \" Điều này làm tôi ứa nước_mắt \" . Vụ_việc liên_đới tới bà Mạnh diễn ra trong bối_cảnh công_ty Huawei đối_mặt với nhiều sức_ép từ chính_phủ Mỹ . Chính_quyền tại Washington cáo_buộc các thiết_bị mạng của Huawei tiềm_ẩn nguy_cơ đối_với an_ninh quốc_gia . Không_chỉ thế , Huawei cũng đang đối_mặt với những cáo_buộc tại Seattle cho_rằng công_ty này đã cố_tình đánh_cắp các bí_mật thương_mại của hãng T - Mobile . Tuy_nhiên bà Mạnh và công_ty Huawei cho tới nay vẫn bác_bỏ những cáo_buộc đó . Cũng trong bức thư đầy cảm_xúc , bà Mạnh cho_biết cảm_thấy được động_viên rất nhiều qua những thông_điệp chia_sẻ của mọi người trên diễn_đàn của công_ty , và qua hình_ảnh các cựu nhân_viên của công_ty xếp_hàng bên ngoài trụ_sở toà_án ở thành_phố Vancouver , Canada . Hai tuần sau khi bị bắt , bà Mạnh được tại_ngoại sau khi nộp 7,5 triệu USD tiền bảo_lãnh . Bà cũng đã nộp lại toàn_bộ hộ_chiếu của mình . Hiện bà đang sống tại một trong hai căn nhà thuộc sở_hữu của bà tại thành_phố Vancouver . Bà cũng phải thanh_toán chi_phí canh_gác 24/24 của lực_lượng an_ninh và đeo còng điện_tử có gắn định_vị GPS . \" Bất_kể việc bị hạn_chế về thể_chất trong một không_gian giới_hạn khi sống tại Vancouver , nhưng trong lòng mình , tôi chưa bao_giờ cảm_thấy sự sinh_động và mênh_mông đến thế \" , bà Mạnh viết . Vụ bắt_giữ giám_đốc tài_chính toàn_cầu của Huawei đã dẫn tới những căng_thẳng ngoại_giao giữa Canada , Trung_Quốc và Mỹ thời_gian qua . Nó cũng đã làm phức_tạp thêm tiến_trình đàm_phán thương_mại Mỹ - Trung . Huawei là nhà_sản_xuất thiết_bị viễn_thông lớn nhất thế_giới . Tuần trước , công_ty này cáo_buộc quá_trình xét_xử vấn_đề dẫn_độ bà Mạnh đang có sự chi_phối bởi các yếu_tố chính_trị , theo đó có_thể vi_phạm \" các quyền hợp_pháp \" của bà . Tháng 3 năm nay , bà Mạnh cũng đã khởi_kiện nhà_chức_trách Canada vì đã vi_phạm các quyền của bà ở thời_điểm họ bắt bà năm_ngoái . Dự_kiến bà Mạnh sẽ phải trình_diện trở_lại tại toà Canada trong tháng 9 tới .  Bà Mạnh_Vãn_Chu - Ảnh : AFP \n",
            "\n",
            "Prediction:  c xut_khu v khách_hàng và s_lng máy_bay Su -32, phiên_bn xut_khu ca tiêm_khu v tiêm_khu và s_lng máy_bay Su -34\n",
            "Truth:  Nhiều quốc_gia tỏ ý quan_tâm tới tiêm_kích bom hiện_đại Su -34 của Nga nhờ hiệu_quả chiến_đấu tại Syria . \n",
            "Content:  Su -34 biểu_diễn tại triển_lãm hàng_không Moscow 2017 . Nga đang thảo_luận với hàng_loạt đối_tác nước_ngoài về việc xuất_khẩu máy_bay Su -32 , phiên_bản xuất_khẩu của tiêm_kích bom Su -34 từng được Moscow triển_khai để ném bom phiến quân Nhà_nước Hồi_giáo ( IS ) ở Syria , Sputnik ngày 19/7 đưa tin . \" Nhiều nước dành sự quan_tâm lớn cho dòng Su -34 , vốn đạt hiệu_quả chiến_đấu rất cao trong chiến_dịch quân_sự tại Syria . Các cuộc đàm_phán dang diễn ra , nhưng còn quá sớm để tiết_lộ thông_tin về khách_hàng và số_lượng máy_bay sẽ được xuất_khẩu \" , Giám_đốc Cơ_quan Hợp_tác Kỹ_thuật Quân_sự ( FSMTC ) Nga Dmitry_Shugaev tuyên_bố . Hồi tháng 5 , tập_đoàn xuất_khẩu vũ_khí Nga_Rosoboronexport cho_biết một_số quốc_gia Trung_Đông như Jordan đã đề_cập tới việc đặt mua tiêm_kích bom Su -32 . Algeria cũng có kế_hoạch đặt mua 12 chiếc Su -34 và có_thể tăng đơn hàng lên 40 chiếc . Có biệt_danh \" thú mỏ vịt \" nhờ phần mũi bẹt , Su -34 là dòng tiêm kích bom hiện_đại được chế_tạo nhằm thay_thế cho máy_bay ném bom chiến_thuật Su -24 . Ngoài nhiệm_vụ tấn_công mặt_đất , Su -34 còn có khả_năng không_chiến tốt nhờ trang_bị các loại tên_lửa tầm ngắn và tầm_xa . Không_quân Nga đang là lực_lượng duy_nhất vận_hành loại tiêm_kích bom tối_tân này với số_lượng khoảng 103 chiếc , phân_bố tại 6 căn_cứ không_quân khác nhau trên lãnh_thổ Nga và Syria . Tử_Quỳnh   Su -34 biểu_diễn tại triển_lãm hàng_không Moscow 2017 . Tiêm_kích Su -34 với cấu_hình vũ_khí chống hạm . \n",
            "\n",
            "Prediction:  c phong_to  phc_v iu_tra. Chiu 28/12, ngi_dân c phong_to  phc_v iu_tra. Chiu 28/12, ngi_dân c phong_to  phc_v iu_tra.\n",
            "Truth:  Cả hai rơi từ tầng 14 chung_cư tại quận 2 ( TP HCM ) , nam thanh_niên tử_vong tại_chỗ , đứa bé còn thoi_thóp được đưa đi cấp_cứu . \n",
            "Content:  Hiện_trường được phong_toả để phục_vụ điều_tra . Chiều 28/12 , người_dân ở lô C - D , khu chung_cư Bình_Khánh ( phường An_Phú quận 2 ) hốt_hoảng khi phát_hiện 2 người rơi từ trên cao xuống đất . Người đàn_ông khoảng 30 tuổi tử_vong tại_chỗ ; bé trai gần một tuổi nằm cạnh , thoi_thóp . \" Tôi đang ở gần đó , giật_mình vì tiếng_động rất mạnh . Nhiều người cũng chạy đến , ai cũng sợ vì cảnh_tượng ấy . Đứa bé được mọi người bắt taxi đưa đi bệnh_viện ngay , nhìn đau_lòng lắm \" , một nhân_chứng kể . Đến 16h30 hiện_trường được giải_toả , nguyên_nhân vụ_việc đang được điều_tra . Khuya cùng ngày , bé trai tử_vong do trấn_thương quá nặng . Sơn_Hoà   Hiện_trường được phong_toả để phục_vụ điều_tra . \n",
            "\n",
            "Prediction:  ông th khi phê thuc nh_im, ci trn, ngi t_vong và 5 ngi t_vong vào con_ng \"...................\n",
            "Truth:  “ Có dịp vui anh_em lại tổ_chức “ bay ” thôi . Đủ thành_phần , già trẻ , trai_gái gì đều chơi hết ” - H. ( 30 tuổi ) , dân “ bay ” có thâm_niên 10 năm ở TP. HCM , tiết_lộ . \n",
            "Content:  Trò_chuyện với chúng_tôi , H. gửi tấm hình hai đàn_em là dân \" bay \" chuyên_nghiệp mặc quần_soóc , cởi trần , ngồi gục tại ghế với đôi mắt đờ_đẫn bởi phê thuốc lắc . Sau vụ 7 người tử_vong và 5 người hôn_mê do sốc ma_tuý tại lễ_hội âm_nhạc ở Hà_Nội , dân_chơi này đánh_giá : \" Trong bối_cảnh người đông thì khi phê thuốc đỉnh_điểm , ảo mạnh không đủ không_khí để thở , cộng thêm nhạc không đủ nên gãy hàng đột_ngột \" . Cuộc_chơi biến_dạng não_bộ H. cho_biết nhiều bạn_bè H. đi \" bay \" liên_tục do nghiện nặng . Mới_đây , có người tử_vong bởi sốc thuốc . Từ năm 2006 , H. bắt_đầu dấn_thân vào con_đường \" cắn \" thuốc tại các quán bar , karaoke . Từ chỗ bạn_bè rủ_rê thử cho vui , giờ_đây hiếm có cuộc vui nào thiếu các món thuốc lắc , cỏ mỹ , hồng phiến , hàng đá hay bóng cười . Theo H. , hiện_nay dân_chơi đang kháo nhau một loại \" kẹo \" vừa_mới được tung ra thị_trường phê rất mạnh . Bóng cười , cỏ mỹ , đá phổ_biến vì rẻ , còn kẹo ( thuốc lắc ) đắt hơn nên ít người có điều_kiện sử_dụng . Chơi cỏ thì ảo , còn chơi đá , kẹo , ke thì ngáo . Không chơi thì thôi chứ chơi các loại ma_tuý này rồi thì thường rơi vào trạng_thái lơ_ngơ như người mất_hồn vài ngày , không ăn , không ngủ . Đặc_biệt , người chơi có những lời_nói , hành_động nguy_hiểm do mất kiểm_soát . Cách \" bay \" của giới trẻ bây_giờ cũng khác xưa . Nếu ngày_xưa \" bay \" phổ_biến ở quán bar thì bây_giờ để an_toàn , tạo cảm_giác thoải_mái gần_gũi , dân \" bay \" có xu_hướng chuyển vào trong các khách_sạn 5 sao và resort . Tại_sao lại không \" bay \" trong quán bar ? \" Trong bar người ra vào tạp nham phiền_phức , chưa kể dễ bị công_an kiểm_tra \" - H. khẳng_định . Ngoài_ra , theo H. , để lôi_kéo dân_chơi , hiện một_số nhà_hàng karaoke thiết_kế phòng để phục_vụ cho dân \" bay \" được thoải_mái , an_toàn . Huỷ_hoại giới trẻ Sở Y_tế TP. HCM cho_rằng tình_hình mua_bán và sử_dụng trái_phép các chất ma_tuý vẫn tiếp_tục tiềm_ẩn , diễn_biến phức_tạp . Mua_bán , sử_dụng ma_tuý nhỏ_lẻ trong cộng_đồng dân_cư , các nơi công_cộng còn diễn ra . Xu_hướng người dùng ma_tuý tổng_hợp ngày_càng tăng , tập_trung nhiều vào giới trẻ khu_vực đô_thị . Báo_động này được thể_hiện khá cụ_thể trong báo_cáo của Sở LĐ - TB & XH TP với lượng người lạm_dụng các chất ma_tuý tổng_hợp được đưa vào các cơ_sở chữa bệnh ngày_càng nhiều . \" Nếu_như năm 2012 trong số khoảng 9.000 người đang chữa bệnh tại trung_tâm cai_nghiện chỉ có 5 % nghiện ma_tuý tổng_hợp thì đến năm 2013 tỉ_lệ này cao gấp hơn 3 lần , đến 17,5 % \" - báo_cáo nêu . Mới_đây , trong báo_cáo về tình_hình , kết_quả công_tác phòng_chống tội_phạm , phòng_chống ma_tuý , UBND TP cho_rằng ma_tuý tổng_hợp đang xuất_hiện với tốc_độ tăng qua các vụ án ma_tuý đã triệt_phá . Theo đó , năm 2015 số ma_tuý tổng_hợp thu_giữ đến 87,1 kg , trước đó chỉ khoảng 3,5 kg , ở một_số quận_huyện \" hàng đá \" bị bắt_giữ thậm_chí còn cao gấp 5-8 lần lượng heroin . Công_an TP. HCM ước_tính tình_trạng sử_dụng ma_tuý tổng_hợp ở giới trẻ ngày_càng tăng cao , chiếm 70 - 80 % ở độ tuổi dưới 30 . Việc dùng ma_tuý tổng_hợp lâu ngày sẽ chuyển sang một dạng ma_tuý mạnh hơn là heroin . Từ việc dùng bằng đường uống , hút chuyển qua đường tiêm_chích để phê nhanh , mạnh hơn . Bác_sĩ Trịnh_Tất_Thắng - giám_đốc Bệnh_viện Tâm_thần TP. HCM - cho_biết trong những năm qua , điều_tra dịch_tễ cắt ngang về tần_suất các loại bệnh_tâm_thần thường gặp trong dân_chúng tại TP cho thấy có đến 16 % dân_số có_thể có vấn_đề về sức_khoẻ tâm_thần , trong đó nhóm loạn thần liên_quan đến chất kích_thích ngày_càng tăng cao ở người trẻ .  Ma_tuý đang lôi_kéo nhiều người trẻ vào vòng xoáy nghiện_ngập . Trong ảnh : một nam thanh_niên đang điều_trị uống thuốc methadone nhằm cắt_cơn nghiện tại Trung_tâm Y_tế dự_phòng Q. Gò_Vấp , TP. HCM - Ảnh HOÀNG_LỘC \n",
            "\n",
            "Prediction:  ng_lot ti các Chnh_ph ch ra trong báo_cáo Chnh_ph tng_hp kt_quyt ti các Chnh_ph và giám_xét gii_quyt tng tr\n",
            "Truth:  Để xử_lý triệt_để , dứt_điểm các bất_cập của trạm thu phí BOT , Nhà_nước cần bố_trí vốn để mua lại các dự_án , nhưng trong giai_đoạn hiện_nay rất khó cân_đối đủ vốn để thực_hiện . \n",
            "Content:  Đánh_giá trên được Chính_phủ đưa ra trong báo_cáo tổng_hợp kết_quả thực_hiện các nghị_quyết , kết_luận của Uỷ_ban Thường_vụ_Quốc_hội về chất_vấn và giám_sát chuyên_đề từ đầu nhiệm_kỳ đến hết năm 2018 mới_đây . Hiện_nay , Thủ_tướng đang giao Bộ Giao_thông vận_tải ( GTVT ) tiếp_tục rà_soát báo_cáo Chính_phủ xem_xét giải_quyết từng trạm BOT , bảo_đảm hài_hoà lợi_ích giữa Nhà_nước , nhà_đầu_tư và người sử_dụng . Báo_cáo của Chính_phủ chỉ ra hàng_loạt tồn_tại cần giải_quyết tại các công_trình giao_thông đầu_tư theo hình_thức BOT đã và đang triển_khai . Một_số nhà_đầu_tư BOT không đồng_ý giảm trừ lãi vay trong thời_gian xây_dựng chưa tính trong tổng mức đầu_tư dự_án BOT và mức chi_phí bảo_toàn vốn trên phần vốn chủ_sở_hữu , nên đến nay chưa thể đàm_phán điều_chỉnh hợp_đồng một_số dự_án BOT . Nếu Nhà_nước đơn_phương điều_chỉnh hợp_đồng BOT thì có_thể sẽ dẫn đến các tranh_chấp pháp_lý , sẽ tác_động tiêu_cực đến việc thu_hút các nhà_đầu_tư tham_gia thực_hiện dự_án PPP trong thời_gian tới . Chính_phủ đã chỉ_đạo các bộ làm_việc với Kiểm_toán Nhà_nước để tháo_gỡ vướng_mắc . Theo Bộ GTVT , đến nay một_số dự_án BOT sụt_giảm doanh_thu so với phương_án tài_chính ban_đầu do lưu_lượng xe qua trạm thấp hơn so với dự_báo , do xuất_hiện các tuyến đường song_hành , đường ngang qua khu_vực trạm thu phí dẫn đến xe tránh trạm . Bên cạnh đó , việc giảm phí , chưa tăng phí BOT theo đúng lộ_trình cam_kết trong hợp_đồng BOT theo nghị_quyết 35 của Chính_phủ cùng sự thay_đổi về số_lượng trạm thu phí và giảm hỗ_trợ từ ngân_sách nhà_nước so với phương_án ban_đầu đang làm_khó các nhà_đầu_tư BOT và ngân_hàng tài_trợ dự_án . Chính_phủ nhấn_mạnh để xử_lý triệt_để , dứt_điểm các bất_cập của các trạm thu phí , Nhà_nước cần bố_trí nguồn vốn để mua lại các dự_án . Nhưng hiện_nay rất khó_khăn để cân_đối đủ nguồn vốn mua lại các trạm BOT . Hơn_nữa , toàn_bộ các dự_án BOT do Bộ GTVT quản_lý đã được Tổng_cục Đường_bộ Việt_Nam , nhà_đầu_tư phối_hợp với địa_phương rà_soát đề_xuất phương_án miễn , giảm phí BOT , trong đó đã thực_hiện giảm phí BOT của 39 dự_án .  Nhiều trạm BOT không_thể tăng phí đúng lộ_trình theo cam_kết hợp_đồng đã ký - Ảnh : TT. Theo Bộ GTVT , nếu không tăng phí đúng lộ_trình , nhiều doanh_nghiệp BOT có nguy_cơ phá_sản - Ảnh : TT \n",
            "\n",
            "Prediction:  Y Hân hn cháu L. gp nhau ti mt a_im thuc Buôn_Krô 2, x C_Né, huyn Krông_Bk, huyn Krông_Bk, huyn Krông_Bk )\n",
            "Truth:  Nhiều lần quan_hệ tình_dục với bạn gái nhí ( SN 2005 ) ngay tại nhà , Y Hân_Mlô_Duôn_Du ( SN 1996 ) dính vòng lao_lý khi người_nhà của bạn gái phát_hiện và gửi đơn tố_giác lên cơ_quan công_an . \n",
            "Content:  Thông_tin trên báo Bảo_vệ Pháp_luật , VKSND thị_xã Buôn_Hồ ( tỉnh Đắk_Lắk ) cho_biết vừa ban_hành cáo_trạng truy_tố bị_can Y Hân_Mlô_Duôn_Du ( SN 1996 , trú tại buôn Tring 4 , xã Ea_Blang , thị_xã Buôn_Hồ , tỉnh Đắk_Lắk ) về tội Giao_cấu với người từ đủ 13 tuổi đến dưới 16 tuổi . Cáo_trạng thể_hiện , khoảng tháng 1/2019 , qua Facebook , Y_Hân quen_biết và phát_sinh tình_cảm yêu_đương với cháu L. ( SN 2005 , trú tại xã Cư_Né , huyện Krông_Búk , tỉnh Đắk_Lắk ) nhưng cả 2 cắt đứt liên_lạc vào_khoảng tháng 3/2019. Khoảng 20h ngày 24/5/2019 , qua Facebook , Y Hân hẹn cháu L. gặp nhau tại một địa_điểm thuộc Buôn_KĐrô 2 , xã Cư_Né , huyện Krông_Búk để tâm_sự chia_tay Y_Hân đi TP. Hồ_Chí_Minh làm_ăn . Sau khi trò_chuyện , Y_Hân rủ cháu L. về nhà mình tại buôn Tring 4 ( xã Ea_Blang ) chơi . Lúc về đến nhà khoảng 23h . Thấy mọi người đã đi ngủ , Y Hân dẫn cháu L. vào phòng riêng của mình cùng chơi điện_tử . Đến khoảng 1h30’ ngày 25/5/2019 , sau khi tắt điện đi ngủ , Y Hân thực_hiện hành_vi quan_hệ tình_dục với cháu L .. Từ khoảng 16h ngày 25/5/2019 đến khoảng 22h ngày 26/5/2019 , Y_Hân tiếp_tục quan_hệ tình_dục 2 lần nữa với cháu L. ngay tại phòng_ngủ của mình . Khoảng 8h ngày 27/5/2019 , L. nhắn_tin cho dì đến nhà Y_Hân đón mình về . Về đến nhà , được mẹ nhiều lần gặng hỏi , cháu L. đã kể lại toàn_bộ sự_việc . Mẹ của L. ngay sau đó đã làm đơn tố_giác hành_vi của Y_Hân gửi đến Cơ_quan CSĐT Công_an thị_xã Buôn_Hồ . Infonet đưa tin , quá_trình điều_tra , Y_Hân khai nhận , vào tháng 2/2019 , Y_Hân có quan_hệ tình_dục với cháu L. tại nhà của mình nhưng vì thời_gian đã lâu nên không nhớ cụ_thể bao_nhiêu lần . Cơ_quan_chức_năng đang hoàn_tất thủ_tục để đưa bị_can Y Hân ra xét_xử theo quy_định của pháp_luật . * Tên nạn_nhân đã thay_đổi . Mộc_Miên ( Tổng_hợp )  Đối_tượng Y Hân_Mlô_Duôn_Du tại cơ_quan công_an . \n",
            "\n",
            "Prediction:  Tng_thng Hàn_Quc_Park_Geun-hye ch_nh cu phát_ngôn_viên Choi_Jai - kyeong tr_thành tr_l công_chng và tr_l công_chng. \" ng_thng H\n",
            "Truth:  Tổng_thống Hàn_Quốc tiến_hành cải_tổ một phần bộ_máy trợ_lý cấp cao nhằm xoa_dịu dư_luận sau vụ bê_bối bà chuyển những tài_liệu bí_mật cho một người bạn lâu năm . \n",
            "Content:  Tổng_thống Hàn_Quốc_Park_Geun-hye . Tổng_thống Hàn_Quốc_Park_Geun-hye chỉ_định cựu công_tố_viên Choi_Jai - kyeong trở_thành trợ_lý cấp cao về các vấn_đề dân_sự cho bà , đồng_thời đề_bạt cựu phát_ngôn_viên Quốc_hội Bae_Sung - rye làm trợ_lý phụ_trách các vấn_đề công_vụ , Yonhap hôm_qua đưa tin . Bà Park cũng chấp_thuận thêm đơn xin từ_chức của ba cố_vấn hàng_đầu là Lee_Jae - man , Jeong_Ho - seong và Ahn_Bong - geun , những người từng giữ vai_trò trợ_lý hành_chính , trợ_lý phụ_trách các vấn_đề cá_nhân của tổng_thống và trợ_lý về quan_hệ công_chúng . \" Nhận_thức sâu_sắc về tính nghiêm_trọng của tình_hình hiện_nay , Tổng_thống Park đã quyết_định thực_hiện một cuộc cải_tổ ban trợ_lý nhằm đáp_ứng yêu_cầu từ các tầng_lớp khác nhau \" , ông Jung_Youn - kuk , phát_ngôn_viên tổng_thống , cho_biết . Tổng_thống Park hôm 28/10 yêu_cầu 10 trợ_lý cấp cao từ_chức . Những người này bao_gồm trợ_lý cấp cao về phối_hợp chính_sách , các vấn_đề chính_trị , dân_sự , ngoại_giao , kinh_tế , an_ninh quốc_gia , quan_hệ công_chúng , chiến_lược tương_lai , giáo_dục , văn_hoá , việc_làm , an_sinh và nhân_sự . Tổng_thống Park_Geun-hye tuần trước thừa_nhận chuyển nhiều tài_liệu nhà_nước bí_mật cho người bạn thân lâu năm là bà Choi_Soon - sil . Hàng nghìn người Hàn_Quốc sau đó biểu_tình ở thủ_đô Seoul yêu_cầu bà từ_chức vì cho_rằng bà phản_bội niềm_tin của công_chúng và thất_bại trong việc quản_lý chính_phủ . Bê_bối khiến mức tín_nhiệm của Tổng_thống Park giảm xuống mức thấp kỷ_lục . Trong một cuộc thăm_dò ý_kiến , hơn 40 % số người được hỏi cho_rằng bà nên từ_chức hoặc bị luận_tội . Xem thêm : Bạn thân Tổng_thống Hàn về nước , hợp_tác điều_tra bê_bối rò_rỉ thông_tin Vũ_Hoàng   Tổng_thống Hàn_Quốc_Park_Geun-hye . \n",
            "\n",
            "Prediction:  tàu gp s_c, trong ó 7 cán_b mng_li kh_tng_thu_vào trôi trôi t_do. a_im tàu gp s_c, trong ó 7 cán_b mng\n",
            "Truth:  Trên đường chở đoàn 7 cán_bộ của trung_tâm khí_tượng đi làm nhiệm_vụ từ đảo vào đất_liền , con tàu công_suất nhỏ bị hỏng máy . \n",
            "Content:  Ông Nguyễn_Văn_Lượng , Giám_đốc Đài_khí_tượng thuỷ_văn Bắc Trung_Bộ cho biết , 13h ngày 16/7 tàu ngư_dân chở 7 cán_bộ mạng_lưới khí_tượng_thuỷ_văn trên đường từ Đảo_Ngư vào đất_liền đã bị hỏng máy . Địa_điểm tàu gặp sự_cố cách đất_liền hơn một hải_lý . Không_thể khắc_phục , những người trên tàu đã liên_lạc về trung_tâm cứu_hộ cứu nạn tỉnh Nghệ_An . Trong lúc đang chờ cứu_hộ , tàu gặp nạn được một tàu của ngư_dân hoạt_động gần đó tiếp_cận , lai_dắt vào bờ biển thị_xã Cửa_Lò sau gần 3 giờ trôi tự_do . \" Lúc tàu gặp sự_cố , sóng biển rất to do ảnh_hưởng của hoàn_lưu trước bão . 8 người trên tàu , trong đó 7 cán_bộ sức_khoẻ ổn_định sau mấy tiếng lênh_đênh trên biển \" , một cán_bộ trên tàu gặp sự_cố cho biết . Biển Cửa_Lò lúc gần 17h ngày 16/7 . Theo ông Lượng trước đó một ngày , đoàn 7 cán_bộ gồm 3 người của Đài_Bắc_Trung_Bộ và 4 cán_bộ kỹ_thuật Mạng_lưới Khí_tượng_thuỷ_văn Trung_ương đã ra đảo Hòn_Ngư ( Nghệ_An ) để bảo_dưỡng máy thiết_bị , phục_vụ đón cơn bão Talas . Tàu chở đoàn cán_bộ có công_suất nhỏ , được thuê của ngư_dân .   Biển Cửa_Lò lúc gần 17h ngày 16/7 . \n",
            "\n",
            "Prediction:  n năm 2014, Ch_tch UBND TP. Hi_Phng có công_văn ch_o v vic lp_t ti nhà_hát ln TP. Hi_Phng có t_trên trên trên mt_s\n",
            "Truth:  Sau hai năm đưa vào sử_dụng , hệ_thống đèn LED nghệ_thuật hàng chục tỉ tại Hải_Phòng đã bị tháo_dỡ khiến nhiều người cảm_thấy tiếc_nuối . \n",
            "Content:  Năm 2014 , Chủ_tịch UBND TP. Hải_Phòng đã có công_văn chỉ_đạo về việc lắp_đặt hệ_thống đèn_điện chiếu sáng tại nhà_hát lớn và đèn trang_trí nghệ_thuật trên một_số tuyến đường chính trong nội_thành . Đến năm 2015 , Sở Văn_Hoá – Thể_thao Hải_Phòng có tờ_trình gửi UBND TP. Hải_Phòng xin phê_duyệt dự_án trên . Theo đó , tổng_số tiền đầu_tư cho dự_án đèn LED nghệ_thuật trên là gần 30 tỉ . Số tiền được phân_bố đều 50/50 . Một_nửa cho một_số tuyến đường chính xung_quanh khu_vực Nhà_hát lớn TP. Hải_Phòng còn một_nửa để lắp_đặt đèn tại đường Lê_Hồng_Phong . Tất_cả số tiền thực_hiện dự_án đều được lấy từ nguồn kinh_phí sự_nghiệp . Số vốn đầu_tư càng lớn , người_dân thành_phố hoa phượng đỏ càng cảm_thấy tiếc_nuối . Bởi ngày 16 , 17/11/2016 , TP. Hải_Phòng đã tiến_hành cho các đơn_vị chức_năng tháo toàn_bộ hệ_thống đèn LED nghệ_thuật trên đường Lê_Hồng_Phong . Đương_nhiên , kèm theo sự tiếc_nuối bao_giờ dư_luận cũng đưa ra “ một sự lựa_chọn tốt hơn ” cho để dùng số tiền đó . Những bình_luận như : “ Tiền đấy để mà xây trường_học cho các em vùng_cao , tiền đấy để làm từ_thiện ... có phải đỡ lãng_phí hơn không ” . Và để giải_thích cho sự tháo_dỡ “ đầy lãng_phí ” đó , ông Lê_Khắc_Nam – Phó Chủ_tịch UBND TP. Hải_Phóng đã có phát_ngôn : “ Nó cũng như bắn pháo_hoa vậy ... Đèn trang_trí cũng để làm_đẹp , sao bảo lãng_phí được ? Giờ nhiệm_vụ của nó đã hoàn_thành rồi , nó đã quá tuổi sử_dụng , cần phải thay_thế bằng một hệ_thống đèn khác để trang_trí đón xuân năm 2017 . ” Đương_nhiên , với những luận_điểm không thừa_nhận sự lãng_phí , ông Lê_Khắc_Nam vấp phải không ít sự phản_đối của cư_dân mạng . Tuy_nhiên , điều ông Nam nói đâu phải không hợp_lí . Đành rằng trên phương_diện nhân_đạo phổ rộng thì những điều cư_dân mạng nói không phải không có_lí . Hàng chục tỉ đồng chỉ để treo đó trang_trí trong vòng hai năm . Những người đói chẳng_thể nhìn vào nó để no mà những em học_sinh vùng_cao cũng chẳng_thể nhờ ánh đèn LED mà đến trường được . Nhưng ở một thành_phố mà mức_sống của người_dân khá cao so với mặt_bằng chung , ở một thành_phố mà du_lịch phát_triển mạnh thì việc đầu_tư hàng chục tỉ đồng để làm_đẹp cho bộ_mặt của thành_phố trong vòng hai năm thì chẳng có gì là lãng_phí . Hãy nhìn vào hàng trăm vụ cháy lớn_nhỏ trên khắp cả nước những năm vừa_qua . Hầu_hết những vụ hoả_hoạn đó đều do chập điện bởi đường_dây , hệ_thống điện không được bảo_hành và thay mới thường_xuyên . Và việc_làm của TP. Hải_Phòng là hoàn_toàn đúng_đắn khi đã nhanh_chóng tháo_dỡ toàn_bộ hệ_thống đèn LED đã hết hạn_sử_dụng . Nhiều thứ cũ có_thể tận_dụng nhưng những thứ liên_quan trực_tiếp đến tính_mạng và đời_sống của người_dân thì cần phải “ mạnh_tay ” dẹp bỏ và thay_thế . Đúng như ông Nam đã nói , nó cũng như là bắn pháo_hoa vậy . Mặc_dù số tiền đầu_tư chỉ để “ ngắm ” cũng khá lớn nhưng đó là việc cần làm để nâng tầm thành_phố và để cho những người_dân thành_phố cảng tự_hào về cảnh_quan của địa_phương mình . Cũng giống như pháo_hoa , nó sẽ làm cho Tết trở_nên ấm_cúng và đáng mong_đợi hơn . Bảo_Trang * Bài viết thể_hiện quan_điểm riêng của tác_giả  \n",
            "\n",
            "Prediction:  ca Tui_Tr Online, danh_tnh ca Tui_Tr Online t B Công_an cho_bit hai t_tù ang b giam T16 cho_bit 2 t_tù b trn vào êm 10-9. Ngay sau khi\n",
            "Truth:  Một vụ_việc hi_hữu vừa xảy ra tại Trại tạm giam T16 Bộ Công_an . Hai tử_tù Lê_Văn_Thọ và Nguyễn_Văn_Tình đã trốn ra khỏi phòng biệt giam . \n",
            "Content:  Ngày 13-9 , nguồn_tin của Tuổi_Trẻ Online từ Bộ Công_an cho_biết hai tử_tù đang bị giam tại trại tạm giam T16 để chờ thi_hành án đã bỏ trốn khỏi phòng biệt giam . Xác_nhận với Tuổi_Trẻ Online , một giám_thị có trách_nhiệm tại trại tạm giam T16 cho_biết 2 tử_tù bỏ trốn vào đêm 10-9 . Ngay sau khi vụ_việc xảy ra , trại tạm giam đã báo_cáo lên Bộ công_an để xin phương_án truy_tìm các tử_tù này . Theo nguồn_tin của Tuổi_Trẻ Online , danh_tính của 2 tử_tù được xác_định là Lê_Văn_Thọ ( biệt_danh Thọ sứt ) 37 tuổi , trú tại xóm 6 , xã Thanh_Sơn , huyện Thanh_Hà , Hải_Dương và Nguyễn_Văn_Tình , trú tại xã Đông_Xuân , Quốc_Oai , Hà_Nội . Thọ có 4 tiền_án về các tội giết người , bắt_cóc nhằm chiếm_đoạt tài_sản , sử_dụng trái_phép vũ_khí quân_dụng , đưa hối_lộ , trộm_cắp tài_sản , lạm_dụng tín_nhiệm chiếm_đoạt tài_sản . Tình có 1 tiền_án về tội tiêu_thụ tài_sản do người khác phạm_tội mà có . Vào tháng 5-2017 , Toà_án nhân_dân ( TAND ) tỉnh Hà_Nam đã tuyên_phạt Lê_Văn_Thọ mức án tử_hình cho các tội_danh mua_bán trái_phép chất ma_tuý , giết người và lừa_đảo chiếm_đoạt tài_sản . Theo hồ_sơ vụ án , mặc_dù là bị án đang chấp_hành án phạt tù có thời_hạn tại trại tạm giam Nam_Hà của Bộ Công_an nhưng Thọ vẫn gọi điện thuê và chỉ_đạo các đối_tượng ngoài xã_hội thực_hiện hành_vi giết người , lừa_đảo chiếm_đoạt tài_sản , mua_bán trái_phép chất ma_tuý . Nguyễn_Văn_Tình bị TAND TP Hà_Nội xử mức án tử_hình trong một vụ buôn_bán ma_tuý vào tháng 4-2017 . Tuổi_Trẻ Online đã đặt câu_hỏi về việc theo quy_định tử_tù bị giam trong phòng biệt giam sẽ bị cùm chân thì sao vẫn có_thể bỏ trốn nhưng đại_diện trại tạm giam T16 chưa trả_lời và chỉ nói ngắn_gọn : \" cơ_quan công_an đang có phương_án để truy bắt \" . Được biết Công_an TP Hà_Nội đã có thông_báo về việc truy_tìm hai đối_tượng bỏ trốn .  Chân_dung 2 tử_tù bỏ trốn - Ảnh : Công_an Hà_Nội \n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    print('\\nPrediction: ',pred_str[i])\n",
        "    print('Truth: ',label_str[i])\n",
        "    print('Content: ',test_data[i]['original'])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n4kLAIQSr5g2",
        "outputId": "b4d745cb-4599-43cf-e8c0-1ec9e5fdba6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'data/vietnews-master/data/test_tokenized/004984.txt.seg'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[0]['file']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "testing-huggingface",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01644f724526402c9f139e19b2035073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03b57581ace346d2bde4378a7c6309ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09375b2aac814adcbb51589402eb8b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aeb387a0f53469c8ff42e57647831d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7097c890712d418e9dd9c3e33873a2d5",
            "placeholder": "​",
            "style": "IPY_MODEL_01644f724526402c9f139e19b2035073",
            "value": " 6589/6589 [02:35&lt;00:00, 42.40ba/s]"
          }
        },
        "0d6a0b11ec2a4c6d975857678415f505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef7f4e43319429d9277d55c83cb084d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_825d4b325e9b45859e808cd6b14fdd42",
              "IPY_MODEL_dd0bdf658c6d4c0cb0a091129ecbebb0"
            ],
            "layout": "IPY_MODEL_ab543b6ef5b34ed4acb85fd25304ed75"
          }
        },
        "1ba158d2f09a4c54bc647ebe77d27b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3598a3c015a64c20be134cf4d2e7fbbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5507016090f64bb99dcbf88e14d71eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ac8ad6eea254d369996622911a6a79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e22006901f10483882e1a1f20f645b24",
            "max": 6589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efd6b87b93244d5ca6817ab35c385510",
            "value": 6589
          }
        },
        "63276058881e45539d8dcd4ff2e05edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "7097c890712d418e9dd9c3e33873a2d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70bb7c0669ca4a3699ad36dfdcc10910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ac8ad6eea254d369996622911a6a79e",
              "IPY_MODEL_0aeb387a0f53469c8ff42e57647831d8"
            ],
            "layout": "IPY_MODEL_1ba158d2f09a4c54bc647ebe77d27b60"
          }
        },
        "825d4b325e9b45859e808cd6b14fdd42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21d97b40ffa43668b9962c5d771debb",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7c296a0b8a84ee3be45c92edb6aad21",
            "value": 22
          }
        },
        "a4898ec38618401396928eee2c4f9926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab543b6ef5b34ed4acb85fd25304ed75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ddde0882d841daa3bfde43ed6e6fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cab0cd369bfa4c80b963ebd27d3e4974",
              "IPY_MODEL_db0264404d934633824b5b381b31a5ac"
            ],
            "layout": "IPY_MODEL_09375b2aac814adcbb51589402eb8b68"
          }
        },
        "cab0cd369bfa4c80b963ebd27d3e4974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b57581ace346d2bde4378a7c6309ca",
            "max": 1416,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63276058881e45539d8dcd4ff2e05edd",
            "value": 1416
          }
        },
        "db0264404d934633824b5b381b31a5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d6a0b11ec2a4c6d975857678415f505",
            "placeholder": "​",
            "style": "IPY_MODEL_5507016090f64bb99dcbf88e14d71eda",
            "value": " 1416/1416 [00:44&lt;00:00, 31.76ba/s]"
          }
        },
        "dd0bdf658c6d4c0cb0a091129ecbebb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3598a3c015a64c20be134cf4d2e7fbbe",
            "placeholder": "​",
            "style": "IPY_MODEL_a4898ec38618401396928eee2c4f9926",
            "value": " 22/22 [29:59&lt;00:00, 81.81s/ba]"
          }
        },
        "e21d97b40ffa43668b9962c5d771debb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e22006901f10483882e1a1f20f645b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd6b87b93244d5ca6817ab35c385510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "f7c296a0b8a84ee3be45c92edb6aad21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
