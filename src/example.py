import sys
sys.path.append("")
import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from src.Utils.utils import read_text_from_file

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")

model_dir="vietnamese_mt5_summary_model"
tokenizer = AutoTokenizer.from_pretrained(model_dir)  
model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)
model.to(device)

file_path = "data/sample.txt"
text = read_text_from_file(file_path)

encoding = tokenizer(text, return_tensors="pt")
input_ids, attention_masks = encoding["input_ids"].to(device), encoding["attention_mask"].to(device)
outputs = model.generate(
    input_ids=input_ids, attention_mask=attention_masks,
    max_length=256,
    # num_beams =1, 
    # early_stopping=True,
)
for output in outputs:
    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)
    print(line)



































































































































































































































































































































